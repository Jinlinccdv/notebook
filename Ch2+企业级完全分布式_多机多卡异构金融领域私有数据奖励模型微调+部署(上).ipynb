{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe98a9e5-4646-47d0-9445-19bf22ef3a54",
   "metadata": {},
   "source": [
    "# <center>Ch2 企业级完全分布式_多机多卡异构金融领域私有数据奖励模型微调+部署(上)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0374a3",
   "metadata": {},
   "source": [
    "# 背景   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce622e5",
   "metadata": {},
   "source": [
    "## 应用场景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a8ca61",
   "metadata": {},
   "source": [
    "1. SFT 阶段圆满结束  \n",
    "   • 小王按计划完成 LoRA-SFT，离线评测显示：  \n",
    "     - 专业知识覆盖率明显提升（F1≈0.72 → 0.88）  \n",
    "     - 解释性有所改善，但读者仍反映某些术语艰深、风险提示不够突出。  \n",
    "   • 线上灰度测试暴露两类主要问题：  \n",
    "     a) 回答经常“跑题”——用户问风险提示，模型给的是行情描述。  \n",
    "     b) 个别回答带有强烈倾向性（“赶紧抄底”“恐慌性减仓”），不符合公司安全红线。\n",
    "\n",
    "2. 领导新指令：用最少资源进一步提质控险  \n",
    "   要求：  \n",
    "   • 用强化学习进一步对话风格和安全边界做微调；  \n",
    "   • 重点解决“跑题”“倾向性建议”两大痛点；  \n",
    "   • 仍需控制 GPU 占用，保证后续可扩展。  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6cc71",
   "metadata": {},
   "source": [
    "3. 技术决策：采用 GRPO + 奖励模型  \n",
    "   • **为什么选 GRPO**  \n",
    "     - 公司只能收集到有限规模的相对偏好数据（用户或审核员标记“回答 A 优于 B”）；  \n",
    "     - GRPO 专门处理组内相对奖励，样本效率高，能在 10⁴ 级别数据上稳定收敛；  \n",
    "     - 与 PPO 相比，GRPO 对 KL 超参数不敏感，迭代次数更省。  \n",
    "\n",
    "   • **训练流水线**  \n",
    "     (1) 收集多候选回答 → (2) 人类打分形成 pair / group → (3) 微调奖励模型 R_θ → (4) GRPO 训练策略 π_φ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620195c0",
   "metadata": {},
   "source": [
    "## 为什么GRPO必须微调奖励模型？\n",
    "\n",
    "### 1. 奖励模型在GRPO中的关键作用\n",
    "\n",
    "**GRPO的工作流程**：\n",
    "```\n",
    "输入问题 → 策略模型生成多个候选回答 → 奖励模型对每个回答打分 → 基于分数差异更新策略\n",
    "```\n",
    "\n",
    "**关键点**：奖励模型的评分直接决定了策略模型的优化方向。如果奖励模型评分不准确，整个GRPO训练就会失败。\n",
    "\n",
    "### 2. 通用奖励模型的根本缺陷\n",
    "\n",
    "#### 2.1 评估标准不匹配\n",
    "\n",
    "**具体例子**：\n",
    "- **通用奖励模型**可能认为：\"买股票很简单，随便选一只就行\"是个\"有用\"的回答\n",
    "- **金融专业标准**要求：必须考虑风险评估、资产配置、市场分析等专业要素\n",
    "\n",
    "**结果**：通用奖励模型会给错误答案高分，导致GRPO训练出一个给出危险金融建议的模型。\n",
    "\n",
    "#### 2.2 无法识别领域特定的错误\n",
    "\n",
    "**通用模型的盲点**：\n",
    "- 不知道金融建议中的合规性要求\n",
    "- 无法判断投资建议的风险等级是否合适\n",
    "- 不理解金融术语的准确性和专业性\n",
    "\n",
    "**危险后果**：GRPO会强化这些专业上错误但表面上\"流畅\"的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7477f",
   "metadata": {},
   "source": [
    "### 3. 微调奖励模型的直接好处\n",
    "\n",
    "#### 3.1 建立正确的评估标准\n",
    "\n",
    "**微调前**：\n",
    "```json\n",
    "问题：如何选择股票？\n",
    "回答A：随便买个热门股票就行\n",
    "回答B：需要分析公司财务、行业前景、估值水平...\n",
    "\n",
    "通用奖励模型可能给A更高分（因为简洁易懂）\n",
    "```\n",
    "\n",
    "**微调后**：\n",
    "```json\n",
    "同样的问题和回答\n",
    "微调后的奖励模型会给B更高分（符合金融专业标准）\n",
    "```\n",
    "\n",
    "#### 3.2 提供准确的优化信号\n",
    "\n",
    "**训练效果对比**：\n",
    "\n",
    "| 奖励模型类型 | GRPO优化方向 | 最终模型行为 |\n",
    "|------------|------------|------------|\n",
    "| 通用模型 | 向简单、通俗的回答优化 | 给出不专业甚至危险的金融建议 |\n",
    "| 微调模型 | 向专业、准确的回答优化 | 给出符合金融标准的专业建议 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1900886",
   "metadata": {},
   "source": [
    "### 4. 项目层面的具体好处\n",
    "\n",
    "#### 4.1 避免训练失败\n",
    "\n",
    "**没有微调的风险**：\n",
    "- GRPO可能训练出一个在金融领域完全不可用的模型\n",
    "- 花费大量计算资源却得到错误的结果\n",
    "- 模型可能给用户提供有害的金融建议\n",
    "\n",
    "**微调后的保障**：\n",
    "- 确保GRPO朝着正确方向优化\n",
    "- 训练出真正有用的金融AI助手\n",
    "- 避免项目失败的风险\n",
    "\n",
    "#### 4.2 提升最终模型质量\n",
    "\n",
    "**量化对比**（理论预期）：\n",
    "\n",
    "| 评估维度 | 使用通用奖励模型 | 使用微调奖励模型 |\n",
    "|---------|----------------|----------------|\n",
    "| 专业准确性 | 30-40% | 80-90% |\n",
    "| 风险意识 | 20-30% | 85-95% |\n",
    "| 合规性 | 10-20% | 90-95% |\n",
    "| 用户满意度 | 低 | 高 |\n",
    "\n",
    "#### 4.3 降低项目风险\n",
    "\n",
    "**业务风险控制**：\n",
    "- **合规风险**：避免AI给出违反金融监管的建议\n",
    "- **声誉风险**：防止因错误建议损害公司声誉\n",
    "- **法律风险**：减少因AI建议导致的法律纠纷\n",
    "\n",
    "#### 4.4 提高投资回报率\n",
    "\n",
    "**成本效益分析**：\n",
    "- **微调成本**：相对较低（主要是数据标注和计算资源）\n",
    "- **失败成本**：极高（整个项目推倒重来）\n",
    "- **ROI**：微调奖励模型是确保项目成功的关键投资"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10debbc8",
   "metadata": {},
   "source": [
    "### 5. 具体的改进机制\n",
    "\n",
    "#### 5.1 评分精度提升\n",
    "\n",
    "**微调前后对比**：\n",
    "```json\n",
    "问题：个人投资者应该如何配置资产？\n",
    "\n",
    "回答1：\"把所有钱都买股票，收益最高\"\n",
    "- 通用模型评分：7/10（听起来积极）\n",
    "- 微调模型评分：2/10（风险过高，不专业）\n",
    "\n",
    "回答2：\"建议根据风险承受能力，配置股票、债券、现金等多元化投资组合\"\n",
    "- 通用模型评分：6/10（比较保守）\n",
    "- 微调模型评分：9/10（专业且合理）\n",
    "```\n",
    "\n",
    "## 总结\n",
    "\n",
    "**为什么必须微调**：\n",
    "1. 通用奖励模型会给GRPO错误的优化信号\n",
    "2. 导致训练出在金融领域不可用甚至有害的模型\n",
    "3. 整个项目面临失败风险\n",
    "\n",
    "**微调带来的好处**：\n",
    "1. **确保项目成功**：避免训练方向错误\n",
    "2. **提升模型质量**：获得真正专业的金融AI\n",
    "3. **降低业务风险**：避免合规、声誉、法律风险\n",
    "4. **提高投资回报**：用相对小的成本确保项目成功\n",
    "\n",
    "**核心逻辑**：奖励模型是GRPO的\"指南针\"，指南针不准确，整个训练就会迷失方向。微调奖励模型就是在校准这个\"指南针\"，确保它能准确指向金融领域的\"正确方向\"。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8501c8",
   "metadata": {},
   "source": [
    "# 1. 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38040c1e",
   "metadata": {},
   "source": [
    "## 一、流程参考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f497a578",
   "metadata": {},
   "source": [
    "整体微调流程可以参考之前专家模型的微调流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0901005",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250528171000691.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40332318",
   "metadata": {},
   "source": [
    "## 二、如何高质量的偏好数据集\n",
    "\n",
    "**关注点**：\n",
    "- **数据来源选择**：新生成 vs 复用现有SFT数据\n",
    "- **数据构建策略**：二元偏好 vs 多层次偏好\n",
    "- **数据一致性**：文档来源的重叠度控制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8cbe3",
   "metadata": {},
   "source": [
    "### 数据处理方案\n",
    "```json\n",
    "奖励模型数据策略决策树：\n",
    "├── 数据来源策略\n",
    "│   ├── 完全重新生成\n",
    "│   ├── 完全复用SFT数据  \n",
    "│   └── 混合策略\n",
    "├── 偏好构建策略\n",
    "│   ├── 二元偏好（好/坏）\n",
    "│   ├── 多层次偏好（1-N分）\n",
    "│   └── 多维度偏好\n",
    "└── 质量控制策略\n",
    "    ├── 人工验证\n",
    "    ├── 自动化检测\n",
    "    └── 迭代优化\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d8b3e",
   "metadata": {},
   "source": [
    "### 2.1 数据来源策略的分析\n",
    "\n",
    "#### 2.1.1 选择维度分析\n",
    "**维度1：数据分布适配性**\n",
    "- **SFT数据特征**：单一正确答案导向，分布集中在高质量区间\n",
    "- **奖励模型需求**：需要质量分布广泛的数据来学习偏好判断\n",
    "- **分析结论**：SFT数据分布与奖励模型需求存在根本性不匹配\n",
    "\n",
    "**维度2：任务目标差异**\n",
    "- **SFT目标**：学习生成符合指令的正确答案\n",
    "- **奖励模型目标**：学习区分不同质量答案的相对优劣\n",
    "- **关键差异**：从\"生成正确答案\"到\"判断答案质量\"的范式转换\n",
    "\n",
    "**维度3：数据质量控制**\n",
    "- **重新生成优势**：可控的质量梯度设计\n",
    "- **复用数据风险**：质量同质化，缺乏判别训练信号\n",
    "- **控制策略**：需要人工设计质量差异\n",
    "\n",
    "#### 2.1.2 决策逻辑链\n",
    "```json\n",
    "问题：数据来源如何选择？\n",
    "↓\n",
    "分析1：SFT数据是否适合奖励模型训练？\n",
    "→ 否，因为分布不匹配\n",
    "↓\n",
    "分析2：重新生成的成本效益如何？\n",
    "→ 高成本但必要，因为质量控制需求\n",
    "↓\n",
    "分析3：是否需要完全抛弃SFT数据？\n",
    "→ 否，可以部分复用保持连续性\n",
    "↓\n",
    "结论：混合策略 - 30%复用 + 70%重新生成(参考比值)\n",
    "```\n",
    "\n",
    "**决策理由**：\n",
    "- **优点**：保持与SFT模型的连续性，同时获得质量多样性\n",
    "- **缺点**：增加数据生成成本\n",
    "- **正确性验证**：通过质量分布分析和模型性能验证\n",
    "\n",
    "方便后续进行强化学习参考，如果单纯微调奖励模型，不需要进行过多数据连续性考虑。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86352da",
   "metadata": {},
   "source": [
    "### 2.2 偏好数据集构建策略\n",
    "\n",
    "#### 2.2.1 数学基础分析\n",
    "**组合数学视角**：\n",
    "```python\n",
    "# 不同答案数量的偏好对生成能力\n",
    "答案数量 | 偏好对数量 | 训练信号密度\n",
    "   2    |     1      |    基准\n",
    "   3    |     3      |    3倍\n",
    "   4    |     6      |    6倍  \n",
    "   5    |    10      |   10倍\n",
    "   6    |    15      |   15倍\n",
    "```\n",
    "\n",
    "**边际效益分析**：\n",
    "- **2→4个答案**：训练信号提升600%，成本增加100%\n",
    "- **4→6个答案**：训练信号提升150%，成本增加50%\n",
    "- **最优点**：5个答案，平衡效益与成本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465b30c",
   "metadata": {},
   "source": [
    "#### 2.2.2 认知科学视角\n",
    "**人类偏好判断特征**：\n",
    "- **相对性**：人类更擅长相对比较而非绝对评分\n",
    "- **层次性**：质量判断存在明显的层次结构\n",
    "- **一致性**：需要足够的对比样本保证判断一致性\n",
    "\n",
    "**设计原则**：\n",
    "```json\n",
    "质量层次设计原则：\n",
    "1. 差异明显性：相邻层次质量差异需人类可感知\n",
    "2. 覆盖完整性：从\"很差\"到\"优秀\"的完整光谱\n",
    "3. 标准一致性：同一层次在不同问题间保持一致\n",
    "4. 领域适配性：符合金融领域的专业标准\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ccdb9",
   "metadata": {},
   "source": [
    "#### 2.2.3 决策分析过程\n",
    "**步骤1：需求分析**\n",
    "- 奖励模型需要学习细粒度的质量判断\n",
    "- 金融领域答案质量呈现渐进式而非二元式分布\n",
    "\n",
    "**步骤2：方案对比**\n",
    "| 策略 | 训练信号 | 实施复杂度 | 质量控制 | 成本效益 |\n",
    "|------|----------|------------|----------|----------|\n",
    "| 二元偏好 | 低 | 简单 | 容易 | 高 |\n",
    "| 4层偏好 | 中高 | 中等 | 中等 | 中高 |\n",
    "| 5层偏好 | 高 | 中等 | 中等 | 最优 |\n",
    "| 6+层偏好 | 很高 | 复杂 | 困难 | 低 |\n",
    "\n",
    "**步骤3：决策逻辑**\n",
    "```json\n",
    "选择5层偏好策略的逻辑：\n",
    "1. 训练信号充足（10对 vs 1对）\n",
    "2. 实施复杂度可控\n",
    "3. 质量控制可行\n",
    "4. 成本效益最优\n",
    "5. 符合人类认知特点\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979152b",
   "metadata": {},
   "source": [
    "### 2.3 文档一致性策略分析\n",
    "\n",
    "#### 2.3.1 一致性程度的影响分析\n",
    "**完全一致的影响**：\n",
    "- **优点**：保持领域知识的连续性\n",
    "- **缺点**：限制数据多样性，可能导致过拟合\n",
    "- **风险**：奖励模型泛化能力不足\n",
    "\n",
    "**完全不一致的影响**：\n",
    "- **优点**：最大化数据多样性\n",
    "- **缺点**：可能破坏与SFT模型的连贯性\n",
    "- **风险**：领域知识不一致，影响模型性能\n",
    "\n",
    "**部分重叠的影响**：\n",
    "- **优点**：平衡连续性与多样性\n",
    "- **缺点**：需要精确控制重叠比例\n",
    "- **策略**：30-40%重叠的理论基础\n",
    "\n",
    "#### 2.3.2 重叠比例的理论依据\n",
    "**信息论视角**：\n",
    "```json\n",
    "信息熵最大化原理：\n",
    "- 过高重叠（>60%）：信息冗余，熵值降低\n",
    "- 过低重叠（<20%）：信息断裂，连续性丢失\n",
    "- 最优区间（30-40%）：平衡信息新颖性与连续性\n",
    "```\n",
    "\n",
    "**机器学习视角**：\n",
    "```json\n",
    "泛化能力优化：\n",
    "- 训练数据多样性 & 模型泛化能力\n",
    "- 领域知识一致性 & 模型专业性\n",
    "- 最优平衡点：30-40%重叠比例\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf4183",
   "metadata": {},
   "source": [
    "## 三、系统性决策\n",
    "\n",
    "### 3.1 决策评估矩阵\n",
    "```\n",
    "评估维度 | 权重 | 重新生成 | 复用SFT | 混合策略\n",
    "---------|------|----------|---------|----------\n",
    "数据质量 | 30%  |    9     |    4    |    8\n",
    "成本控制 | 20%  |    3     |    9    |    7\n",
    "实施难度 | 15%  |    4     |    8    |    6\n",
    "效果预期 | 25%  |    9     |    5    |    8\n",
    "风险控制 | 10%  |    7     |    6    |    8\n",
    "---------|------|----------|---------|----------\n",
    "加权得分 |      |   6.9    |   6.0   |   7.6\n",
    "```\n",
    "\n",
    "### 3.2 风险-收益分析\n",
    "**高风险高收益策略**：完全重新生成\n",
    "- **收益**：最优数据质量，最佳模型性能\n",
    "- **风险**：高成本，实施复杂度大\n",
    "\n",
    "**低风险低收益策略**：完全复用SFT\n",
    "- **收益**：低成本，实施简单\n",
    "- **风险**：数据质量不足，模型性能受限\n",
    "\n",
    "**中风险中高收益策略**：混合策略\n",
    "- **收益**：平衡质量与成本，预期性能良好\n",
    "- **风险**：实施复杂度中等，需要精确控制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d6db0",
   "metadata": {},
   "source": [
    "## 四、实施策略的正确性验证\n",
    "\n",
    "### 4.1 理论正确性\n",
    "**基于RLHF理论**：\n",
    "- 奖励模型需要学习人类偏好分布\n",
    "- 偏好数据应覆盖质量光谱的完整范围\n",
    "- 数据多样性直接影响模型泛化能力\n",
    "\n",
    "**基于认知科学**：\n",
    "- 人类偏好判断具有相对性和层次性\n",
    "- 5层质量分级符合人类认知特点\n",
    "- 渐进式质量差异有助于精确判断\n",
    "\n",
    "### 4.2 实践正确性\n",
    "**成功案例验证**：\n",
    "- OpenAI GPT-4的RLHF训练使用了多层次偏好数据\n",
    "- Anthropic  AI采用了类似的质量分级策略\n",
    "- 学术研究表明多层次偏好优于二元偏好\n",
    "\n",
    "\n",
    "### 4.3 经济正确性\n",
    "**成本效益分析**：\n",
    "```\n",
    "投入产出比计算：\n",
    "- 数据生成成本：5层策略 vs 2层策略 = 2.5倍\n",
    "- 性能提升预期：5层策略 vs 2层策略 = 3-4倍\n",
    "```\n",
    "\n",
    "## 五、系统性思考的核心洞察\n",
    "\n",
    "### 5.1 方法论层面\n",
    "**系统思维应用**：\n",
    "- 将奖励模型数据策略视为一个完整系统\n",
    "- 考虑各组件间的相互作用和依赖关系\n",
    "- 优化整体性能而非局部最优\n",
    "\n",
    "**权衡思维应用**：\n",
    "- 在质量、成本、复杂度间寻找最优平衡点\n",
    "- 避免极端策略，选择稳健的中间路径\n",
    "- 基于量化分析进行决策\n",
    "\n",
    "### 5.2 领域特异性考虑\n",
    "**金融领域特点**：\n",
    "- 专业性要求高，错误成本大\n",
    "- 风险意识是核心评估维度\n",
    "- 监管合规性需要特别关注\n",
    "\n",
    "**适配策略**：\n",
    "- 质量评估标准需要包含金融专业维度\n",
    "- 风险提示和免责声明是必要组成部分\n",
    "- 需要金融专家参与质量验证过程\n",
    "\n",
    "### 5.3 可扩展性设计\n",
    "**框架通用性**：\n",
    "- 该思考框架可适用于其他专业领域\n",
    "- 核心原则具有普遍适用性\n",
    "- 具体参数可根据领域特点调整\n",
    "\n",
    "**迭代优化机制**：\n",
    "- 建立数据质量监控体系\n",
    "- 设计A/B测试验证策略效果\n",
    "- 根据实际效果调整策略参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d135a141",
   "metadata": {},
   "source": [
    "## 六、结论\n",
    "\n",
    "### 6.1 核心决策\n",
    "基于系统性分析，推荐采用以下策略：\n",
    "1. **数据来源**：混合策略（30%复用SFT + 70%重新生成）\n",
    "2. **偏好构建**：5层质量分级，生成10对偏好数据\n",
    "3. **质量控制**：建立多维度评估标准和人工验证机制\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661c891b",
   "metadata": {},
   "source": [
    "# 2. 数据集构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f6bcbf",
   "metadata": {},
   "source": [
    "## 项目核心思路与想法\n",
    "\n",
    "### **核心思路**\n",
    "项目的核心想法是：**通过生成不同质量等级的答案对，让奖励模型学会区分好答案和差答案**\n",
    "\n",
    "- **输入**：英文金融文章 + 已有SFT对话数据\n",
    "- **输出**：包含5个不同质量等级答案的完整训练数据集\n",
    "- **目标**：训练一个能够准确评判金融领域回答质量的奖励模型\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15da3a",
   "metadata": {},
   "source": [
    "## 一、项目架构设计\n",
    "\n",
    "###  **reward_model_data/** - 项目根目录\n",
    "\n",
    "####  **核心程序文件**\n",
    "1. `main.py` - 项目主程序入口\n",
    "   - 作用：协调整个数据生成流程的执行\n",
    "   - 功能：问题生成 → 答案生成 → 数据拆分\n",
    "\n",
    "2. `config.py` - 配置管理中心  \n",
    "   - 作用：统一管理所有配置参数\n",
    "   - 功能：API设置、文件路径、生成参数、质量等级定义\n",
    "\n",
    "####  **功能模块文件**\n",
    "3. `question_generator.py` - 问题生成引擎\n",
    "   - 作用：从英文金融文章生成中文问题\n",
    "   - 功能：文章分析、问题生成、并发处理\n",
    "\n",
    "4. `answer_generator.py` - 答案生成引擎\n",
    "   - 作用：为每个问题生成5个不同质量等级的答案\n",
    "   - 功能：多质量答案生成、偏好对构建、批处理保存\n",
    "\n",
    "5. `data_processor.py` - 数据处理中心\n",
    "   - 作用：处理SFT数据和文章数据\n",
    "   - 功能：数据加载、问题提取、采样混合\n",
    "\n",
    "6. `data_splitter.py` - 数据集分割器\n",
    "   - 作用：将数据分割为训练/验证/测试集\n",
    "   - 功能：数据分割、格式转换、统计报告\n",
    "\n",
    "7. `utils.py` - 工具函数库\n",
    "   - 作用：提供通用的基础功能\n",
    "   - 功能：文件操作、数据采样、日志管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e37043",
   "metadata": {},
   "source": [
    "###  **项目工作流程**\n",
    "\n",
    "1. **问题生成阶段** (`question_generator.py`)\n",
    "   - 从SFT数据提取已有问题（30%）\n",
    "   - 从金融文章生成新问题（70%）\n",
    "   - 混合并保存所有问题\n",
    "\n",
    "2. **答案生成阶段** (`answer_generator.py`)  \n",
    "   - 为每个问题生成5个不同质量的答案\n",
    "   - 质量等级：1分（差）→ 5分（好）\n",
    "   - 批量保存，合并最终数据\n",
    "\n",
    "3. **数据拆分阶段** (`data_splitter.py`)\n",
    "   - 按8:1:1分割为训练/验证/测试集\n",
    "   - 转换为偏好对格式（用于奖励模型训练）\n",
    "   - 生成详细统计报告"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8682a1",
   "metadata": {},
   "source": [
    "## 二、项目核心\n",
    "\n",
    "### 1. 多质量等级答案生成体系\n",
    "```python\n",
    "QUALITY_LEVELS = {\n",
    "    1: \"低质量答案 - 逻辑混乱，信息不准确\",\n",
    "    2: \"中低质量答案 - 基本正确但分析不够深入\", \n",
    "    3: \"中等质量答案 - 正确但不够全面\",\n",
    "    4: \"中高质量答案 - 专业且全面\",\n",
    "    5: \"高质量答案 - 专业、全面、深入\"\n",
    "}\n",
    "```\n",
    "**重点**：为每个问题生成5个不同质量等级的答案，构建完整的质量梯度\n",
    "\n",
    "### 2. 双层并发处理架构\n",
    "```\n",
    "总并发控制\n",
    "├── 问题级别并发 (同时处理多个问题)\n",
    "│   └── 答案级别并发 (每个问题同时生成5个答案)\n",
    "│       └── API级别调用 (每个答案一次API调用)\n",
    "```\n",
    "**重点**：智能并发控制，最大化API利用率，显著提升生成效率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e103d",
   "metadata": {},
   "source": [
    "### 3. 数据来源混合策略\n",
    "- **30% SFT数据**：从已有高质量对话数据中提取问题\n",
    "- **70% 新生成**：从英文金融文章生成中文问题\n",
    "- **均匀混合**：确保数据多样性和质量平衡\n",
    "\n",
    "### 4. 完整的数据处理流水线\n",
    "- **输入验证** → **数据加载** → **问题生成** → **答案生成** → **数据拆分** → **格式转换**\n",
    "- 每个环节都有错误处理和质量控制\n",
    "\n",
    "### 5. 科学的数据拆分\n",
    "- **训练集80%** + **验证集10%** + **测试集10%**\n",
    "- 自动生成偏好对格式，直接用于奖励模型训练\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65922714",
   "metadata": {},
   "source": [
    "## 三、项目运行流程\n",
    "\n",
    "### 阶段一：问题生成 (Questions Generation)\n",
    "```json\n",
    "1. 加载SFT数据 → 提取用户问题 → 随机采样30%\n",
    "2. 加载金融文章 → AI分析提取关键信息 → 生成中文问题70%  \n",
    "3. 混合两种问题 → 打乱顺序 → 保存questions.jsonl\n",
    "```\n",
    "**核心逻辑**：从多个数据源获取问题，确保问题的多样性和专业性\n",
    "\n",
    "### 阶段二：答案生成 (Answers Generation)\n",
    "```json\n",
    "读取questions.jsonl\n",
    "    ↓\n",
    "并发处理每个问题 (问题级别并发)\n",
    "    ↓\n",
    "为每个问题并发生成5个不同质量答案 (答案级别并发)\n",
    "    ↓\n",
    "批量保存 → 合并为complete_qa_dataset.jsonl\n",
    "```\n",
    "**核心逻辑**：使用双层并发，高效生成多质量等级答案\n",
    "\n",
    "### 阶段三：数据拆分 (Data Splitting)\n",
    "```json\n",
    "加载complete_qa_dataset.jsonl\n",
    "    ↓\n",
    "随机打乱 → 按8:1:1比例分割\n",
    "    ↓\n",
    "转换为偏好对格式 → 保存到train/eval/test目录\n",
    "    ↓\n",
    "生成统计报告\n",
    "```\n",
    "**核心逻辑**：科学分割数据，转换为标准训练格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27502cd",
   "metadata": {},
   "source": [
    "## 四、使用方式\n",
    "\n",
    "### **完整流程执行**\n",
    "```bash\n",
    "# 执行所有阶段\n",
    "python main.py \\\n",
    "    --stage all \\\n",
    "    --sft_data_path \"./data/sft/deepspeek_sft_dataset_1w.jsonl,./data/sft/deepspeek_sft_dataset_5k.jsonl\" \\\n",
    "    --base_articles_path \"./data/base_data/filtered_financial_news_5k.jsonl\" \\\n",
    "    --total_questions 4500 \\\n",
    "    --sft_ratio 0.3 \\\n",
    "    --concurrency_num 100 \\\n",
    "    --output_dir \"./reward_data\"\n",
    "\n",
    "nohup python main.py \\\n",
    "    --stage all \\\n",
    "    --sft_data_path \"./data/sft/deepspeek_sft_dataset_1w.jsonl,./data/sft/deepspeek_sft_dataset_5k.jsonl\" \\\n",
    "    --base_articles_path \"./data/base_data/filtered_financial_news_5k.jsonl\" \\\n",
    "    --total_questions 4500 \\\n",
    "    --sft_ratio 0.3 \\\n",
    "    --concurrency_num 100 \\\n",
    "    --output_dir \"./reward_data\" > data.log 2>&1 &\n",
    "```\n",
    "\n",
    "### **分阶段执行**\n",
    "```bash\n",
    "# 只生成问题\n",
    "python main.py \\\n",
    "    --stage questions \\\n",
    "    --sft_data_path \"./data/sft/deepspeek_sft_dataset_1w.jsonl,./data/sft/deepspeek_sft_dataset_5k.jsonl\" \\\n",
    "    --base_articles_path \"./data/base_data/filtered_financial_news_5k.jsonl\" \\\n",
    "    --total_questions 3000 \\\n",
    "    --sft_ratio 0.3 \\\n",
    "    --concurrency_num 100 \\\n",
    "    --output_dir \"./reward_data\"\n",
    "\n",
    "# 只生成答案\n",
    "python main.py \\\n",
    "    --stage answers \\\n",
    "    --max_questions 5 \\\n",
    "    --concurrency_num 2 \\\n",
    "    --output_dir \"./reward_data\"\n",
    "    \n",
    "# 只拆分数据\n",
    "python data_splitter.py --input-dir ./reward_data --output-dir ./final_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a419aa8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172709154.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6ff4e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620174606651.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2418d51",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172731281.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f86223",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172749341.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab97214",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172806556.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92209ff7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172832435.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5142e1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620172854279.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990120c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b7d295",
   "metadata": {},
   "source": [
    "##  数据结构\n",
    "\n",
    "####  **数据目录结构**\n",
    "\n",
    "```json\n",
    "data/\n",
    "├── base_data/          # 基础数据（金融文章）\n",
    "├── sft/               # SFT训练数据\n",
    "└── train_dataset.jsonl\n",
    "\n",
    "reward_data/           # 生成的奖励模型数据\n",
    "├── answers/          # 批次答案文件\n",
    "├── train/           # 训练集\n",
    "├── eval/            # 验证集  \n",
    "├── test/            # 测试集\n",
    "├── questions.jsonl  # 生成的问题\n",
    "├── complete_qa_dataset.jsonl  # 完整问答数据\n",
    "└── generation_report.json     # 生成报告\n",
    "```\n",
    "\n",
    "### **偏好对数据格式示例**\n",
    "```json\n",
    "{\n",
    "  \"question_id\": 1,\n",
    "  \"question\": \"根据财报显示，某公司Q3营收增长15%，但净利润下降3%...\",\n",
    "  \"chosen\": \"高质量答案内容\",\n",
    "  \"rejected\": \"低质量答案内容\", \n",
    "  \"chosen_level\": 5,\n",
    "  \"rejected_level\": 2,\n",
    "  \"quality_gap\": 3\n",
    "}\n",
    "```\n",
    "\n",
    "## 技术要点\n",
    "\n",
    "### **1. 错误恢复机制**\n",
    "- 批量保存避免数据丢失\n",
    "- API调用失败自动记录和跳过\n",
    "- 支持断点续传\n",
    "\n",
    "### **2. 质量控制体系**\n",
    "- 答案格式验证（必须包含<think>标签）\n",
    "- 文件存在性检查\n",
    "- 数据完整性验证\n",
    "\n",
    "### **3. 性能优化**\n",
    "- 智能并发控制\n",
    "- 内存友好的批处理\n",
    "- API请求频率控制\n",
    "\n",
    "### **4. 可重现性保证**\n",
    "- 固定随机种子\n",
    "- 详细的操作日志\n",
    "- 完整的统计报告\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45299da8",
   "metadata": {},
   "source": [
    "## 五、具体代码："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66810dd",
   "metadata": {},
   "source": [
    " `utils.py` - 工具函数库\n",
    "   - 作用：提供通用的基础功能\n",
    "   - 功能：文件操作、数据采样、日志管理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34adf971",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "工具函数模块 - 简化版本\n",
    "包含数据处理、文件操作等基础功能\n",
    "\n",
    "【作用】\n",
    "这个模块是整个项目的\"工具箱\"，提供各种通用的基础功能：\n",
    "1. 文件操作：读取、保存、目录管理\n",
    "2. 数据处理：采样、混合、格式转换\n",
    "3. 日志管理：统一的日志配置\n",
    "4. 路径验证：确保文件存在性\n",
    "\n",
    "【为什么需要工具模块】\n",
    "- 避免代码重复：多个模块都需要相同的基础功能\n",
    "- 统一标准：确保所有模块使用相同的文件操作方式\n",
    "- 便于维护：修改基础功能时只需改一个地方\n",
    "- 提高可靠性：经过测试的通用函数更稳定\n",
    "\n",
    "【在整体程序中的作用】\n",
    "- 为所有其他模块提供基础服务\n",
    "- 确保文件操作的一致性和安全性\n",
    "- 提供数据处理的标准方法\n",
    "- 统一错误处理和日志记录\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_logging(log_level: str = \"INFO\") -> None:\n",
    "    \"\"\"\n",
    "    设置日志配置\n",
    "    \n",
    "    【作用】\n",
    "    为整个程序配置统一的日志系统：\n",
    "    1. 设置日志级别（控制显示哪些信息）\n",
    "    2. 设置日志格式（时间、级别、消息）\n",
    "    3. 确保所有模块使用相同的日志标准\n",
    "    \n",
    "    【日志级别说明】\n",
    "    - DEBUG: 最详细，包含调试信息\n",
    "    - INFO: 一般信息，程序正常运行状态\n",
    "    - WARNING: 警告信息，可能有问题但不影响运行\n",
    "    - ERROR: 错误信息，程序出现问题\n",
    "    \n",
    "    【为什么要统一日志】\n",
    "    - 便于问题诊断：所有信息格式一致\n",
    "    - 控制信息量：可以调整显示的详细程度\n",
    "    - 便于监控：程序运行状态一目了然\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 程序启动时的第一步配置\n",
    "    - 为所有模块提供统一的日志接口\n",
    "    - 帮助用户了解程序运行状态\n",
    "    \n",
    "    Args:\n",
    "        log_level: 日志级别 (DEBUG, INFO, WARNING, ERROR)\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=getattr(logging, log_level.upper()),  # 将字符串转换为日志级别常量\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',  # 格式：时间 - 级别 - 消息\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'  # 时间格式：年-月-日 时:分:秒\n",
    "    )\n",
    "\n",
    "def ensure_directory_exists(directory_path) -> None:\n",
    "    \"\"\"\n",
    "    确保目录存在，如果不存在则创建\n",
    "    \n",
    "    【作用】\n",
    "    这是一个安全的目录创建函数：\n",
    "    1. 检查目录是否已经存在\n",
    "    2. 如果不存在，创建目录（包括所有父目录）\n",
    "    3. 如果已存在，什么都不做\n",
    "    4. 处理权限和其他创建错误\n",
    "    \n",
    "    【为什么需要这个函数】\n",
    "    程序运行时经常需要保存文件到指定目录，\n",
    "    但目录可能不存在，直接保存会出错。\n",
    "    这个函数确保目录一定存在。\n",
    "    \n",
    "    【Path.mkdir()参数说明】\n",
    "    - parents=True: 如果父目录不存在，也会创建\n",
    "    - exist_ok=True: 如果目录已存在，不会报错\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 在保存任何文件之前确保目录存在\n",
    "    - 避免因目录不存在导致的文件保存失败\n",
    "    - 提供统一的目录管理方式\n",
    "    \n",
    "    Args:\n",
    "        directory_path: 目录路径（可以是字符串或Path对象）\n",
    "    \"\"\"\n",
    "    path = Path(directory_path)  # 转换为Path对象，统一处理\n",
    "    path.mkdir(parents=True, exist_ok=True)  # 创建目录，包括父目录\n",
    "\n",
    "def load_jsonl_file(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    读取JSONL格式文件\n",
    "    \n",
    "    【作用】\n",
    "    JSONL（JSON Lines）是一种常用的数据格式，每行一个JSON对象。\n",
    "    这个函数负责：\n",
    "    1. 打开并读取JSONL文件\n",
    "    2. 逐行解析JSON数据\n",
    "    3. 处理格式错误和文件错误\n",
    "    4. 返回所有数据的列表\n",
    "    \n",
    "    【什么是JSONL格式】\n",
    "    每行都是一个完整的JSON对象，例如：\n",
    "    {\"id\": 1, \"question\": \"问题1\"}\n",
    "    {\"id\": 2, \"question\": \"问题2\"}\n",
    "    {\"id\": 3, \"question\": \"问题3\"}\n",
    "    \n",
    "    【为什么使用JSONL】\n",
    "    - 流式处理：可以逐行读取，不需要一次性加载整个文件\n",
    "    - 容错性好：某行出错不影响其他行\n",
    "    - 易于追加：可以直接在文件末尾添加新数据\n",
    "    - 工具支持：很多数据处理工具支持JSONL格式\n",
    "    \n",
    "    【错误处理策略】\n",
    "    - 文件不存在：抛出异常，程序停止\n",
    "    - JSON格式错误：记录警告，跳过错误行，继续处理\n",
    "    - 空行：自动跳过\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 为所有模块提供统一的文件读取接口\n",
    "    - 确保数据加载的一致性和可靠性\n",
    "    - 处理各种异常情况，提高程序稳定性\n",
    "    \n",
    "    Args:\n",
    "        file_path: 文件路径\n",
    "        \n",
    "    Returns:\n",
    "        包含所有数据行的列表\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):  # enumerate从1开始，方便报告行号\n",
    "                line = line.strip()  # 去除首尾空白字符\n",
    "                if line:  # 跳过空行\n",
    "                    try:\n",
    "                        # 解析JSON数据\n",
    "                        json_data = json.loads(line)\n",
    "                        data.append(json_data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        # JSON格式错误时记录警告但继续处理\n",
    "                        logging.warning(f\"第{line_num}行JSON解析失败: {e}\")\n",
    "                        continue\n",
    "        logging.info(f\"成功读取 {len(data)} 条数据从 {file_path}\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"文件不存在: {file_path}\")\n",
    "        raise  # 重新抛出异常，让调用者处理\n",
    "    except Exception as e:\n",
    "        logging.error(f\"读取文件失败 {file_path}: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_jsonl_file(data: List[Dict[str, Any]], file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    保存数据到JSONL格式文件\n",
    "    \n",
    "    【作用】\n",
    "    将Python数据结构保存为JSONL格式文件：\n",
    "    1. 确保输出目录存在\n",
    "    2. 将每个数据项转换为JSON字符串\n",
    "    3. 每行写入一个JSON对象\n",
    "    4. 处理编码和写入错误\n",
    "    \n",
    "    【保存格式】\n",
    "    每个列表项会转换为一行JSON：\n",
    "    [{\"id\": 1, \"text\": \"数据1\"}, {\"id\": 2, \"text\": \"数据2\"}]\n",
    "    保存为：\n",
    "    {\"id\": 1, \"text\": \"数据1\"}\n",
    "    {\"id\": 2, \"text\": \"数据2\"}\n",
    "    \n",
    "    【编码说明】\n",
    "    - encoding='utf-8': 支持中文字符\n",
    "    - ensure_ascii=False: 保持中文字符不转义\n",
    "    \n",
    "    【错误处理】\n",
    "    - 目录不存在：自动创建\n",
    "    - 权限不足：抛出异常\n",
    "    - 磁盘空间不足：抛出异常\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 为所有模块提供统一的文件保存接口\n",
    "    - 确保保存格式的一致性\n",
    "    - 处理文件保存的各种异常情况\n",
    "    \n",
    "    Args:\n",
    "        data: 要保存的数据列表\n",
    "        file_path: 输出文件路径\n",
    "    \"\"\"\n",
    "    # 确保输出目录存在\n",
    "    # 【预防性处理】在保存文件前确保目录存在\n",
    "    ensure_directory_exists(Path(file_path).parent)\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            for item in data:\n",
    "                # 将每个数据项转换为JSON字符串并写入\n",
    "                json_line = json.dumps(item, ensure_ascii=False)\n",
    "                f.write(json_line + '\\n')  # 每行一个JSON对象\n",
    "        logging.info(f\"成功保存 {len(data)} 条数据到 {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"保存文件失败 {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def random_sample_with_seed(data: List[Any], sample_size: int, seed: int = 42) -> List[Any]:\n",
    "    \"\"\"\n",
    "    使用固定随机种子进行随机采样\n",
    "    \n",
    "    【作用】\n",
    "    从大量数据中随机选择指定数量的样本：\n",
    "    1. 设置固定的随机种子，确保结果可重现\n",
    "    2. 使用Python的random.sample进行无重复采样\n",
    "    3. 处理采样数量超过数据总量的情况\n",
    "    4. 返回采样后的数据列表\n",
    "    \n",
    "    【什么是随机采样】\n",
    "    从N个数据中随机选择M个，每个数据被选中的概率相等，\n",
    "    且选中的数据不会重复。\n",
    "    \n",
    "    【为什么要固定随机种子】\n",
    "    - 可重现性：相同种子产生相同结果\n",
    "    - 调试方便：每次运行结果一致，便于定位问题\n",
    "    - 实验控制：确保对比实验的公平性\n",
    "    \n",
    "    【边界情况处理】\n",
    "    如果需要采样的数量大于等于数据总量，直接返回所有数据的副本\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 为数据处理器提供标准的采样方法\n",
    "    - 确保采样结果的可重现性\n",
    "    - 控制数据处理的规模，避免处理过多数据\n",
    "    \n",
    "    Args:\n",
    "        data: 原始数据列表\n",
    "        sample_size: 采样数量\n",
    "        seed: 随机种子\n",
    "        \n",
    "    Returns:\n",
    "        采样后的数据列表\n",
    "    \"\"\"\n",
    "    if sample_size >= len(data):\n",
    "        logging.warning(f\"采样数量({sample_size})大于等于数据总量({len(data)})，返回全部数据\")\n",
    "        return data.copy()  # 返回副本，避免修改原始数据\n",
    "    \n",
    "    # 设置随机种子确保结果可复现\n",
    "    # 【临时设置种子】只影响这次采样，不影响其他随机操作\n",
    "    random.seed(seed)\n",
    "    sampled_data = random.sample(data, sample_size)\n",
    "    \n",
    "    logging.info(f\"从 {len(data)} 条数据中采样了 {len(sampled_data)} 条\")\n",
    "    return sampled_data\n",
    "\n",
    "def mix_data_evenly(data_list1: List[Any], data_list2: List[Any], seed: int = 42) -> List[Any]:\n",
    "    \"\"\"\n",
    "    将两个数据列表均匀混合\n",
    "    \n",
    "    【作用】\n",
    "    将两个不同来源的数据列表合并并打乱：\n",
    "    1. 将两个列表合并成一个\n",
    "    2. 使用固定种子随机打乱顺序\n",
    "    3. 确保两种数据类型分布均匀\n",
    "    4. 返回混合后的数据列表\n",
    "    \n",
    "    【为什么要均匀混合】\n",
    "    如果两个列表分别代表不同类型的数据（如SFT问题和生成问题），\n",
    "    简单拼接会导致数据分布不均匀，影响后续处理效果。\n",
    "    随机混合确保数据分布更加均匀。\n",
    "    \n",
    "    【混合策略】\n",
    "    1. 先合并：[A数据] + [B数据] = [所有数据]\n",
    "    2. 再打乱：随机重新排列顺序\n",
    "    3. 使用固定种子确保结果可重现\n",
    "    \n",
    "    【使用场景】\n",
    "    - 合并SFT问题和新生成的问题\n",
    "    - 混合不同来源的训练数据\n",
    "    - 打乱数据顺序，避免顺序偏差\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 为数据处理器提供数据混合功能\n",
    "    - 确保最终数据集的多样性\n",
    "    - 避免数据来源的顺序偏差\n",
    "    \n",
    "    Args:\n",
    "        data_list1: 第一个数据列表\n",
    "        data_list2: 第二个数据列表\n",
    "        seed: 随机种子\n",
    "        \n",
    "    Returns:\n",
    "        混合后的数据列表\n",
    "    \"\"\"\n",
    "    # 合并两个列表\n",
    "    # 【列表拼接】使用+操作符合并列表\n",
    "    combined_data = data_list1 + data_list2\n",
    "    \n",
    "    # 使用固定种子打乱顺序\n",
    "    # 【就地打乱】shuffle会直接修改列表顺序\n",
    "    random.seed(seed)\n",
    "    random.shuffle(combined_data)\n",
    "    \n",
    "    logging.info(f\"混合了 {len(data_list1)} + {len(data_list2)} = {len(combined_data)} 条数据\")\n",
    "    return combined_data\n",
    "\n",
    "def validate_file_paths(file_paths: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    验证文件路径是否存在\n",
    "    \n",
    "    【作用】\n",
    "    批量检查文件是否存在，过滤出有效的文件路径：\n",
    "    1. 遍历所有提供的文件路径\n",
    "    2. 检查每个文件是否真实存在\n",
    "    3. 记录检查结果（存在/不存在）\n",
    "    4. 返回所有存在的文件路径列表\n",
    "    \n",
    "    【为什么要验证文件路径】\n",
    "    - 早期发现问题：在程序开始处理前就发现文件缺失\n",
    "    - 避免运行时错误：防止程序运行到一半才发现文件不存在\n",
    "    - 提供清晰反馈：告诉用户哪些文件存在，哪些不存在\n",
    "    \n",
    "    【处理策略】\n",
    "    - 存在的文件：记录信息，加入有效列表\n",
    "    - 不存在的文件：记录警告，跳过该文件\n",
    "    - 返回所有有效文件的列表\n",
    "    \n",
    "    【使用场景】\n",
    "    - 程序启动时验证输入文件\n",
    "    - 批量处理前的文件检查\n",
    "    - 配置验证和错误预防\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 为所有模块提供文件存在性检查\n",
    "    - 提高程序的健壮性和用户体验\n",
    "    - 避免因文件不存在导致的程序崩溃\n",
    "    \n",
    "    Args:\n",
    "        file_paths: 文件路径列表\n",
    "        \n",
    "    Returns:\n",
    "        存在的文件路径列表\n",
    "    \"\"\"\n",
    "    valid_paths = []\n",
    "    for path in file_paths:\n",
    "        if Path(path).exists():  # 使用Path对象检查文件存在性\n",
    "            valid_paths.append(path)\n",
    "            logging.info(f\"文件存在: {path}\")\n",
    "        else:\n",
    "            logging.warning(f\"文件不存在: {path}\")\n",
    "    \n",
    "    return valid_paths \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3e438",
   "metadata": {},
   "source": [
    " `question_generator.py` - 问题生成引擎\n",
    "   - 作用：从英文金融文章生成中文问题\n",
    "   - 功能：文章分析、问题生成、并发处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab32daa",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "问题生成模块\n",
    "负责从基础文章生成金融领域的专业问题\n",
    "\"\"\"\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import openai\n",
    "import threading\n",
    "import concurrent.futures\n",
    "import os\n",
    "from typing import List, Dict\n",
    "from utils import save_jsonl_file\n",
    "\n",
    "class QuestionGenerator:\n",
    "    \"\"\"问题生成器类，负责从文章生成问题\"\"\"\n",
    "    \n",
    "    def __init__(self, config, output_dir: str = None, concurrency_level: int = None):\n",
    "        \"\"\"\n",
    "        初始化问题生成器\n",
    "        \n",
    "        参数:\n",
    "            config: 配置对象\n",
    "            output_dir: 输出目录路径，如果不指定则使用配置中的默认值\n",
    "            concurrency_level: 并发级别，控制同时处理的文章数量\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.output_dir = output_dir or config.output_dir\n",
    "        \n",
    "        # 并发控制参数 - 统一使用concurrency_num\n",
    "        self.concurrency_level = concurrency_level or getattr(config, 'CONCURRENCY_NUM', 3)\n",
    "        \n",
    "        # 初始化OpenAI客户端（用于调用DeepSeek API）\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=config.api_key,\n",
    "            base_url=config.base_url\n",
    "        )\n",
    "        \n",
    "        # 线程锁，用于多线程环境下的安全操作\n",
    "        self.print_lock = threading.Lock()    # 保护打印输出\n",
    "        self.output_lock = threading.Lock()   # 保护文件写入\n",
    "    \n",
    "    def truncate_text(self, text: str, max_length: int = 5000) -> str:\n",
    "        \"\"\"\n",
    "        截断文本以满足API长度限制\n",
    "        \n",
    "        API通常对输入文本长度有限制，过长的文本会导致请求失败\n",
    "        \n",
    "        参数:\n",
    "            text: 需要截断的文本\n",
    "            max_length: 最大允许长度\n",
    "        \n",
    "        返回:\n",
    "            截断后的文本\n",
    "        \"\"\"\n",
    "        if len(text) <= max_length:\n",
    "            return text\n",
    "        return text[:max_length]\n",
    "    \n",
    "    def generate_question_from_article(self, article_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        从单篇文章生成问题\n",
    "        \n",
    "        这个函数的核心作用：\n",
    "        1. 分析英文金融文章的内容\n",
    "        2. 提取关键信息和数据\n",
    "        3. 生成包含详细背景信息的中文问题\n",
    "        4. 确保问题包含足够信息支持后续回答\n",
    "        \n",
    "        参数:\n",
    "            article_data: 文章数据字典，包含article字段\n",
    "        \n",
    "        返回:\n",
    "            生成的问题数据，如果失败返回None\n",
    "        \"\"\"\n",
    "        # 提取文章内容\n",
    "        article_content = article_data.get('Article', '')\n",
    "        if not article_content:\n",
    "            return None\n",
    "        \n",
    "        # 截断文章以满足API限制\n",
    "        article_truncated = self.truncate_text(article_content)\n",
    "        \n",
    "        # 构建提示词\n",
    "        # 这个提示词的设计非常重要，它决定了生成问题的质量\n",
    "        prompt = f\"\"\"\n",
    "请基于以下英文金融文章，创建一个详细的中文金融问题。\n",
    "\n",
    "英文文章:\n",
    "{article_truncated}\n",
    "\n",
    "请完成以下任务:\n",
    "1. 从文章中提取关键信息、数据、事实和核心观点\n",
    "2. 创建一个针对这些关键信息的专业金融领域问题\n",
    "3. 问题必须包含足够详细的背景信息和事实，确保仅凭问题本身就能够推导出合理的回答\n",
    "\n",
    "输出格式必须是有效的JSON，结构如下:\n",
    "{{\n",
    "  \"question\": \"这里是包含详细背景信息的专业金融问题\"\n",
    "}}\n",
    "\n",
    "要求:\n",
    "- 问题必须具体且深入，能够引导出金融专业领域的分析\n",
    "- 必须包含足够丰富的事实信息，使第三方仅通过阅读问题就能回答\n",
    "- 禁止出现\"本文\"、\"文章\"、\"整体基调\"、\"情绪\"等字样\n",
    "- 禁止对文章本身进行评价或总结\n",
    "- 直接以陈述事实的方式提供背景信息\n",
    "- 问题应以客观的方式呈现数据和事实，避免主观评价\n",
    "- 问题要以自然、符合实际提问习惯的方式表达\n",
    "- 问题内容要特别详细，包含文章中所有能够支持回答问题的关键信息\n",
    "- 问题应该能够支撑生成带有思考过程的详细回答\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 调用API生成问题\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.model_name,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"你是一个专业的金融数据分析助手，精通英文金融文章翻译和问题构建。你的任务是创建包含充分背景信息的专业金融问题，这些问题需要能够支撑后续生成详细的分析回答。\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                stream=False,\n",
    "                temperature=self.config.temperature\n",
    "            )\n",
    "            \n",
    "            # 解析API响应\n",
    "            result = response.choices[0].message.content\n",
    "            \n",
    "            # 提取JSON格式的数据\n",
    "            json_start = result.find('{')\n",
    "            json_end = result.rfind('}') + 1\n",
    "            \n",
    "            if json_start != -1 and json_end != -1:\n",
    "                json_str = result[json_start:json_end]\n",
    "                data = json.loads(json_str)\n",
    "                \n",
    "                # 验证返回的数据\n",
    "                if \"question\" in data and data[\"question\"].strip():\n",
    "                    return {\n",
    "                        \"question\": data[\"question\"],\n",
    "                        \"source\": \"generated_from_article\",\n",
    "                        \"original_article_index\": article_data.get('original_index', -1)\n",
    "                    }\n",
    "                else:\n",
    "                    print(\"警告: 返回的JSON缺少question字段或内容为空\")\n",
    "                    return None\n",
    "            else:\n",
    "                print(\"无法在响应中找到有效的JSON\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"生成问题时出错: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_single_article(self, args):\n",
    "        \"\"\"\n",
    "        处理单篇文章的包装函数\n",
    "        \n",
    "        这个函数专门用于并行处理，它：\n",
    "        1. 解包参数\n",
    "        2. 调用问题生成函数\n",
    "        3. 将结果写入文件\n",
    "        4. 返回处理状态\n",
    "        \n",
    "        参数:\n",
    "            args: 包含(article_data, index, total, output_file)的元组\n",
    "        \n",
    "        返回:\n",
    "            True表示处理成功，False表示失败\n",
    "        \"\"\"\n",
    "        # 解包参数\n",
    "        article_data, index, total, output_file = args\n",
    "        \n",
    "        # 显示处理进度（使用线程锁确保输出不混乱）\n",
    "        with self.print_lock:\n",
    "            print(f\"处理文章 {index+1}/{total}\")\n",
    "        \n",
    "        # 添加随机延迟，避免API请求过于集中\n",
    "        time.sleep(random.uniform(0, self.config.request_interval))\n",
    "        \n",
    "        # 生成问题\n",
    "        question_result = self.generate_question_from_article(article_data)\n",
    "        \n",
    "        if question_result:\n",
    "            # 使用文件写入锁，确保多线程写入安全\n",
    "            with self.output_lock:\n",
    "                with open(output_file, 'a', encoding='utf-8') as f:\n",
    "                    f.write(json.dumps(question_result, ensure_ascii=False) + '\\n')\n",
    "            return True\n",
    "        else:\n",
    "            with self.print_lock:\n",
    "                print(f\"文章 {index+1}/{total}: 问题生成失败\")\n",
    "            return False\n",
    "    \n",
    "    def generate_questions_from_articles(self, articles: List[Dict]) -> List[str]:\n",
    "        \"\"\"\n",
    "        从文章列表批量生成问题\n",
    "        \n",
    "        这个函数使用多线程并行处理，大大提高生成效率\n",
    "        \n",
    "        参数:\n",
    "            articles: 文章数据列表\n",
    "        \n",
    "        返回:\n",
    "            生成的问题列表\n",
    "        \"\"\"\n",
    "        print(f\"=== 开始从 {len(articles)} 篇文章生成问题 ===\")\n",
    "        print(f\"📊 并发设置: 文章级别并发数={self.concurrency_level}\")\n",
    "        \n",
    "        # 准备输出文件\n",
    "        output_file = os.path.join(self.output_dir, 'generated_questions.jsonl')\n",
    "        \n",
    "        # 清空输出文件\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            pass\n",
    "        \n",
    "        # 准备并行处理的参数\n",
    "        args_list = [\n",
    "            (article, i, len(articles), output_file) \n",
    "            for i, article in enumerate(articles)\n",
    "        ]\n",
    "        \n",
    "        # 使用线程池并行处理 - 使用统一的并发控制\n",
    "        success_count = 0\n",
    "        print(f\"开始并行处理，并发线程数: {self.concurrency_level}\")\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.concurrency_level) as executor:\n",
    "            # 并行执行所有任务\n",
    "            results = list(executor.map(self.process_single_article, args_list))\n",
    "            # 统计成功数量\n",
    "            success_count = sum(1 for r in results if r)\n",
    "        \n",
    "        # 加载生成的问题\n",
    "        generated_questions = []\n",
    "        if os.path.exists(output_file):\n",
    "            with open(output_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        question_data = json.loads(line.strip())\n",
    "                        generated_questions.append(question_data['question'])\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "        \n",
    "        print(f\"=== 问题生成完成 ===\")\n",
    "        print(f\"处理结果:\")\n",
    "        print(f\"  - 成功生成: {success_count}/{len(articles)} 个问题\")\n",
    "        print(f\"  - 实际保存: {len(generated_questions)} 个问题\")\n",
    "        print(f\"  - 保存位置: {output_file}\")\n",
    "        \n",
    "        return generated_questions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaba54f4",
   "metadata": {},
   "source": [
    " `answer_generator.py` - 答案生成引擎\n",
    "   - 作用：为每个问题生成5个不同质量等级的答案\n",
    "   - 功能：多质量答案生成、偏好对构建、批处理保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaa50d2",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "金融领域奖励模型数据生成 - 答案生成器（优化版）\n",
    "支持可控的并发处理，提高生成效率\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "\n",
    "class AnswerGenerator:\n",
    "    \"\"\"答案生成器类 - 支持可控并发\"\"\"\n",
    "    \n",
    "    def __init__(self, config, output_dir: str = None, concurrency_level: int = None):\n",
    "        \"\"\"\n",
    "        初始化答案生成器\n",
    "        \n",
    "        Args:\n",
    "            config: 配置对象，包含API设置和质量等级定义\n",
    "            output_dir: 输出目录路径，如果不指定则使用配置中的默认值\n",
    "            concurrency_level: 总并发级别，控制同时进行的API调用数量\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.output_dir = Path(output_dir) if output_dir else Path(config.OUTPUT_DIR)\n",
    "        \n",
    "        # 创建answers子目录用于存储批次文件\n",
    "        self.answers_dir = self.output_dir / \"answers\"\n",
    "        self.answers_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 并发控制参数计算\n",
    "        # 总并发数：同时进行的API调用数量\n",
    "        total_concurrency = concurrency_level or getattr(config, 'CONCURRENCY_NUM', 15)\n",
    "        \n",
    "        # 答案级别的并发数：每个问题同时生成多少个答案（固定为5）\n",
    "        self.answer_concurrency = 5\n",
    "        \n",
    "        # 问题级别的并发数：同时处理多少个问题\n",
    "        # 计算公式：总并发数 / 每个问题的答案数 = 问题级别并发数\n",
    "        self.question_concurrency = max(1, total_concurrency // self.answer_concurrency)\n",
    "        \n",
    "        # 线程安全的锁\n",
    "        self.print_lock = threading.Lock()  # 用于安全打印\n",
    "        self.file_lock = threading.Lock()   # 用于安全文件操作\n",
    "        self.stats_lock = threading.Lock()  # 用于安全统计更新\n",
    "        \n",
    "        # 初始化OpenAI客户端\n",
    "        self.client = openai.OpenAI(\n",
    "            api_key=config.api_key,\n",
    "            base_url=config.base_url\n",
    "        )\n",
    "        \n",
    "        # 统计信息\n",
    "        self.stats = {\n",
    "            \"total_questions\": 0,\n",
    "            \"completed_questions\": 0,\n",
    "            \"total_api_calls\": 0,\n",
    "            \"successful_api_calls\": 0,\n",
    "            \"failed_api_calls\": 0,\n",
    "            \"start_time\": None,\n",
    "            \"end_time\": None\n",
    "        }\n",
    "        \n",
    "        # 打印并发控制设置\n",
    "        self.safe_print(f\"🔧 并发控制设置:\")\n",
    "        self.safe_print(f\"   - 总并发数: {total_concurrency}\")\n",
    "        self.safe_print(f\"   - 问题级别并发数: {self.question_concurrency}\")\n",
    "        self.safe_print(f\"   - 答案级别并发数: {self.answer_concurrency}\")\n",
    "        self.safe_print(f\"   - 实际同时API调用数: {self.question_concurrency * self.answer_concurrency}\")\n",
    "        \n",
    "    def safe_print(self, message: str):\n",
    "        \"\"\"线程安全的打印函数\"\"\"\n",
    "        with self.print_lock:\n",
    "            print(message)\n",
    "            \n",
    "    def update_stats(self, **kwargs):\n",
    "        \"\"\"线程安全的统计更新\"\"\"\n",
    "        with self.stats_lock:\n",
    "            for key, value in kwargs.items():\n",
    "                if key in self.stats:\n",
    "                    if isinstance(self.stats[key], int):\n",
    "                        self.stats[key] += value\n",
    "                    else:\n",
    "                        self.stats[key] = value\n",
    "\n",
    "    def generate_single_answer(self, question: str, quality_level: int, question_id: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        为单个问题生成指定质量等级的答案\n",
    "        \n",
    "        Args:\n",
    "            question: 问题内容\n",
    "            quality_level: 质量等级 (1-5)，数字越大质量越高\n",
    "            question_id: 问题ID，用于日志记录\n",
    "            \n",
    "        Returns:\n",
    "            包含答案内容和元数据的字典\n",
    "        \"\"\"\n",
    "        quality_info = self.config.QUALITY_LEVELS[quality_level]\n",
    "            \n",
    "        # 构建完整的提示词\n",
    "        full_prompt = f\"\"\"你是一个金融领域的专业分析师。\n",
    "\n",
    "{quality_info['instruction']}\n",
    "\n",
    "问题：{question}\n",
    "\n",
    "请按照以下格式回答：\n",
    "<think>\n",
    "[在这里写出你的思考过程，包括：\n",
    "1. 问题分析和理解\n",
    "2. 相关金融概念和理论\n",
    "3. 分析步骤和逻辑推理\n",
    "4. 结论推导过程]\n",
    "</think>\n",
    "\n",
    "[最终答案内容]\n",
    "\n",
    "注意：\n",
    "1. 必须使用<think>标签包裹思考过程\n",
    "2. 思考过程要体现金融专业知识和分析能力\n",
    "3. 最终答案要简洁明了且符合质量要求\n",
    "4. 确保答案质量符合{quality_info['name']}的标准\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 记录API调用\n",
    "            self.update_stats(total_api_calls=1)\n",
    "            \n",
    "            # 调用API生成答案\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.config.MODEL_NAME,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"你是一个专业的金融分析师，擅长提供不同质量等级的专业分析。\"},\n",
    "                    {\"role\": \"user\", \"content\": full_prompt}\n",
    "                ],\n",
    "                temperature=self.config.TEMPERATURE,\n",
    "                max_tokens=self.config.MAX_TOKENS\n",
    "            )\n",
    "            \n",
    "            answer_content = response.choices[0].message.content.strip()\n",
    "                \n",
    "            # 验证答案格式\n",
    "            if \"<think>\" not in answer_content or \"</think>\" not in answer_content:\n",
    "                self.safe_print(f\"⚠️  问题{question_id} 质量等级{quality_level}的答案缺少<think>标签\")  \n",
    "            \n",
    "            # 记录成功的API调用\n",
    "            self.update_stats(successful_api_calls=1)\n",
    "            \n",
    "            return {\n",
    "                \"quality_level\": quality_level,\n",
    "                \"quality_name\": quality_info[\"name\"],\n",
    "                \"quality_description\": quality_info[\"description\"],\n",
    "                \"content\": answer_content,\n",
    "                \"length\": len(answer_content),\n",
    "                \"has_think_tags\": \"<think>\" in answer_content and \"</think>\" in answer_content\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            # 记录失败的API调用\n",
    "            self.update_stats(failed_api_calls=1)\n",
    "            self.safe_print(f\"❌ 问题{question_id} 质量等级{quality_level}答案生成失败: {e}\")\n",
    "            \n",
    "            return {\n",
    "                \"quality_level\": quality_level,\n",
    "                \"quality_name\": quality_info[\"name\"],\n",
    "                \"quality_description\": quality_info[\"description\"],\n",
    "                \"content\": f\"生成失败: {str(e)}\",\n",
    "                \"error\": True,\n",
    "                \"error_message\": str(e)\n",
    "            }\n",
    "\n",
    "    def generate_answers_for_question(self, question_data: Dict[str, Any], question_index: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        为单个问题并行生成5个不同质量等级的答案\n",
    "        \n",
    "        Args:\n",
    "            question_data: 包含问题内容的字典\n",
    "            question_index: 问题在列表中的索引（用于显示进度）\n",
    "            \n",
    "        Returns:\n",
    "            包含问题和所有答案的完整数据\n",
    "        \"\"\"\n",
    "        question = question_data.get(\"question\", \"\")\n",
    "        question_id = question_data.get(\"id\", question_index)\n",
    "        \n",
    "        self.safe_print(f\"🔄 处理问题 {question_index + 1}/{self.stats['total_questions']} (ID: {question_id})\")\n",
    "        \n",
    "        # 使用线程池并行生成5个不同质量的答案\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.answer_concurrency) as executor:\n",
    "            # 提交所有答案生成任务\n",
    "            future_to_level = {\n",
    "                executor.submit(self.generate_single_answer, question, level, question_id): level \n",
    "                for level in range(1, 6)\n",
    "            }\n",
    "            \n",
    "            # 收集结果\n",
    "            answers = []\n",
    "            for future in concurrent.futures.as_completed(future_to_level):\n",
    "                level = future_to_level[future]\n",
    "                try:\n",
    "                    answer = future.result()\n",
    "                    answers.append(answer)\n",
    "                except Exception as e:\n",
    "                    self.safe_print(f\"❌ 问题{question_id} 质量等级{level}处理异常: {e}\")\n",
    "                    answers.append({\n",
    "                        \"quality_level\": level,\n",
    "                        \"quality_name\": self.config.QUALITY_LEVELS[level][\"name\"],\n",
    "                        \"quality_description\": self.config.QUALITY_LEVELS[level][\"description\"],\n",
    "                        \"content\": f\"处理异常: {str(e)}\",\n",
    "                        \"error\": True,\n",
    "                        \"error_message\": str(e)\n",
    "                    })\n",
    "            \n",
    "            # 按质量等级排序\n",
    "            answers.sort(key=lambda x: x[\"quality_level\"])\n",
    "        \n",
    "        # 更新完成统计\n",
    "        self.update_stats(completed_questions=1)\n",
    "        \n",
    "        result = {\n",
    "            \"question_id\": question_id,\n",
    "            \"question\": question,\n",
    "            \"answers\": answers,\n",
    "            \"metadata\": {\n",
    "                \"total_answers\": len(answers),\n",
    "                \"successful_answers\": len([a for a in answers if not a.get(\"error\", False)]),\n",
    "                \"failed_answers\": len([a for a in answers if a.get(\"error\", False)])\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def save_intermediate_results(self, results: List[Dict[str, Any]], batch_num: int):\n",
    "        \"\"\"\n",
    "        保存中间结果到answers子目录，防止程序崩溃时丢失数据\n",
    "        \n",
    "        Args:\n",
    "            results: 要保存的结果列表\n",
    "            batch_num: 批次编号\n",
    "        \"\"\"\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        # 保存到answers子目录\n",
    "        answers_file = self.answers_dir / f\"answers_batch_{batch_num}.jsonl\"\n",
    "        \n",
    "        with self.file_lock:\n",
    "            # 保存答案数据\n",
    "            with open(answers_file, 'w', encoding='utf-8') as f:\n",
    "                for result in results:\n",
    "                    f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        self.safe_print(f\"💾 已保存批次 {batch_num} 的中间结果\")\n",
    "        self.safe_print(f\"   - 答案文件: {answers_file}\")\n",
    "\n",
    "    def merge_all_batch_files(self) -> str:\n",
    "        \"\"\"\n",
    "        合并所有批次文件为一个完整的问题-答案文件，保存到reward_data根目录\n",
    "        \n",
    "        Returns:\n",
    "            合并后的文件路径\n",
    "        \"\"\"\n",
    "        self.safe_print(\"🔄 合并所有批次文件...\")\n",
    "        \n",
    "        # 查找answers目录下的所有批次文件\n",
    "        batch_files = list(self.answers_dir.glob(\"answers_batch_*.jsonl\"))\n",
    "        batch_files.sort()  # 按文件名排序\n",
    "        \n",
    "        if not batch_files:\n",
    "            raise FileNotFoundError(f\"在 {self.answers_dir} 中未找到任何answers_batch文件\")\n",
    "        \n",
    "        # 合并文件，保存到reward_data根目录\n",
    "        merged_file = self.output_dir / \"complete_qa_dataset.jsonl\"\n",
    "        all_data = []\n",
    "        \n",
    "        for batch_file in batch_files:\n",
    "            self.safe_print(f\"   - 读取: {batch_file.name}\")\n",
    "            with open(batch_file, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        try:\n",
    "                            data = json.loads(line.strip())\n",
    "                            all_data.append(data)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            self.safe_print(f\"⚠️  跳过无效行: {e}\")\n",
    "        \n",
    "        # 保存合并后的文件到根目录\n",
    "        with open(merged_file, 'w', encoding='utf-8') as f:\n",
    "            for item in all_data:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "        \n",
    "        self.safe_print(f\"✅ 合并完成: {merged_file}\")\n",
    "        self.safe_print(f\"   - 总问题数: {len(all_data)}\")\n",
    "        self.safe_print(f\"   - 批次文件位置: {self.answers_dir}\")\n",
    "        self.safe_print(f\"   - 合并文件位置: {merged_file}\")\n",
    "        \n",
    "        return str(merged_file)\n",
    "\n",
    "    def generate_preference_dataset(self, questions: List[Dict[str, Any]], max_questions: int = None) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        为问题列表生成偏好数据集（主要入口函数）\n",
    "        \n",
    "        Args:\n",
    "            questions: 问题列表\n",
    "            max_questions: 最大处理问题数，用于测试或限制处理量\n",
    "            \n",
    "        Returns:\n",
    "            包含所有结果和统计信息的字典\n",
    "        \"\"\"\n",
    "        # 限制处理的问题数量\n",
    "        if max_questions:\n",
    "            questions = questions[:max_questions]\n",
    "            self.safe_print(f\"🔢 限制处理数量为: {max_questions}\")\n",
    "        \n",
    "        # 初始化统计信息\n",
    "        self.stats[\"total_questions\"] = len(questions)\n",
    "        self.stats[\"start_time\"] = time.time()\n",
    "        \n",
    "        self.safe_print(f\"🚀 开始为 {len(questions)} 个问题生成答案...\")\n",
    "        self.safe_print(f\"📊 并发设置: 问题级别={self.question_concurrency}, 答案级别={self.answer_concurrency}\")\n",
    "        self.safe_print(f\"📁 批次文件保存位置: {self.answers_dir}\")\n",
    "        \n",
    "        all_results = []\n",
    "        batch_size = getattr(self.config, 'BATCH_SIZE', 10)\n",
    "        \n",
    "        # 使用线程池并行处理多个问题\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.question_concurrency) as executor:\n",
    "            # 提交所有问题处理任务\n",
    "            future_to_index = {\n",
    "                executor.submit(self.generate_answers_for_question, question, i): i\n",
    "                for i, question in enumerate(questions)\n",
    "            }\n",
    "            \n",
    "            # 收集结果并定期保存\n",
    "            batch_results = []\n",
    "            batch_num = 1\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_index):\n",
    "                index = future_to_index[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    all_results.append(result)\n",
    "                    batch_results.append(result)\n",
    "                    \n",
    "                    # 定期保存中间结果\n",
    "                    if len(batch_results) >= batch_size:\n",
    "                        self.save_intermediate_results(batch_results, batch_num)\n",
    "                        batch_results = []\n",
    "                        batch_num += 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    self.safe_print(f\"❌ 问题 {index + 1} 处理失败: {e}\")\n",
    "            \n",
    "            # 保存最后一批结果\n",
    "            if batch_results:\n",
    "                self.save_intermediate_results(batch_results, batch_num)\n",
    "        \n",
    "        # 记录结束时间\n",
    "        self.stats[\"end_time\"] = time.time()\n",
    "        \n",
    "        # 合并所有批次文件\n",
    "        merged_file_path = self.merge_all_batch_files()\n",
    "        \n",
    "        # 生成最终统计报告\n",
    "        self.generate_final_report(all_results)\n",
    "        \n",
    "        return {\n",
    "            \"results\": all_results,\n",
    "            \"statistics\": self.stats,\n",
    "            \"total_questions\": len(questions),\n",
    "            \"merged_file_path\": merged_file_path\n",
    "        }\n",
    "\n",
    "    def generate_final_report(self, results: List[Dict[str, Any]]):\n",
    "        \"\"\"生成最终的统计报告\"\"\"\n",
    "        total_time = self.stats[\"end_time\"] - self.stats[\"start_time\"]\n",
    "        \n",
    "        # 计算详细统计\n",
    "        successful_questions = len([r for r in results if r[\"metadata\"][\"failed_answers\"] == 0])\n",
    "        \n",
    "        report = {\n",
    "            \"generation_summary\": {\n",
    "                \"total_questions\": self.stats[\"total_questions\"],\n",
    "                \"completed_questions\": self.stats[\"completed_questions\"],\n",
    "                \"successful_questions\": successful_questions,\n",
    "                \"total_time_seconds\": total_time,\n",
    "                \"questions_per_minute\": (self.stats[\"completed_questions\"] / total_time) * 60 if total_time > 0 else 0\n",
    "            },\n",
    "            \"api_statistics\": {\n",
    "                \"total_api_calls\": self.stats[\"total_api_calls\"],\n",
    "                \"successful_api_calls\": self.stats[\"successful_api_calls\"],\n",
    "                \"failed_api_calls\": self.stats[\"failed_api_calls\"],\n",
    "                \"success_rate\": (self.stats[\"successful_api_calls\"] / self.stats[\"total_api_calls\"]) * 100 if self.stats[\"total_api_calls\"] > 0 else 0\n",
    "            },\n",
    "            \"concurrency_settings\": {\n",
    "                \"question_concurrency\": self.question_concurrency,\n",
    "                \"answer_concurrency\": self.answer_concurrency\n",
    "            },\n",
    "            \"file_locations\": {\n",
    "                \"batch_files_directory\": str(self.answers_dir),\n",
    "                \"merged_file\": str(self.output_dir / \"complete_qa_dataset.jsonl\")\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 保存报告\n",
    "        report_file = self.output_dir / \"generation_report.json\"\n",
    "        with open(report_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(report, indent=2, ensure_ascii=False, fp=f)\n",
    "        \n",
    "        # 打印总结\n",
    "        self.safe_print(\"\\n\" + \"=\"*60)\n",
    "        self.safe_print(\"🎉 答案生成完成！\")\n",
    "        self.safe_print(\"=\"*60)\n",
    "        self.safe_print(f\"📊 处理问题: {self.stats['completed_questions']}/{self.stats['total_questions']}\")\n",
    "        self.safe_print(f\"✅ 成功问题: {successful_questions}\")\n",
    "        self.safe_print(f\"⏱️  总耗时: {total_time:.1f}秒\")\n",
    "        self.safe_print(f\"🚀 处理速度: {(self.stats['completed_questions'] / total_time) * 60:.1f} 问题/分钟\")\n",
    "        self.safe_print(f\"📡 API成功率: {(self.stats['successful_api_calls'] / self.stats['total_api_calls']) * 100:.1f}%\")\n",
    "        self.safe_print(f\"📁 批次文件目录: {self.answers_dir}\")\n",
    "        self.safe_print(f\"📄 合并文件: {self.output_dir / 'complete_qa_dataset.jsonl'}\")\n",
    "        self.safe_print(f\"📄 报告文件: {report_file}\")\n",
    "        self.safe_print(\"=\"*60)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17004b56",
   "metadata": {},
   "source": [
    " `data_processor.py` - 数据处理中心\n",
    "   - 作用：处理SFT数据和文章数据\n",
    "   - 功能：数据加载、问题提取、采样混合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1398d5",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "数据处理器 - 简化版本\n",
    "负责处理SFT数据和基础文章数据\n",
    "\n",
    "【作用】\n",
    "这个模块是整个数据生成流程的\"数据管家\"，负责：\n",
    "1. 加载各种格式的数据文件（SFT数据、文章数据）\n",
    "2. 从已有数据中提取有用信息（如问题）\n",
    "3. 对数据进行采样和混合处理\n",
    "4. 为其他模块提供标准化的数据格式\n",
    "\n",
    "【在整体程序中的作用】\n",
    "- 在问题生成阶段：加载SFT数据和文章数据，提取和生成问题\n",
    "- 为问题生成器提供原始材料\n",
    "- 统一数据格式，让其他模块易于使用\n",
    "- 实现数据的随机采样和混合，确保数据多样性\n",
    "\n",
    "【为什么需要数据处理器】\n",
    "不同来源的数据格式可能不同，需要统一处理\n",
    "而且需要从大量数据中选择合适的样本，不是所有数据都要用\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import List, Dict, Any\n",
    "from utils import load_jsonl_file, random_sample_with_seed, mix_data_evenly, validate_file_paths\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    数据处理器类\n",
    "    \n",
    "    【核心功能】\n",
    "    1. 数据文件的加载和验证\n",
    "    2. SFT数据中问题的提取\n",
    "    3. 文章数据的采样处理\n",
    "    4. 不同来源数据的混合\n",
    "    5. 数据格式的标准化\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed: int = 42):\n",
    "        \"\"\"\n",
    "        初始化数据处理器\n",
    "        \n",
    "        【作用】\n",
    "        设置数据处理器的基本参数，特别是随机种子\n",
    "        \n",
    "        【为什么要设置随机种子】\n",
    "        随机种子确保每次运行程序时，随机采样的结果都相同\n",
    "        这对于实验的可重现性非常重要\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为整个数据处理流程做准备\n",
    "        - 确保数据处理的一致性和可重现性\n",
    "        \n",
    "        Args:\n",
    "            seed: 随机种子，确保结果可复现\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        logging.info(f\"数据处理器初始化，随机种子: {seed}\")\n",
    "    \n",
    "    def load_sft_data(self, sft_file_paths: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        加载SFT数据文件\n",
    "        \n",
    "        【作用】\n",
    "        SFT（Supervised Fine-Tuning）数据是已经训练好的对话数据，\n",
    "        这个函数的任务是：\n",
    "        1. 验证所有SFT文件是否存在\n",
    "        2. 逐个加载每个文件的内容\n",
    "        3. 将所有文件的数据合并成一个大列表\n",
    "        4. 记录加载过程和统计信息\n",
    "        \n",
    "        【什么是SFT数据】\n",
    "        SFT数据通常包含用户问题(input)和AI回答(output)的对话对\n",
    "        我们主要用其中的问题部分来丰富我们的问题库\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为问题生成阶段提供高质量的已有问题\n",
    "        - 确保生成的数据集包含经过验证的问题类型\n",
    "        - 平衡新生成问题和已有问题的比例\n",
    "        \n",
    "        Args:\n",
    "            sft_file_paths: SFT数据文件路径列表\n",
    "            \n",
    "        Returns:\n",
    "            合并后的SFT数据列表\n",
    "        \"\"\"\n",
    "        # 验证文件路径\n",
    "        # 【为什么要验证】避免程序运行到一半才发现文件不存在\n",
    "        valid_paths = validate_file_paths(sft_file_paths)\n",
    "        if not valid_paths:\n",
    "            raise ValueError(\"没有找到有效的SFT数据文件\")\n",
    "        \n",
    "        # 加载所有文件并合并\n",
    "        all_sft_data = []\n",
    "        for file_path in valid_paths:\n",
    "            # 加载单个文件\n",
    "            data = load_jsonl_file(file_path)\n",
    "            all_sft_data.extend(data)\n",
    "            logging.info(f\"从 {file_path} 加载了 {len(data)} 条SFT数据\")\n",
    "        \n",
    "        logging.info(f\"总共加载了 {len(all_sft_data)} 条SFT数据\")\n",
    "        return all_sft_data\n",
    "    \n",
    "    def load_base_articles(self, base_articles_path: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        加载基础文章数据\n",
    "        \n",
    "        【作用】\n",
    "        基础文章是用来生成新问题的原始材料，通常是金融新闻或分析文章\n",
    "        这个函数负责：\n",
    "        1. 验证文章文件是否存在\n",
    "        2. 加载文章内容\n",
    "        3. 为后续问题生成做准备\n",
    "        \n",
    "        【什么是基础文章】\n",
    "        基础文章通常是英文的金融新闻，包含市场动态、公司分析、\n",
    "        经济指标等信息，我们从中提取关键信息生成中文问题\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为问题生成器提供丰富的素材\n",
    "        - 确保生成的问题具有时效性和专业性\n",
    "        - 扩展问题的多样性和覆盖面\n",
    "        \n",
    "        Args:\n",
    "            base_articles_path: 基础文章文件路径\n",
    "            \n",
    "        Returns:\n",
    "            基础文章数据列表\n",
    "        \"\"\"\n",
    "        # 验证文件是否存在\n",
    "        if not validate_file_paths([base_articles_path]):\n",
    "            raise ValueError(f\"基础文章文件不存在: {base_articles_path}\")\n",
    "        \n",
    "        # 加载文章数据\n",
    "        articles = load_jsonl_file(base_articles_path)\n",
    "        logging.info(f\"加载了 {len(articles)} 篇基础文章\")\n",
    "        return articles\n",
    "    \n",
    "    def extract_questions_from_sft(self, sft_data: List[Dict[str, Any]], sample_size: int) -> List[str]:\n",
    "        \"\"\"\n",
    "        从SFT数据中提取问题（只提取input字段，不包含instruction）\n",
    "        \n",
    "        【作用】\n",
    "        这是一个关键的数据处理函数，它的任务是：\n",
    "        1. 从SFT数据中随机选择指定数量的样本\n",
    "        2. 从每个样本中提取用户的问题部分\n",
    "        3. 过滤掉无效或过短的问题\n",
    "        4. 返回清洗后的问题列表\n",
    "        \n",
    "        【为什么只提取input字段】\n",
    "        SFT数据的结构通常是：\n",
    "        - input: 用户的实际问题\n",
    "        - output: AI的回答\n",
    "        - instruction: 系统指令\n",
    "        我们只需要真实的用户问题，不需要系统指令\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 从已有的高质量对话数据中提取问题\n",
    "        - 为问题库提供经过验证的问题类型\n",
    "        - 确保生成的数据集包含多样化的问题\n",
    "        \n",
    "        Args:\n",
    "            sft_data: SFT数据列表\n",
    "            sample_size: 需要采样的问题数量\n",
    "            \n",
    "        Returns:\n",
    "            问题列表\n",
    "        \"\"\"\n",
    "        # 随机采样SFT数据\n",
    "        # 【为什么要采样】通常SFT数据很多，我们只需要其中一部分\n",
    "        # 采样可以控制数据量，也能保证随机性\n",
    "        sampled_sft = random_sample_with_seed(sft_data, sample_size, self.seed)\n",
    "        \n",
    "        # 提取问题（只使用input字段）\n",
    "        questions = []\n",
    "        for item in sampled_sft:\n",
    "            question = \"\"\n",
    "            \n",
    "            # 优先使用input字段，这是实际的问题内容\n",
    "            # 【数据字段的优先级】\n",
    "            # input > question > 其他字段\n",
    "            if 'input' in item:\n",
    "                question = item['input'].strip()\n",
    "            elif 'question' in item:\n",
    "                question = item['question'].strip()\n",
    "            else:\n",
    "                logging.warning(f\"无法从SFT数据中提取问题: {item}\")\n",
    "                continue\n",
    "            \n",
    "            # 验证问题质量\n",
    "            if question:\n",
    "                questions.append(question)\n",
    "            else:\n",
    "                logging.warning(f\"提取的问题为空: {item}\")\n",
    "        \n",
    "        logging.info(f\"从SFT数据中提取了 {len(questions)} 个问题\")\n",
    "        return questions\n",
    "    \n",
    "    def sample_articles_for_generation(self, articles: List[Dict[str, Any]], sample_size: int) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        为问题生成采样基础文章\n",
    "        \n",
    "        【作用】\n",
    "        从大量的基础文章中选择一部分用于问题生成：\n",
    "        1. 根据需要生成的问题数量决定采样数量\n",
    "        2. 随机选择文章，确保多样性\n",
    "        3. 为每篇文章添加索引，方便追踪\n",
    "        \n",
    "        【为什么要采样】\n",
    "        - 基础文章可能有成千上万篇，全部处理耗时太长\n",
    "        - 采样可以控制处理时间和API成本\n",
    "        - 随机采样保证了问题的多样性\n",
    "        \n",
    "        【采样策略】\n",
    "        使用固定随机种子的采样，确保结果可重现\n",
    "        这样每次运行程序都会选择相同的文章\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为问题生成器提供合适数量的文章素材\n",
    "        - 控制问题生成的工作量和成本\n",
    "        - 确保文章选择的随机性和可重现性\n",
    "        \n",
    "        Args:\n",
    "            articles: 基础文章列表\n",
    "            sample_size: 采样数量\n",
    "            \n",
    "        Returns:\n",
    "            采样后的文章列表\n",
    "        \"\"\"\n",
    "        sampled_articles = random_sample_with_seed(articles, sample_size, self.seed)\n",
    "        logging.info(f\"为问题生成采样了 {len(sampled_articles)} 篇文章\")\n",
    "        return sampled_articles\n",
    "    \n",
    "    def combine_questions(self, sft_questions: List[str], generated_questions: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        合并SFT问题和新生成的问题\n",
    "        \n",
    "        【作用】\n",
    "        这是数据处理的最后一步，将两种来源的问题合并：\n",
    "        1. 来自SFT数据的高质量问题\n",
    "        2. 从文章新生成的问题\n",
    "        3. 均匀混合，打乱顺序\n",
    "        4. 返回最终的问题列表\n",
    "        \n",
    "        【为什么要混合】\n",
    "        - SFT问题质量高但可能类型有限\n",
    "        - 新生成的问题更有针对性但质量可能不稳定\n",
    "        - 混合两者可以取长补短，提高数据集质量\n",
    "        \n",
    "        【混合策略】\n",
    "        使用均匀混合算法，确保两种类型的问题分布均匀\n",
    "        不是简单拼接，而是交替分布\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 完成问题生成阶段的最终整合\n",
    "        - 为答案生成阶段提供完整的问题列表\n",
    "        - 确保问题的多样性和质量平衡\n",
    "        \n",
    "        Args:\n",
    "            sft_questions: 从SFT数据提取的问题\n",
    "            generated_questions: 新生成的问题\n",
    "            \n",
    "        Returns:\n",
    "            混合后的问题列表\n",
    "        \"\"\"\n",
    "        # 使用工具函数进行均匀混合\n",
    "        # 【mix_data_evenly函数的作用】\n",
    "        # 1. 将两个列表合并\n",
    "        # 2. 使用固定种子打乱顺序\n",
    "        # 3. 确保结果可重现\n",
    "        combined_questions = mix_data_evenly(sft_questions, generated_questions, self.seed)\n",
    "        logging.info(f\"合并了 {len(sft_questions)} + {len(generated_questions)} = {len(combined_questions)} 个问题\")\n",
    "        return combined_questions\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b6129b",
   "metadata": {},
   "source": [
    " `data_splitter.py` - 数据集分割器\n",
    "   - 作用：将数据分割为训练/验证/测试集\n",
    "   - 功能：数据分割、格式转换、统计报告\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc38c6",
   "metadata": {},
   "source": [
    "```python \n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "数据拆分器 - 将问题-五答案数据拆分为训练/验证/测试集\n",
    "并生成对应的偏好对格式数据\n",
    "\n",
    "【作用】\n",
    "这个模块是整个数据生成流程的最后一步，负责：\n",
    "1. 将完整的问题-答案数据按比例分割成不同用途的数据集\n",
    "2. 将数据转换为奖励模型训练需要的偏好对格式\n",
    "3. 生成详细的统计报告，帮助用户了解数据分布\n",
    "4. 为不同的训练阶段提供标准化的数据文件\n",
    "\n",
    "【为什么要分割数据集】\n",
    "机器学习的标准做法是将数据分为三部分：\n",
    "- 训练集（80%）：用于训练奖励模型\n",
    "- 验证集（10%）：用于调整模型参数\n",
    "- 测试集（10%）：用于最终评估模型性能\n",
    "\n",
    "【在整体程序中的作用】\n",
    "- 完成整个数据生成流程的最后一环\n",
    "- 为奖励模型训练提供标准格式的数据\n",
    "- 确保训练数据的科学性和规范性\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from utils import ensure_directory_exists, save_jsonl_file, load_jsonl_file\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"\n",
    "    数据拆分器类\n",
    "    \n",
    "    【核心功能】\n",
    "    1. 加载完整的问题-答案数据\n",
    "    2. 按比例随机分割数据集\n",
    "    3. 生成偏好对格式的训练数据\n",
    "    4. 保存不同格式的数据文件\n",
    "    5. 生成详细的统计报告\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dir: str, output_dir: str, random_seed: int = 42):\n",
    "        \"\"\"\n",
    "        初始化数据拆分器\n",
    "        \n",
    "        【作用】\n",
    "        设置数据拆分器的基本参数和工作目录\n",
    "        \n",
    "        【为什么需要输入和输出目录】\n",
    "        - input_dir: 存放完整数据的目录（来自答案生成阶段）\n",
    "        - output_dir: 存放分割后数据的目录（用于后续训练）\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 衔接答案生成和模型训练两个阶段\n",
    "        - 为数据分割过程做准备\n",
    "        - 确保分割结果的可重现性\n",
    "        \n",
    "        Args:\n",
    "            input_dir: 输入目录路径（包含答案数据文件）\n",
    "            output_dir: 输出目录路径（保存分割后的数据）\n",
    "            random_seed: 随机种子，确保结果可重现\n",
    "        \"\"\"\n",
    "        self.input_dir = Path(input_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        # 设置随机种子\n",
    "        # 【确保可重现性】相同的种子会产生相同的分割结果\n",
    "        random.seed(random_seed)\n",
    "        \n",
    "        print(f\"数据拆分器初始化:\")\n",
    "        print(f\"  输入目录: {self.input_dir}\")\n",
    "        print(f\"  输出目录: {self.output_dir}\")\n",
    "        print(f\"  随机种子: {self.random_seed}\")\n",
    "    \n",
    "    def load_all_answers_data(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        加载所有的answers_batch文件数据或合并文件数据\n",
    "        \n",
    "        【作用】\n",
    "        从答案生成阶段的输出中加载完整数据：\n",
    "        1. 优先查找合并后的完整文件\n",
    "        2. 如果没有合并文件，则加载所有批次文件\n",
    "        3. 验证数据的完整性和格式\n",
    "        4. 返回统一格式的数据列表\n",
    "        \n",
    "        【为什么要支持两种加载方式】\n",
    "        - 如果答案生成正常完成，会有合并文件，直接加载更快\n",
    "        - 如果程序中断，可能只有批次文件，需要逐个加载\n",
    "        \n",
    "        【数据格式说明】\n",
    "        每条数据包含：\n",
    "        - question_id: 问题唯一标识\n",
    "        - question: 问题内容\n",
    "        - answers: 5个不同质量等级的答案列表\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为数据分割提供输入数据\n",
    "        - 确保数据加载的灵活性和鲁棒性\n",
    "        - 验证上一阶段的输出质量\n",
    "        \n",
    "        Returns:\n",
    "            合并后的所有问题-答案数据\n",
    "        \"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        # 首先检查是否存在合并文件\n",
    "        merged_file = self.input_dir / \"complete_qa_dataset.jsonl\"\n",
    "        if merged_file.exists():\n",
    "            print(f\"找到合并文件: {merged_file.name}\")\n",
    "            data = load_jsonl_file(str(merged_file))\n",
    "            all_data.extend(data)\n",
    "            print(f\"从合并文件加载了 {len(data)} 个问题-答案组合\")\n",
    "        else:\n",
    "            # 查找所有answers_batch文件\n",
    "            # 【批次文件的命名规则】answers_batch_1.jsonl, answers_batch_2.jsonl, ...\n",
    "            answers_files = list(self.input_dir.glob(\"answers_batch_*.jsonl\"))\n",
    "            \n",
    "            if not answers_files:\n",
    "                raise FileNotFoundError(f\"在 {self.input_dir} 中未找到 complete_qa_dataset.jsonl 或 answers_batch_*.jsonl 文件\")\n",
    "            \n",
    "            print(f\"找到 {len(answers_files)} 个answers_batch文件:\")\n",
    "            \n",
    "            # 按文件名排序，确保加载顺序一致\n",
    "            for file_path in sorted(answers_files):\n",
    "                print(f\"  - {file_path.name}\")\n",
    "                data = load_jsonl_file(str(file_path))\n",
    "                all_data.extend(data)\n",
    "        \n",
    "        print(f\"总共加载了 {len(all_data)} 个问题-答案组合\")\n",
    "        return all_data\n",
    "    \n",
    "    def split_data(self, data: List[Dict[str, Any]], \n",
    "                   train_ratio: float = 0.8, \n",
    "                   eval_ratio: float = 0.1, \n",
    "                   test_ratio: float = 0.1) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        将数据按比例拆分为训练/验证/测试集\n",
    "        \n",
    "        【作用】\n",
    "        这是数据分割的核心方法：\n",
    "        1. 验证分割比例的合理性\n",
    "        2. 随机打乱数据顺序，避免偏差\n",
    "        3. 按比例计算各个集合的大小\n",
    "        4. 将数据分配到不同的集合中\n",
    "        \n",
    "        【为什么要随机打乱】\n",
    "        原始数据可能有顺序偏差（比如简单问题在前，复杂问题在后）\n",
    "        随机打乱确保每个数据集都包含各种类型的问题\n",
    "        \n",
    "        【分割比例的选择】\n",
    "        8:1:1是机器学习中常用的分割比例：\n",
    "        - 80%训练集：足够多的数据用于学习\n",
    "        - 10%验证集：用于调整超参数\n",
    "        - 10%测试集：用于最终评估\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为奖励模型训练提供科学的数据分割\n",
    "        - 确保模型评估的可靠性\n",
    "        - 避免数据泄露和过拟合问题\n",
    "        \n",
    "        Args:\n",
    "            data: 原始数据列表\n",
    "            train_ratio: 训练集比例\n",
    "            eval_ratio: 验证集比例  \n",
    "            test_ratio: 测试集比例\n",
    "            \n",
    "        Returns:\n",
    "            (训练集, 验证集, 测试集) 的元组\n",
    "        \"\"\"\n",
    "        # 验证比例\n",
    "        # 【为什么要验证比例】确保比例加起来等于1，避免数据丢失或重复\n",
    "        total_ratio = train_ratio + eval_ratio + test_ratio\n",
    "        if abs(total_ratio - 1.0) > 1e-6:  # 允许微小的浮点误差\n",
    "            raise ValueError(f\"比例之和必须为1.0，当前为 {total_ratio}\")\n",
    "        \n",
    "        # 打乱数据顺序\n",
    "        # 【深拷贝的重要性】避免修改原始数据，保持数据完整性\n",
    "        shuffled_data = data.copy()\n",
    "        random.shuffle(shuffled_data)\n",
    "        \n",
    "        # 计算各集合的大小\n",
    "        total_size = len(shuffled_data)\n",
    "        train_size = int(total_size * train_ratio)\n",
    "        eval_size = int(total_size * eval_ratio)\n",
    "        # test_size自动为剩余部分，避免舍入误差\n",
    "        \n",
    "        # 拆分数据\n",
    "        # 【索引分割法】使用数组切片进行分割，简单高效\n",
    "        train_data = shuffled_data[:train_size]\n",
    "        eval_data = shuffled_data[train_size:train_size + eval_size]\n",
    "        test_data = shuffled_data[train_size + eval_size:]\n",
    "        \n",
    "        # 显示分割结果\n",
    "        print(f\"数据拆分结果:\")\n",
    "        print(f\"  训练集: {len(train_data)} 个问题 ({len(train_data)/total_size*100:.1f}%)\")\n",
    "        print(f\"  验证集: {len(eval_data)} 个问题 ({len(eval_data)/total_size*100:.1f}%)\")\n",
    "        print(f\"  测试集: {len(test_data)} 个问题 ({len(test_data)/total_size*100:.1f}%)\")\n",
    "        \n",
    "        return train_data, eval_data, test_data\n",
    "    \n",
    "    def generate_preference_pairs_from_answers(self, answers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        从5个答案生成所有可能的偏好对\n",
    "        \n",
    "        【作用】\n",
    "        这是奖励模型训练数据生成的核心方法：\n",
    "        1. 从5个不同质量的答案中生成所有两两对比的组合\n",
    "        2. 确定每一对中哪个答案更好（质量等级更高）\n",
    "        3. 创建\"好答案vs差答案\"的偏好对\n",
    "        4. 为每个偏好对添加质量差距信息\n",
    "        \n",
    "        【什么是偏好对】\n",
    "        偏好对是奖励模型训练的标准格式：\n",
    "        - chosen: 更好的答案\n",
    "        - rejected: 较差的答案\n",
    "        - 模型学习给好答案打高分，给差答案打低分\n",
    "        \n",
    "        【为什么要生成所有组合】\n",
    "        从5个答案可以生成C(5,2)=10个偏好对，这样可以：\n",
    "        - 充分利用数据，增加训练样本\n",
    "        - 让模型学习不同质量等级之间的差异\n",
    "        - 提高训练效率和模型性能\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 将原始问题-答案数据转换为训练格式\n",
    "        - 为奖励模型提供丰富的对比样本\n",
    "        - 实现数据格式的标准化转换\n",
    "        \n",
    "        Args:\n",
    "            answers: 5个不同质量等级的答案\n",
    "            \n",
    "        Returns:\n",
    "            偏好对列表\n",
    "        \"\"\"\n",
    "        preference_pairs = []\n",
    "        \n",
    "        # 生成所有可能的答案对组合 (C(5,2) = 10对)\n",
    "        # 【双重循环的逻辑】\n",
    "        # i从0到4，j从i+1到4，确保不重复且不自比较\n",
    "        for i in range(len(answers)):\n",
    "            for j in range(i + 1, len(answers)):\n",
    "                answer_a = answers[i]\n",
    "                answer_b = answers[j]\n",
    "                \n",
    "                # 跳过有错误的答案\n",
    "                # 【错误处理】生成过程中可能有些答案生成失败\n",
    "                if answer_a.get(\"error\") or answer_b.get(\"error\"):\n",
    "                    continue\n",
    "                \n",
    "                # 确定哪个是更好的答案（质量等级更高的）\n",
    "                # 【偏好判断的依据】完全基于预设的质量等级\n",
    "                if answer_a[\"quality_level\"] > answer_b[\"quality_level\"]:\n",
    "                    chosen = answer_a[\"content\"]\n",
    "                    rejected = answer_b[\"content\"]\n",
    "                    chosen_level = answer_a[\"quality_level\"]\n",
    "                    rejected_level = answer_b[\"quality_level\"]\n",
    "                else:\n",
    "                    chosen = answer_b[\"content\"]\n",
    "                    rejected = answer_a[\"content\"]\n",
    "                    chosen_level = answer_b[\"quality_level\"]\n",
    "                    rejected_level = answer_a[\"quality_level\"]\n",
    "                \n",
    "                # 创建偏好对记录\n",
    "                preference_pairs.append({\n",
    "                    \"chosen\": chosen,\n",
    "                    \"rejected\": rejected,\n",
    "                    \"chosen_level\": chosen_level,\n",
    "                    \"rejected_level\": rejected_level,\n",
    "                    \"quality_gap\": chosen_level - rejected_level  # 质量差距，用于分析\n",
    "                })\n",
    "        \n",
    "        return preference_pairs\n",
    "    \n",
    "    def convert_to_preference_format(self, data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        将问题-答案格式转换为偏好对格式\n",
    "        \n",
    "        【作用】\n",
    "        这个方法实现了数据格式的批量转换：\n",
    "        1. 遍历所有问题-答案数据\n",
    "        2. 为每个问题生成偏好对\n",
    "        3. 将偏好对与问题信息结合\n",
    "        4. 创建最终的训练数据格式\n",
    "        \n",
    "        【输入格式】\n",
    "        问题-答案格式：\n",
    "        {\n",
    "          \"question_id\": 1,\n",
    "          \"question\": \"问题内容\",\n",
    "          \"answers\": [答案1, 答案2, 答案3, 答案4, 答案5]\n",
    "        }\n",
    "        \n",
    "        【输出格式】\n",
    "        偏好对格式：\n",
    "        {\n",
    "          \"question_id\": 1,\n",
    "          \"question\": \"问题内容\",\n",
    "          \"chosen\": \"更好的答案\",\n",
    "          \"rejected\": \"较差的答案\",\n",
    "          \"chosen_level\": 4,\n",
    "          \"rejected_level\": 2,\n",
    "          \"quality_gap\": 2\n",
    "        }\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 完成从原始数据到训练数据的转换\n",
    "        - 大大增加训练样本的数量\n",
    "        - 为奖励模型提供标准化的输入格式\n",
    "        \n",
    "        Args:\n",
    "            data: 问题-答案格式的数据\n",
    "            \n",
    "        Returns:\n",
    "            偏好对格式的数据\n",
    "        \"\"\"\n",
    "        preference_data = []\n",
    "        \n",
    "        for item in data:\n",
    "            question = item[\"question\"]\n",
    "            question_id = item[\"question_id\"]\n",
    "            answers = item[\"answers\"]\n",
    "            \n",
    "            # 生成偏好对\n",
    "            # 【调用前面定义的方法】复用代码，保持逻辑一致性\n",
    "            preference_pairs = self.generate_preference_pairs_from_answers(answers)\n",
    "            \n",
    "            # 为每个偏好对添加问题信息\n",
    "            # 【数据结构扩展】将偏好对与具体问题关联\n",
    "            for pair in preference_pairs:\n",
    "                preference_record = {\n",
    "                    \"question_id\": question_id,\n",
    "                    \"question\": question,\n",
    "                    **pair  # 展开偏好对的所有字段\n",
    "                }\n",
    "                preference_data.append(preference_record)\n",
    "        \n",
    "        return preference_data\n",
    "    \n",
    "    def save_dataset(self, data: List[Dict[str, Any]], dataset_name: str, \n",
    "                     save_qa_format: bool = True, save_preference_format: bool = True):\n",
    "        \"\"\"\n",
    "        保存数据集到指定目录\n",
    "        \n",
    "        【作用】\n",
    "        这个方法负责将分割后的数据保存为不同格式的文件：\n",
    "        1. 创建对应的目录结构\n",
    "        2. 保存问题-答案格式（用于分析和调试）\n",
    "        3. 保存偏好对格式（用于奖励模型训练）\n",
    "        4. 确保文件命名的规范性\n",
    "        \n",
    "        【目录结构】\n",
    "        output_dir/\n",
    "        ├── train/\n",
    "        │   ├── qa_dataset.jsonl          # 问题-答案格式\n",
    "        │   └── preference_dataset.jsonl  # 偏好对格式\n",
    "        ├── eval/\n",
    "        │   ├── qa_dataset.jsonl\n",
    "        │   └── preference_dataset.jsonl\n",
    "        └── test/\n",
    "            ├── qa_dataset.jsonl\n",
    "            └── preference_dataset.jsonl\n",
    "        \n",
    "        【为什么要保存两种格式】\n",
    "        - qa_dataset.jsonl: 便于人工检查和分析\n",
    "        - preference_dataset.jsonl: 直接用于模型训练\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 为不同的使用场景提供合适的数据格式\n",
    "        - 规范化数据文件的组织结构\n",
    "        - 方便后续的模型训练和评估\n",
    "        \n",
    "        Args:\n",
    "            data: 要保存的数据\n",
    "            dataset_name: 数据集名称 (train/eval/test)\n",
    "            save_qa_format: 是否保存问题-答案格式\n",
    "            save_preference_format: 是否保存偏好对格式\n",
    "        \"\"\"\n",
    "        # 创建目录\n",
    "        dataset_dir = self.output_dir / dataset_name\n",
    "        ensure_directory_exists(dataset_dir)\n",
    "        \n",
    "        print(f\"保存 {dataset_name} 数据集到: {dataset_dir}\")\n",
    "        \n",
    "        # 保存问题-答案格式\n",
    "        if save_qa_format:\n",
    "            qa_file = dataset_dir / \"qa_dataset.jsonl\"\n",
    "            save_jsonl_file(data, str(qa_file))\n",
    "            print(f\"  ✅ QA格式: {qa_file.name} ({len(data)} 个问题)\")\n",
    "        \n",
    "        # 保存偏好对格式\n",
    "        if save_preference_format:\n",
    "            preference_data = self.convert_to_preference_format(data)\n",
    "            preference_file = dataset_dir / \"preference_dataset.jsonl\"\n",
    "            save_jsonl_file(preference_data, str(preference_file))\n",
    "            print(f\"  ✅ 偏好对格式: {preference_file.name} ({len(preference_data)} 个偏好对)\")\n",
    "\n",
    "    def generate_summary_report(self, train_data: List[Dict], eval_data: List[Dict], test_data: List[Dict]):\n",
    "        \"\"\"\n",
    "        生成数据拆分的统计报告\n",
    "        \n",
    "        【作用】\n",
    "        创建详细的统计报告，帮助用户了解数据分割的结果：\n",
    "        1. 基本统计信息（数量、比例）\n",
    "        2. 质量分布分析\n",
    "        3. 答案成功率统计\n",
    "        4. 偏好对数量统计\n",
    "        5. 数据完整性检查\n",
    "        \n",
    "        【报告的用途】\n",
    "        - 验证数据分割的正确性\n",
    "        - 分析数据质量分布\n",
    "        - 为模型训练提供参考信息\n",
    "        - 发现潜在的数据问题\n",
    "        \n",
    "        【统计维度】\n",
    "        - 数量统计：每个集合的问题数和偏好对数\n",
    "        - 质量统计：不同质量等级的答案分布\n",
    "        - 成功率统计：答案生成的成功率\n",
    "        - 完整性检查：是否有缺失或错误的数据\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 提供数据分割过程的完整总结\n",
    "        - 为后续工作提供数据质量参考\n",
    "        - 帮助发现和解决数据问题\n",
    "        \n",
    "        Args:\n",
    "            train_data: 训练集数据\n",
    "            eval_data: 验证集数据  \n",
    "            test_data: 测试集数据\n",
    "        \"\"\"\n",
    "        # 计算基本统计\n",
    "        total_questions = len(train_data) + len(eval_data) + len(test_data)\n",
    "        \n",
    "        # 统计答案质量分布\n",
    "        def analyze_quality_distribution(data, dataset_name):\n",
    "            \"\"\"分析单个数据集的质量分布\"\"\"\n",
    "            quality_stats = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "            total_answers = 0\n",
    "            successful_answers = 0\n",
    "            \n",
    "            for item in data:\n",
    "                answers = item.get(\"answers\", [])\n",
    "                for answer in answers:\n",
    "                    total_answers += 1\n",
    "                    if not answer.get(\"error\", False):\n",
    "                        successful_answers += 1\n",
    "                        level = answer.get(\"quality_level\", 0)\n",
    "                        if level in quality_stats:\n",
    "                            quality_stats[level] += 1\n",
    "            \n",
    "            return {\n",
    "                \"dataset_name\": dataset_name,\n",
    "                \"questions\": len(data),\n",
    "                \"total_answers\": total_answers,\n",
    "                \"successful_answers\": successful_answers,\n",
    "                \"success_rate\": successful_answers / total_answers * 100 if total_answers > 0 else 0,\n",
    "                \"quality_distribution\": quality_stats\n",
    "            }\n",
    "        \n",
    "        # 分析各个数据集\n",
    "        train_stats = analyze_quality_distribution(train_data, \"训练集\")\n",
    "        eval_stats = analyze_quality_distribution(eval_data, \"验证集\")\n",
    "        test_stats = analyze_quality_distribution(test_data, \"测试集\")\n",
    "        \n",
    "        # 计算偏好对数量\n",
    "        def count_preference_pairs(data):\n",
    "            \"\"\"计算偏好对数量\"\"\"\n",
    "            total_pairs = 0\n",
    "            for item in data:\n",
    "                answers = item.get(\"answers\", [])\n",
    "                successful_answers = [a for a in answers if not a.get(\"error\", False)]\n",
    "                # C(n,2) = n*(n-1)/2\n",
    "                n = len(successful_answers)\n",
    "                pairs = n * (n - 1) // 2 if n >= 2 else 0\n",
    "                total_pairs += pairs\n",
    "            return total_pairs\n",
    "        \n",
    "        train_pairs = count_preference_pairs(train_data)\n",
    "        eval_pairs = count_preference_pairs(eval_data)\n",
    "        test_pairs = count_preference_pairs(test_data)\n",
    "        \n",
    "        # 创建完整报告\n",
    "        report = {\n",
    "            \"summary\": {\n",
    "                \"total_questions\": total_questions,\n",
    "                \"train_questions\": len(train_data),\n",
    "                \"eval_questions\": len(eval_data),\n",
    "                \"test_questions\": len(test_data),\n",
    "                \"train_preference_pairs\": train_pairs,\n",
    "                \"eval_preference_pairs\": eval_pairs,\n",
    "                \"test_preference_pairs\": test_pairs,\n",
    "                \"total_preference_pairs\": train_pairs + eval_pairs + test_pairs\n",
    "            },\n",
    "            \"dataset_statistics\": [train_stats, eval_stats, test_stats],\n",
    "            \"split_ratios\": {\n",
    "                \"train\": len(train_data) / total_questions * 100,\n",
    "                \"eval\": len(eval_data) / total_questions * 100,\n",
    "                \"test\": len(test_data) / total_questions * 100\n",
    "            },\n",
    "            \"random_seed\": self.random_seed,\n",
    "            \"split_timestamp\": json.dumps({\"timestamp\": __import__('time').time()})\n",
    "        }\n",
    "        \n",
    "        # 保存报告\n",
    "        report_file = self.output_dir / \"split_report.json\"\n",
    "        try:\n",
    "            with open(report_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # 打印摘要信息\n",
    "            print(\"\\n📊 数据拆分统计报告:\")\n",
    "            print(f\"  📋 总问题数: {total_questions}\")\n",
    "            print(f\"  🎯 训练集: {len(train_data)} 问题, {train_pairs} 偏好对\")\n",
    "            print(f\"  🔍 验证集: {len(eval_data)} 问题, {eval_pairs} 偏好对\") \n",
    "            print(f\"  🧪 测试集: {len(test_data)} 问题, {test_pairs} 偏好对\")\n",
    "            print(f\"  📊 总偏好对: {train_pairs + eval_pairs + test_pairs}\")\n",
    "            print(f\"  📄 详细报告: {report_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 生成报告失败: {e}\")\n",
    "\n",
    "    def split_and_save(self, train_ratio: float = 0.8, eval_ratio: float = 0.1, test_ratio: float = 0.1):\n",
    "        \"\"\"\n",
    "        执行完整的数据拆分和保存流程\n",
    "        \n",
    "        【作用】\n",
    "        这是数据拆分器的主要入口方法，执行完整的处理流程：\n",
    "        1. 加载所有原始数据\n",
    "        2. 按比例分割数据集\n",
    "        3. 保存不同格式的数据文件\n",
    "        4. 生成统计报告\n",
    "        5. 清理和验证结果\n",
    "        \n",
    "        【流程概述】\n",
    "        加载数据 → 随机分割 → 格式转换 → 保存文件 → 生成报告\n",
    "        \n",
    "        【异常处理】\n",
    "        整个过程包含完善的错误处理：\n",
    "        - 文件不存在的处理\n",
    "        - 数据格式错误的处理\n",
    "        - 磁盘空间不足的处理\n",
    "        - 权限问题的处理\n",
    "        \n",
    "        【在整体程序中的作用】\n",
    "        - 完成整个数据生成流程的最后一步\n",
    "        - 为奖励模型训练提供标准化数据\n",
    "        - 确保数据处理的科学性和规范性\n",
    "        \n",
    "        Args:\n",
    "            train_ratio: 训练集比例\n",
    "            eval_ratio: 验证集比例\n",
    "            test_ratio: 测试集比例\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"🚀 开始数据拆分流程...\")\n",
    "            \n",
    "            # 第一步：加载所有数据\n",
    "            print(\"📥 加载原始数据...\")\n",
    "            all_data = self.load_all_answers_data()\n",
    "            \n",
    "            if not all_data:\n",
    "                raise ValueError(\"没有找到任何数据进行拆分\")\n",
    "            \n",
    "            # 第二步：执行数据拆分\n",
    "            print(\"✂️  执行数据拆分...\")\n",
    "            train_data, eval_data, test_data = self.split_data(\n",
    "                all_data, train_ratio, eval_ratio, test_ratio\n",
    "            )\n",
    "            \n",
    "            # 第三步：保存各个数据集\n",
    "            print(\"💾 保存数据集文件...\")\n",
    "            self.save_dataset(train_data, \"train\")\n",
    "            self.save_dataset(eval_data, \"eval\")  \n",
    "            self.save_dataset(test_data, \"test\")\n",
    "            \n",
    "            # 第四步：生成统计报告\n",
    "            print(\"📊 生成统计报告...\")\n",
    "            self.generate_summary_report(train_data, eval_data, test_data)\n",
    "            \n",
    "            print(\"✅ 数据拆分流程完成！\")\n",
    "            print(f\"📁 输出目录: {self.output_dir.absolute()}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 数据拆分失败: {e}\")\n",
    "            raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    数据拆分器的命令行入口\n",
    "    \n",
    "    【作用】\n",
    "    提供独立的命令行工具，允许用户单独运行数据拆分：\n",
    "    1. 解析命令行参数\n",
    "    2. 创建数据拆分器实例\n",
    "    3. 执行拆分流程\n",
    "    4. 处理命令行错误\n",
    "    \n",
    "    【使用场景】\n",
    "    - 独立运行数据拆分（不执行完整流程）\n",
    "    - 重新拆分已有数据\n",
    "    - 使用不同的拆分比例\n",
    "    - 调试和测试拆分功能\n",
    "    \n",
    "    【在整体程序中的作用】\n",
    "    - 提供灵活的数据处理方式\n",
    "    - 支持模块化的工作流程\n",
    "    - 便于测试和调试\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"数据拆分工具\")\n",
    "    parser.add_argument(\"--input-dir\", required=True, help=\"输入目录（包含答案数据）\")\n",
    "    parser.add_argument(\"--output-dir\", required=True, help=\"输出目录\")\n",
    "    parser.add_argument(\"--train-ratio\", type=float, default=0.8, help=\"训练集比例\")\n",
    "    parser.add_argument(\"--eval-ratio\", type=float, default=0.1, help=\"验证集比例\")\n",
    "    parser.add_argument(\"--test-ratio\", type=float, default=0.1, help=\"测试集比例\")\n",
    "    parser.add_argument(\"--random-seed\", type=int, default=42, help=\"随机种子\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # 创建并运行数据拆分器\n",
    "    splitter = DataSplitter(\n",
    "        input_dir=args.input_dir,\n",
    "        output_dir=args.output_dir,\n",
    "        random_seed=args.random_seed\n",
    "    )\n",
    "    \n",
    "    splitter.split_and_save(\n",
    "        train_ratio=args.train_ratio,\n",
    "        eval_ratio=args.eval_ratio,\n",
    "        test_ratio=args.test_ratio\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b7167",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f630c818",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b7824c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d766f0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`config.py` - 配置管理中心  \n",
    "   - 作用：统一管理所有配置参数\n",
    "   - 功能：API设置、文件路径、生成参数、质量等级定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8632d1",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "配置文件：定义所有的配置参数和常量\n",
    "这个文件包含了整个项目需要用到的所有配置信息，方便统一管理\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv  # 需要安装: pip install python-dotenv\n",
    "\n",
    "# 加载环境变量文件\n",
    "# 这样可以从.env文件中读取配置，避免在代码中硬编码敏感信息\n",
    "load_dotenv()\n",
    "\n",
    "class Config:\n",
    "    \"\"\"\n",
    "    配置类：存储所有配置参数\n",
    "    \n",
    "    这个类就像一个设置面板，包含了程序运行需要的所有参数\n",
    "    比如文件路径、API设置、生成参数等\n",
    "    \"\"\"\n",
    "    \n",
    "    # ==================== API相关配置 ====================\n",
    "    # 这部分配置用于连接AI模型的API服务\n",
    "    \n",
    "    # DeepSeek API的密钥，优先从环境变量读取，确保安全性\n",
    "    # 环境变量 > .env文件 > 默认值的优先级\n",
    "    DEEPSEEK_API_KEY: str = os.getenv(\"DEEPSEEK_API_KEY\", \"sk-de8e3482dwvyuybovuc22167d461b0d3cb\")\n",
    "    \n",
    "    # DeepSeek API的基础URL地址\n",
    "    DEEPSEEK_BASE_URL: str = os.getenv(\"DEEPSEEK_BASE_URL\", \"https://api.deepseek.com\")\n",
    "    \n",
    "    # 使用的AI模型名称\n",
    "    # deepseek-chat是DeepSeek的主要对话模型\n",
    "    MODEL_NAME: str = \"deepseek-chat\"\n",
    "    \n",
    "    # API调用的温度参数，控制生成内容的随机性\n",
    "    # 0.7表示有一定随机性但不会太乱，数值越高越随机\n",
    "    TEMPERATURE: float = 0.7\n",
    "    \n",
    "    # 每次API调用生成的最大字符数\n",
    "    # 5000个token大概是3500-4000个中文字符\n",
    "    MAX_TOKENS: int = 5000\n",
    "    \n",
    "    # API调用之间的等待时间（秒）\n",
    "    # DeepSeek的频率限制相对宽松，1秒间隔比较安全\n",
    "    API_CALL_INTERVAL: float = 1.0\n",
    "    \n",
    "    # 最大并发线程数\n",
    "    # DeepSeek支持较高的并发，但建议不超过20个线程\n",
    "    MAX_WORKERS: int = 20\n",
    "    \n",
    "    # ==================== 并发控制配置 ====================\n",
    "    # 通用并发数：同时处理多少个任务\n",
    "    CONCURRENCY_NUM: int = int(os.getenv(\"CONCURRENCY_NUM\", \"3\"))\n",
    "    \n",
    "    # 答案级别的并发数：每个问题同时生成多少个答案（固定为5）\n",
    "    ANSWER_CONCURRENCY: int = 5\n",
    "    \n",
    "    # ==================== 数据文件配置 ====================\n",
    "    # 这部分配置定义了各种数据文件的路径和格式\n",
    "    \n",
    "    # 支持的数据文件格式列表\n",
    "    # 程序会自动识别这些格式的文件\n",
    "    SUPPORTED_FILE_FORMATS: List[str] = [\".json\", \".jsonl\", \".txt\", \".csv\"]\n",
    "    \n",
    "    # SFT训练数据的文件路径列表\n",
    "    # 可以是多个文件，程序会自动合并处理\n",
    "    SFT_DATA_FILES: List[str] = []\n",
    "    \n",
    "    # 源文章数据的文件路径列表\n",
    "    # 这些是用来生成新问题的基础文档\n",
    "    SOURCE_ARTICLES_FILES: List[str] = []\n",
    "    \n",
    "    # 输出目录路径\n",
    "    # 所有生成的文件都会保存在这个目录下\n",
    "    OUTPUT_DIR: str = os.getenv(\"DEFAULT_OUTPUT_DIR\", \"./reward_model_data\")\n",
    "    \n",
    "    # ==================== 数据生成配置 ====================\n",
    "    # 这部分配置控制数据生成的数量和比例\n",
    "    \n",
    "    # 总共要生成的问题数量\n",
    "    # 建议5000个问题，可以根据需要调整\n",
    "    TOTAL_QUESTIONS: int = int(os.getenv(\"DEFAULT_TOTAL_QUESTIONS\", \"5000\"))\n",
    "    \n",
    "    # 从SFT数据中提取问题的比例\n",
    "    # 0.3表示30%的问题来自已有的SFT数据\n",
    "    SFT_QUESTION_RATIO: float = float(os.getenv(\"DEFAULT_SFT_RATIO\", \"0.3\"))\n",
    "    \n",
    "    # 每个问题生成的答案数量\n",
    "    # 5个不同质量等级的答案，用于构建偏好对\n",
    "    ANSWERS_PER_QUESTION: int = 5\n",
    "    \n",
    "    # 随机种子，用于确保结果可重现\n",
    "    # 相同的种子会产生相同的随机结果\n",
    "    RANDOM_SEED: int = int(os.getenv(\"DEFAULT_RANDOM_SEED\", \"42\"))\n",
    "    \n",
    "    # 批处理大小，每处理这么多条数据就保存一次\n",
    "    # 防止程序崩溃时丢失太多数据\n",
    "    BATCH_SIZE: int = int(os.getenv(\"BATCH_SIZE\", \"10\"))\n",
    "    \n",
    "    # ==================== 日志配置 ====================\n",
    "    LOG_LEVEL: str = os.getenv(\"LOG_LEVEL\", \"INFO\")\n",
    "    \n",
    "    # ==================== 质量等级配置 ====================\n",
    "    # 定义5个不同质量等级的答案要求\n",
    "    \n",
    "    QUALITY_LEVELS: Dict[int, Dict[str, str]] = {\n",
    "        1: {\n",
    "            \"name\": \"低质量答案\",\n",
    "            \"description\": \"逻辑混乱，信息不准确，分析浅显\",\n",
    "            \"instruction\": \"\"\"请生成一个质量较低的回答，具体要求：\n",
    "1. 逻辑不够清晰，分析比较浅显\n",
    "2. 可能包含一些不够准确的信息（但不能完全错误）\n",
    "3. 思考过程简单，缺乏深度分析\n",
    "4. 但仍然要使用<think>标签包裹思考过程\n",
    "5. 答案要有一定的相关性，不能完全偏题\"\"\"\n",
    "        },\n",
    "        2: {\n",
    "            \"name\": \"中低质量答案\", \n",
    "            \"description\": \"基本正确但分析不够深入\",\n",
    "            \"instruction\": \"\"\"请生成一个中等偏低质量的回答，具体要求：\n",
    "1. 基本信息正确但分析不够深入\n",
    "2. 思考过程相对简单，缺少一些关键步骤\n",
    "3. 缺乏一些重要的金融专业见解\n",
    "4. 使用<think>标签包裹思考过程\n",
    "5. 答案基本能解决问题但不够全面\"\"\"\n",
    "        },\n",
    "        3: {\n",
    "            \"name\": \"中等质量答案\",\n",
    "            \"description\": \"正确但不够全面\", \n",
    "            \"instruction\": \"\"\"请生成一个中等质量的回答，具体要求：\n",
    "1. 信息准确，逻辑基本清晰\n",
    "2. 有一定的专业分析但覆盖面不够全面\n",
    "3. 思考过程较为完整，有基本的分析步骤\n",
    "4. 使用<think>标签包裹思考过程\n",
    "5. 能够解决问题但可能遗漏一些重要方面\"\"\"\n",
    "        },\n",
    "        4: {\n",
    "            \"name\": \"中高质量答案\",\n",
    "            \"description\": \"专业且全面\",\n",
    "            \"instruction\": \"\"\"请生成一个中等偏高质量的回答，具体要求：\n",
    "1. 信息准确，分析专业且较为全面\n",
    "2. 逻辑清晰，有较深度的金融专业见解\n",
    "3. 思考过程详细且有条理，考虑多个角度\n",
    "4. 使用<think>标签包裹思考过程\n",
    "5. 能够很好地解决问题，分析比较深入\"\"\"\n",
    "        },\n",
    "        5: {\n",
    "            \"name\": \"高质量答案\",\n",
    "            \"description\": \"专业、全面、深入\",\n",
    "            \"instruction\": \"\"\"请生成一个高质量的回答，具体要求：\n",
    "1. 信息非常准确，分析专业且全面深入\n",
    "2. 逻辑非常清晰，有独到的金融专业见解\n",
    "3. 思考过程非常详细，考虑多个维度和可能性\n",
    "4. 使用<think>标签包裹思考过程，展现完整的分析链条\n",
    "5. 完美解决问题，提供深刻洞察和实用建议\"\"\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # ==================== 文件命名配置 ====================\n",
    "    # 定义各种输出文件的名称\n",
    "    \n",
    "    # 采样后的SFT问题文件名\n",
    "    SAMPLED_SFT_QUESTIONS_FILE: str = \"sampled_sft_questions.jsonl\"\n",
    "    \n",
    "    # 采样后的文章文件名\n",
    "    SAMPLED_ARTICLES_FILE: str = \"sampled_articles.jsonl\"\n",
    "    \n",
    "    # 生成的新问题文件名\n",
    "    GENERATED_QUESTIONS_FILE: str = \"generated_questions.jsonl\"\n",
    "    \n",
    "    # 混合问题文件名（第一阶段输出）\n",
    "    MIXED_QUESTIONS_FILE: str = \"all_questions_mixed.jsonl\"\n",
    "    \n",
    "    # 生成答案文件名（第二阶段输出）\n",
    "    GENERATED_ANSWERS_FILE: str = \"generated_answers.jsonl\"\n",
    "    \n",
    "    # 偏好对文件名（用于训练奖励模型）\n",
    "    PREFERENCE_PAIRS_FILE: str = \"preference_pairs.jsonl\"\n",
    "    \n",
    "    # 统计报告文件名\n",
    "    STATISTICS_REPORT_FILE: str = \"generation_report.json\"\n",
    "    \n",
    "    # 错误日志文件名\n",
    "    ERROR_LOG_FILE: str = \"error_log.txt\"\n",
    "    \n",
    "    # ==================== 数据验证配置 ====================\n",
    "    # 用于验证生成数据质量的配置\n",
    "    \n",
    "    # SFT数据必须包含的字段\n",
    "    # 这些字段是SFT数据文件必须要有的，缺少会报错\n",
    "    REQUIRED_SFT_FIELDS: List[str] = [\"input\"]  # SFT数据主要需要input字段作为问题\n",
    "    \n",
    "    # 源文章数据必须包含的字段\n",
    "    # 这些字段是源文章文件必须要有的\n",
    "    REQUIRED_ARTICLE_FIELDS: List[str] = [\"Article\"]  # 文章数据需要Article字段\n",
    "    \n",
    "    # 问题的最小长度（字符数）\n",
    "    # 太短的问题质量通常不高\n",
    "    MIN_QUESTION_LENGTH: int = 20\n",
    "    \n",
    "    # 答案的最小长度（字符数）\n",
    "    # 太短的答案通常不够详细\n",
    "    MIN_ANSWER_LENGTH: int = 100\n",
    "    \n",
    "    @classmethod\n",
    "    def validate_config(cls) -> bool:\n",
    "        \"\"\"\n",
    "        验证配置是否正确\n",
    "        \n",
    "        这个方法会检查所有重要的配置项是否设置正确\n",
    "        就像开车前检查油量、轮胎一样，确保程序能正常运行\n",
    "        \n",
    "        Returns:\n",
    "            bool: 如果配置正确返回True，否则返回False\n",
    "        \"\"\"\n",
    "        errors = []  # 用来收集所有的错误信息\n",
    "        \n",
    "        # 检查API密钥是否设置\n",
    "        # API密钥就像身份证，没有它就无法调用AI服务\n",
    "        if not cls.DEEPSEEK_API_KEY:\n",
    "            errors.append(\"DEEPSEEK_API_KEY 未设置，请在.env文件中设置或通过环境变量提供\")\n",
    "        \n",
    "        # 检查比例参数是否合理\n",
    "        # 比例必须在0到1之间，超出范围就不合理\n",
    "        if not 0 <= cls.SFT_QUESTION_RATIO <= 1:\n",
    "            errors.append(\"SFT_QUESTION_RATIO 必须在0到1之间\")\n",
    "        \n",
    "        # 检查数量参数是否为正数\n",
    "        # 负数或零没有意义\n",
    "        if cls.TOTAL_QUESTIONS <= 0:\n",
    "            errors.append(\"TOTAL_QUESTIONS 必须大于0\")\n",
    "        \n",
    "        if cls.ANSWERS_PER_QUESTION <= 0:\n",
    "            errors.append(\"ANSWERS_PER_QUESTION 必须大于0\")\n",
    "        \n",
    "        # 如果有错误，打印出来并返回False\n",
    "        if errors:\n",
    "            print(\"配置验证失败，发现以下错误：\")\n",
    "            for i, error in enumerate(errors, 1):\n",
    "                print(f\"{i}. {error}\")\n",
    "            return False\n",
    "        \n",
    "        print(\"配置验证通过！\")\n",
    "        return True\n",
    "    \n",
    "    @classmethod\n",
    "    def get_output_paths(cls) -> Dict[str, Path]:\n",
    "        \"\"\"\n",
    "        获取所有输出文件的完整路径\n",
    "        \n",
    "        这个方法会返回一个字典，包含所有输出文件的路径\n",
    "        方便其他模块使用，避免路径拼接错误\n",
    "        \n",
    "        Returns:\n",
    "            Dict[str, Path]: 包含所有输出文件路径的字典\n",
    "        \"\"\"\n",
    "        output_dir = Path(cls.OUTPUT_DIR)\n",
    "        \n",
    "        return {\n",
    "            \"output_dir\": output_dir,\n",
    "            \"sampled_sft_questions\": output_dir / cls.SAMPLED_SFT_QUESTIONS_FILE,\n",
    "            \"sampled_articles\": output_dir / cls.SAMPLED_ARTICLES_FILE,\n",
    "            \"generated_questions\": output_dir / cls.GENERATED_QUESTIONS_FILE,\n",
    "            \"mixed_questions\": output_dir / cls.MIXED_QUESTIONS_FILE,\n",
    "            \"generated_answers\": output_dir / cls.GENERATED_ANSWERS_FILE,\n",
    "            \"preference_pairs\": output_dir / cls.PREFERENCE_PAIRS_FILE,\n",
    "            \"statistics_report\": output_dir / cls.STATISTICS_REPORT_FILE,\n",
    "            \"error_log\": output_dir / cls.ERROR_LOG_FILE\n",
    "        }\n",
    "\n",
    "    # ==================== 属性访问方法 ====================\n",
    "    @property\n",
    "    def api_key(self):\n",
    "        \"\"\"获取API密钥\"\"\"\n",
    "        return self.DEEPSEEK_API_KEY\n",
    "    \n",
    "    @property\n",
    "    def base_url(self):\n",
    "        \"\"\"获取API基础URL\"\"\"\n",
    "        return self.DEEPSEEK_BASE_URL\n",
    "    \n",
    "    @property\n",
    "    def model_name(self):\n",
    "        \"\"\"获取模型名称\"\"\"\n",
    "        return self.MODEL_NAME\n",
    "    \n",
    "    @property\n",
    "    def temperature(self):\n",
    "        \"\"\"获取温度参数\"\"\"\n",
    "        return self.TEMPERATURE\n",
    "    \n",
    "    @property\n",
    "    def max_tokens(self):\n",
    "        \"\"\"获取最大token数\"\"\"\n",
    "        return self.MAX_TOKENS\n",
    "    \n",
    "    @property\n",
    "    def request_interval(self):\n",
    "        \"\"\"获取请求间隔\"\"\"\n",
    "        return self.API_CALL_INTERVAL\n",
    "    \n",
    "    @property\n",
    "    def max_workers(self):\n",
    "        \"\"\"获取最大工作线程数\"\"\"\n",
    "        return self.MAX_WORKERS\n",
    "    \n",
    "    @property\n",
    "    def output_dir(self):\n",
    "        \"\"\"获取输出目录\"\"\"\n",
    "        return self.OUTPUT_DIR\n",
    "    \n",
    "    @property\n",
    "    def batch_size(self):\n",
    "        \"\"\"获取批处理大小\"\"\"\n",
    "        return self.BATCH_SIZE\n",
    "\n",
    "def create_argument_parser():\n",
    "    \"\"\"\n",
    "    创建命令行参数解析器\n",
    "    \n",
    "    这个函数定义了所有可用的命令行参数\n",
    "    让用户可以通过命令行灵活控制程序行为\n",
    "    \n",
    "    Returns:\n",
    "        argparse.ArgumentParser: 配置好的参数解析器\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "            description='金融领域奖励模型数据生成工具',\n",
    "            formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "            epilog=\"\"\"\n",
    "使用示例:\n",
    "\n",
    "1. 完整流程（推荐）:\n",
    "   python main.py --stage all --sft_data_path ./sft_data.jsonl --base_articles_path ./articles.jsonl\n",
    "\n",
    "2. 分阶段执行:\n",
    "   # 第一步：数据采样\n",
    "   python main.py --stage sample --sft_data_path ./sft_data.jsonl --base_articles_path ./articles.jsonl\n",
    "   \n",
    "   # 第二步：问题生成\n",
    "   python main.py --stage questions\n",
    "   \n",
    "   # 第三步：答案生成\n",
    "   python main.py --stage answers --max_questions 100 --concurrency_num 3\n",
    "\n",
    "3. 自定义参数:\n",
    "   python main.py --stage all --total_questions 3000 --sft_ratio 0.4 --output_dir ./my_data\n",
    "\n",
    "注意：\n",
    "- API密钥会自动从.env文件或环境变量中读取\n",
    "- 默认使用DeepSeek API\n",
    "- 所有生成的文件都会保存在输出目录中\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # === 执行阶段控制 ===\n",
    "    # 这是最重要的参数，决定程序执行哪个阶段\n",
    "    parser.add_argument(\n",
    "        '--stage', \n",
    "            type=str, \n",
    "        choices=['sample', 'questions', 'answers', 'all'], \n",
    "        default='all',\n",
    "        help=\"\"\"执行阶段选择：\n",
    "        sample - 仅执行数据采样（从原始数据中选择用于训练的子集）\n",
    "        questions - 仅执行问题生成（从文章生成新问题）\n",
    "        answers - 仅执行答案生成（为问题生成不同质量的答案）\n",
    "        all - 执行完整流程（默认选项）\"\"\"\n",
    "        )\n",
    "        \n",
    "        # === 数据路径配置 ===\n",
    "    # 这些参数指定输入数据的位置\n",
    "    data_group = parser.add_argument_group('数据路径配置', '指定输入数据文件的位置')\n",
    "    data_group.add_argument(\n",
    "            '--sft_data_path', \n",
    "            type=str, \n",
    "        help=\"\"\"SFT训练数据文件路径（JSONL格式）\n",
    "        文件应包含以下字段：\n",
    "        - instruction: 任务指令（可选）\n",
    "        - input: 问题内容（必需）\n",
    "        - output: 期望答案（可选）\n",
    "        \n",
    "        示例：{\"instruction\": \"分析以下情况\", \"input\": \"某公司股价下跌的原因\", \"output\": \"...\"}\"\"\"\n",
    "        )\n",
    "    data_group.add_argument(\n",
    "            '--base_articles_path', \n",
    "            type=str, \n",
    "        help=\"\"\"基础文章数据文件路径（JSONL格式）\n",
    "        文件应包含以下字段：\n",
    "        - Article: 文章内容（必需）\n",
    "        - Summary: 文章摘要（可选）\n",
    "        \n",
    "        示例：{\"Article\": \"金融市场分析...\", \"Summary\": \"本文分析了...\"}\"\"\"\n",
    "        )\n",
    "    data_group.add_argument(\n",
    "            '--output_dir', \n",
    "            type=str, \n",
    "        default=Config.OUTPUT_DIR, \n",
    "        help=f'输出目录路径，所有生成的文件都会保存在这里（默认：{Config.OUTPUT_DIR}）'\n",
    "        )\n",
    "        \n",
    "        # === 数据采样配置 ===\n",
    "    # 这些参数控制数据采样的行为\n",
    "    sample_group = parser.add_argument_group('数据采样配置', '控制如何从原始数据中选择训练样本')\n",
    "    sample_group.add_argument(\n",
    "        '--total_questions', \n",
    "        type=int, \n",
    "    default=Config.TOTAL_QUESTIONS, \n",
    "    help=f'总问题数量，程序会生成这么多个问题用于训练（默认：{Config.TOTAL_QUESTIONS}）'\n",
    "    )\n",
    "    sample_group.add_argument(\n",
    "        '--sft_ratio', \n",
    "        type=float, \n",
    "    default=Config.SFT_QUESTION_RATIO, \n",
    "    help=f\"\"\"SFT数据占比，取值范围0-1\n",
    "    例如0.3表示30%%的问题来自SFT数据，70%%来自新生成的问题\n",
    "    （默认：{Config.SFT_QUESTION_RATIO}）\"\"\"\n",
    "    )\n",
    "    sample_group.add_argument(\n",
    "        '--random_seed', \n",
    "        type=int, \n",
    "    default=Config.RANDOM_SEED, \n",
    "        help=f'随机种子，确保结果可重现。相同种子会产生相同的随机结果（默认：{Config.RANDOM_SEED}）'\n",
    "    )\n",
    "    \n",
    "    # === 答案生成专用配置 ===\n",
    "    answer_group = parser.add_argument_group('答案生成配置', '控制答案生成阶段的行为')\n",
    "    answer_group.add_argument(\n",
    "        '--max_questions', \n",
    "        type=int, \n",
    "        help='最大处理问题数（用于测试或限制处理量）'\n",
    "    )\n",
    "    answer_group.add_argument(\n",
    "        '--concurrency_num', \n",
    "        type=int, \n",
    "        default=Config.CONCURRENCY_NUM,\n",
    "        help=f'并发数量，同时处理多少个问题（默认：{Config.CONCURRENCY_NUM}）'\n",
    "        )\n",
    "        \n",
    "        # === 生成配置 ===\n",
    "    # 这些参数控制AI生成的行为\n",
    "    gen_group = parser.add_argument_group('生成配置', '控制AI生成问题和答案的行为')\n",
    "    gen_group.add_argument(\n",
    "        '--max_workers', \n",
    "        type=int, \n",
    "    default=Config.MAX_WORKERS, \n",
    "    help=f\"\"\"最大并发线程数，控制同时进行的API调用数量\n",
    "    数值越大生成越快，但可能触发API频率限制\n",
    "    建议根据API服务商的限制调整（默认：{Config.MAX_WORKERS}）\"\"\"\n",
    "    )\n",
    "    gen_group.add_argument(\n",
    "        '--request_interval', \n",
    "        type=float, \n",
    "    default=Config.API_CALL_INTERVAL, \n",
    "    help=f\"\"\"API请求间隔（秒），每次API调用之间的等待时间\n",
    "    用于避免触发频率限制，数值越大越安全但生成越慢\n",
    "    （默认：{Config.API_CALL_INTERVAL}秒）\"\"\"\n",
    "    )\n",
    "    gen_group.add_argument(\n",
    "        '--batch_size', \n",
    "        type=int, \n",
    "        default=Config.BATCH_SIZE, \n",
    "        help=f\"\"\"批处理大小，每处理这么多条数据就保存一次\n",
    "        用于防止程序崩溃时丢失数据，建议10-50之间\n",
    "        （默认：{Config.BATCH_SIZE}）\"\"\"\n",
    "    )\n",
    "    \n",
    "    # === 系统配置 ===\n",
    "    system_group = parser.add_argument_group('系统配置', '控制程序运行行为的系统参数')\n",
    "    system_group.add_argument(\n",
    "        '--log_level', \n",
    "        type=str, \n",
    "        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], \n",
    "        default=Config.LOG_LEVEL,\n",
    "        help=f'日志级别（默认：{Config.LOG_LEVEL}）'\n",
    "    )\n",
    "    \n",
    "    # === 高级选项 ===\n",
    "    # 这些是一些高级用户可能需要的选项\n",
    "    advanced_group = parser.add_argument_group('高级选项', '高级用户可能需要的特殊选项')\n",
    "    advanced_group.add_argument(\n",
    "        '--start_index', \n",
    "        type=int, \n",
    "        default=0, \n",
    "        help=\"\"\"开始处理的索引位置，用于断点续传\n",
    "        如果程序中途中断，可以从指定位置继续处理\n",
    "        例如--start_index 1000表示从第1001个问题开始处理\"\"\"\n",
    "    )\n",
    "    advanced_group.add_argument(\n",
    "        '--api_key_override', \n",
    "        type=str, \n",
    "        help=\"\"\"临时覆盖API密钥，仅在特殊情况下使用\n",
    "        正常情况下请在.env文件中设置DEEPSEEK_API_KEY\n",
    "        注意：命令行中的密钥可能被其他用户看到，存在安全风险\"\"\"\n",
    "    )\n",
    "    advanced_group.add_argument(\n",
    "        '--base_url_override', \n",
    "            type=str, \n",
    "        help=f\"\"\"临时覆盖API基础URL，用于使用自定义API端点\n",
    "        （默认：{Config.DEEPSEEK_BASE_URL}）\"\"\"\n",
    "    )\n",
    "    advanced_group.add_argument(\n",
    "        '--verbose', \n",
    "        action='store_true', \n",
    "        help='启用详细输出模式，显示更多调试信息'\n",
    "    )\n",
    "    \n",
    "    return parser\n",
    "\n",
    "def parse_and_validate_args():\n",
    "    \"\"\"\n",
    "    解析并验证命令行参数\n",
    "    \n",
    "    这个函数会：\n",
    "    1. 解析用户输入的命令行参数\n",
    "    2. 验证参数的有效性\n",
    "    3. 更新配置类的设置\n",
    "    4. 返回验证后的参数\n",
    "    \n",
    "    Returns:\n",
    "        argparse.Namespace: 解析后的参数对象\n",
    "    \n",
    "    Raises:\n",
    "        SystemExit: 如果参数验证失败\n",
    "    \"\"\"\n",
    "    parser = create_argument_parser()\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # 验证必需的参数\n",
    "    # 某些阶段需要特定的输入文件\n",
    "    if args.stage in ['sample', 'all']:\n",
    "        if not args.sft_data_path:\n",
    "            parser.error(\"执行sample或all阶段时，必须提供--sft_data_path参数\")\n",
    "        if not args.base_articles_path:\n",
    "            parser.error(\"执行sample或all阶段时，必须提供--base_articles_path参数\")\n",
    "        \n",
    "        # 检查文件是否存在\n",
    "        sft_paths = [path.strip() for path in args.sft_data_path.split(',')]\n",
    "        for sft_path in sft_paths:\n",
    "            if not os.path.exists(sft_path):\n",
    "                parser.error(f\"SFT数据文件不存在: {sft_path}\")\n",
    "        \n",
    "        if not os.path.exists(args.base_articles_path):\n",
    "            parser.error(f\"基础文章文件不存在: {args.base_articles_path}\")\n",
    "        \n",
    "        # 验证参数范围\n",
    "    if not 0 <= args.sft_ratio <= 1:\n",
    "        parser.error(\"sft_ratio必须在0和1之间\")\n",
    "    if args.total_questions <= 0:\n",
    "        parser.error(\"total_questions必须大于0\")\n",
    "    if args.sft_ratio <= 0:\n",
    "        parser.error(\"sft_ratio必须大于0\")\n",
    "    if args.max_workers <= 0:\n",
    "        parser.error(\"max_workers必须大于0\")\n",
    "    if args.request_interval < 0:\n",
    "        parser.error(\"request_interval不能为负数\")\n",
    "    \n",
    "    # 更新配置类\n",
    "    # 将命令行参数应用到配置类中\n",
    "    if args.api_key_override:\n",
    "        Config.DEEPSEEK_API_KEY = args.api_key_override\n",
    "        print(\"警告：使用命令行提供的API密钥，请注意安全风险\")\n",
    "    \n",
    "    if args.base_url_override:\n",
    "        Config.DEEPSEEK_BASE_URL = args.base_url_override\n",
    "    \n",
    "    Config.OUTPUT_DIR = args.output_dir\n",
    "    Config.TOTAL_QUESTIONS = args.total_questions\n",
    "    Config.SFT_QUESTION_RATIO = args.sft_ratio\n",
    "    Config.RANDOM_SEED = args.random_seed\n",
    "    Config.MAX_WORKERS = args.max_workers\n",
    "    Config.API_CALL_INTERVAL = args.request_interval\n",
    "    Config.BATCH_SIZE = args.batch_size\n",
    "    Config.CONCURRENCY_NUM = getattr(args, 'concurrency_num', Config.CONCURRENCY_NUM)\n",
    "    Config.LOG_LEVEL = args.log_level\n",
    "        \n",
    "        # 设置随机种子，确保结果可重现\n",
    "    random.seed(args.random_seed)\n",
    "        \n",
    "        # 创建输出目录\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "        \n",
    "    # 验证最终配置\n",
    "    if not Config.validate_config():\n",
    "        parser.error(\"配置验证失败，请检查上述错误信息\")\n",
    "    \n",
    "    # 显示配置摘要\n",
    "    print(f\"\\n=== 配置摘要 ===\")\n",
    "    print(f\"执行阶段: {args.stage}\")\n",
    "    print(f\"输出目录: {args.output_dir}\")\n",
    "    if hasattr(args, 'max_questions') and args.max_questions:\n",
    "        print(f\"限制问题数: {args.max_questions}\")\n",
    "    if hasattr(args, 'concurrency_num'):\n",
    "        print(f\"并发数量: {args.concurrency_num}\")\n",
    "    print(f\"总问题数: {args.total_questions}\")\n",
    "    print(f\"SFT数据比例: {args.sft_ratio:.1%}\")\n",
    "    print(f\"随机种子: {args.random_seed}\")\n",
    "    print(f\"日志级别: {args.log_level}\")\n",
    "    print(f\"最大并发数: {args.max_workers}\")\n",
    "    print(f\"API间隔: {args.request_interval}秒\")\n",
    "    if hasattr(args, 'sft_data_path') and args.sft_data_path:\n",
    "        print(f\"SFT数据文件: {args.sft_data_path}\")\n",
    "    if hasattr(args, 'base_articles_path') and args.base_articles_path:\n",
    "        print(f\"文章数据文件: {args.base_articles_path}\")\n",
    "    print(f\"API服务: DeepSeek ({Config.DEEPSEEK_BASE_URL})\")\n",
    "    print(\"=\" * 50)\n",
    "        \n",
    "    return args\n",
    "\n",
    "# 查看配置文件\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc742aa",
   "metadata": {},
   "source": [
    "\n",
    "`main.py` - 项目主程序入口\n",
    "   - 作用：协调整个数据生成流程的执行\n",
    "   - 功能：问题生成 → 答案生成 → 数据拆分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "金融领域奖励模型数据生成 - 主程序\n",
    "支持可控并发的高效数据生成\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# 导入项目模块\n",
    "from config import Config, parse_and_validate_args\n",
    "from data_processor import DataProcessor\n",
    "from question_generator import QuestionGenerator\n",
    "from answer_generator import AnswerGenerator\n",
    "from data_splitter import DataSplitter\n",
    "from utils import setup_logging, ensure_directory_exists, save_jsonl_file, load_jsonl_file\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    try:\n",
    "        # 解析命令行参数\n",
    "        args = parse_and_validate_args()\n",
    "        \n",
    "        # 设置日志\n",
    "        setup_logging(args.log_level)\n",
    "        \n",
    "        # 创建配置对象\n",
    "        config = Config()\n",
    "        \n",
    "        # 更新配置中的并发参数\n",
    "        config.CONCURRENCY_NUM = args.concurrency_num\n",
    "        \n",
    "        logging.info(\"=\" * 60)\n",
    "        logging.info(\"金融领域奖励模型数据生成工具启动\")\n",
    "        logging.info(\"=\" * 60)\n",
    "        \n",
    "        # 验证参数\n",
    "        logging.info(\"参数验证通过\")\n",
    "        \n",
    "        # 显示配置信息\n",
    "        if args.stage in [\"questions\", \"all\"]:\n",
    "            sft_question_count = int(args.total_questions * args.sft_ratio)\n",
    "            new_question_count = args.total_questions - sft_question_count\n",
    "            sft_files = args.sft_data_path.split(',')\n",
    "            \n",
    "            logging.info(\"配置信息:\")\n",
    "            logging.info(f\"  执行阶段: {args.stage}\")\n",
    "            logging.info(f\"  总问题数: {args.total_questions}\")\n",
    "            logging.info(f\"  SFT问题数: {sft_question_count} ({args.sft_ratio*100:.1f}%)\")\n",
    "            logging.info(f\"  新生成问题数: {new_question_count} ({(1-args.sft_ratio)*100:.1f}%)\")\n",
    "            logging.info(f\"  SFT数据文件: {len(sft_files)} 个\")\n",
    "            logging.info(f\"  问题生成并发数: {args.concurrency_num}\")\n",
    "        \n",
    "        if args.stage in [\"answers\", \"all\"]:\n",
    "            logging.info(f\"  并发设置:\")\n",
    "            logging.info(f\"    问题级别并发数: {args.concurrency_num}\")\n",
    "            logging.info(f\"    答案级别并发数: 5 (固定)\")\n",
    "            if args.max_questions:\n",
    "                logging.info(f\"  限制处理数量: {args.max_questions}\")\n",
    "        \n",
    "        logging.info(f\"  输出目录: {args.output_dir}\")\n",
    "        logging.info(f\"  随机种子: {args.random_seed}\")\n",
    "        \n",
    "        # 创建输出目录\n",
    "        output_dir = Path(args.output_dir)\n",
    "        ensure_directory_exists(output_dir)\n",
    "        logging.info(f\"输出目录已创建: {output_dir.absolute()}\")\n",
    "        \n",
    "        # 初始化组件\n",
    "        logging.info(\"初始化组件...\")\n",
    "        data_processor = DataProcessor(args.random_seed)\n",
    "        \n",
    "        # 执行问题生成阶段\n",
    "        if args.stage in [\"questions\", \"all\"]:\n",
    "            logging.info(\"=\" * 40)\n",
    "            logging.info(\"开始问题生成阶段\")\n",
    "            logging.info(\"=\" * 40)\n",
    "            \n",
    "            # 加载数据\n",
    "            logging.info(\"加载数据文件...\")\n",
    "            sft_file_paths = [path.strip() for path in args.sft_data_path.split(',')]\n",
    "            sft_data = data_processor.load_sft_data(sft_file_paths)\n",
    "            base_articles = data_processor.load_base_articles(args.base_articles_path)\n",
    "            \n",
    "            # 从SFT数据中提取问题\n",
    "            logging.info(\"从SFT数据中提取问题...\")\n",
    "            sft_question_count = int(args.total_questions * args.sft_ratio)\n",
    "            sft_questions = data_processor.extract_questions_from_sft(sft_data, sft_question_count)\n",
    "            \n",
    "            # 生成新问题\n",
    "            logging.info(\"基于基础文章生成新问题...\")\n",
    "            new_question_count = args.total_questions - len(sft_questions)\n",
    "            question_generator = QuestionGenerator(\n",
    "                config, \n",
    "                str(output_dir), \n",
    "                concurrency_level=args.concurrency_num\n",
    "            )\n",
    "            sampled_articles = data_processor.sample_articles_for_generation(base_articles, new_question_count)\n",
    "            new_questions = question_generator.generate_questions_from_articles(sampled_articles)\n",
    "            \n",
    "            # 合并问题\n",
    "            logging.info(\"合并问题...\")\n",
    "            all_questions = data_processor.combine_questions(sft_questions, new_questions)\n",
    "            \n",
    "            # 保存问题\n",
    "            questions_file = output_dir / \"questions.jsonl\"\n",
    "            questions_data = [{\"question\": q, \"id\": i} for i, q in enumerate(all_questions)]\n",
    "            save_jsonl_file(questions_data, str(questions_file))\n",
    "            \n",
    "            logging.info(\"✅ 问题生成完成！\")\n",
    "            logging.info(f\"   文件位置: {questions_file.absolute()}\")\n",
    "            logging.info(f\"   问题总数: {len(all_questions)}\")\n",
    "        \n",
    "        # 执行答案生成阶段\n",
    "        if args.stage in [\"answers\", \"all\"]:\n",
    "            logging.info(\"=\" * 40)\n",
    "            logging.info(\"开始答案生成阶段\")\n",
    "            logging.info(\"=\" * 40)\n",
    "            \n",
    "            # 读取问题文件\n",
    "            questions_file = output_dir / \"questions.jsonl\"\n",
    "            logging.info(f\"读取问题文件: {questions_file}\")\n",
    "            questions = load_jsonl_file(str(questions_file))\n",
    "            \n",
    "            if args.max_questions:\n",
    "                logging.info(f\"限制处理数量为: {args.max_questions}\")\n",
    "                logging.info(f\"将处理 {min(args.max_questions, len(questions))} 个问题\")\n",
    "            \n",
    "            # 初始化答案生成器（传入并发参数）\n",
    "            answer_generator = AnswerGenerator(\n",
    "                config, \n",
    "                str(output_dir),\n",
    "                concurrency_level=args.concurrency_num\n",
    "            )\n",
    "            \n",
    "            # 生成答案和偏好对\n",
    "            logging.info(\"开始生成答案...\")\n",
    "            results = answer_generator.generate_preference_dataset(\n",
    "                questions, \n",
    "                max_questions=args.max_questions\n",
    "            )\n",
    "            \n",
    "            logging.info(\"✅ 答案生成完成！\")\n",
    "            logging.info(f\"   处理问题数: {results['total_questions']}\")\n",
    "            logging.info(f\"   合并文件: {results['merged_file_path']}\")\n",
    "        \n",
    "        # 执行数据拆分阶段（仅在stage为all时自动执行）\n",
    "        if args.stage == \"all\":\n",
    "            logging.info(\"=\" * 40)\n",
    "            logging.info(\"开始数据拆分阶段\")\n",
    "            logging.info(\"=\" * 40)\n",
    "            \n",
    "            # 检查合并文件是否存在\n",
    "            merged_file = output_dir / \"complete_qa_dataset.jsonl\"\n",
    "            if not merged_file.exists():\n",
    "                logging.error(f\"未找到合并文件: {merged_file}\")\n",
    "                raise FileNotFoundError(f\"合并文件不存在: {merged_file}\")\n",
    "            \n",
    "            # 创建数据拆分器\n",
    "            data_splitter = DataSplitter(\n",
    "                input_dir=str(output_dir),\n",
    "                output_dir=str(output_dir),\n",
    "                random_seed=args.random_seed\n",
    "            )\n",
    "            \n",
    "            # 执行数据拆分\n",
    "            logging.info(\"执行数据拆分...\")\n",
    "            data_splitter.split_and_save(\n",
    "                train_ratio=0.8,\n",
    "                eval_ratio=0.1,\n",
    "                test_ratio=0.1\n",
    "            )\n",
    "            \n",
    "            logging.info(\"✅ 数据拆分完成！\")\n",
    "        \n",
    "        logging.info(\"🎉 所有任务完成！\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        logging.warning(\"⚠️  用户中断程序执行\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"程序执行失败: {e}\")\n",
    "        logging.error(\"详细错误信息:\")\n",
    "        import traceback\n",
    "        logging.error(traceback.format_exc())\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624ed84",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620125717338.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f969ec7",
   "metadata": {},
   "source": [
    "split_report.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3e159",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"split_info\": {\n",
    "    \"random_seed\": 42,\n",
    "    \"split_ratios\": {\n",
    "      \"train\": 0.8,\n",
    "      \"eval\": 0.1,\n",
    "      \"test\": 0.1\n",
    "    }\n",
    "  },\n",
    "  \"dataset_statistics\": {\n",
    "    \"train\": {\n",
    "      \"questions\": 6,\n",
    "      \"preference_pairs\": 60\n",
    "    },\n",
    "    \"eval\": {\n",
    "      \"questions\": 2,\n",
    "      \"preference_pairs\": 20\n",
    "    },\n",
    "    \"test\": {\n",
    "      \"questions\": 3,\n",
    "      \"preference_pairs\": 30\n",
    "    },\n",
    "    \"total\": {\n",
    "      \"questions\": 11,\n",
    "      \"preference_pairs\": 110\n",
    "    }\n",
    "  },\n",
    "  \"file_structure\": {\n",
    "    \"train\": [\n",
    "      \"train/qa_dataset.jsonl\",\n",
    "      \"train/preference_dataset.jsonl\"\n",
    "    ],\n",
    "    \"eval\": [\n",
    "      \"eval/qa_dataset.jsonl\",\n",
    "      \"eval/preference_dataset.jsonl\"\n",
    "    ],\n",
    "    \"test\": [\n",
    "      \"test/qa_dataset.jsonl\",\n",
    "      \"test/preference_dataset.jsonl\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdcdb80",
   "metadata": {},
   "source": [
    "questions.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d98ac6",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"question\": \"根据最新交易数据，GameStop Corp (GME)今日期权交易总量达51,353份合约，对应约510万股标的股票，占该股过去一个月日均成交量1,110万股的46.5%。其中2024年1月19日到期、行权价127.50美元的看涨期权交易量尤为突出，达5,929份合约（对应592,900股）。Etsy Inc (ETSY)期权总交易量18,723份合约（对应190万股），占其月均成交量410万股的46.2%，2024年1月19日到期、行权价100美元的看涨期权交易量1,489份合约（对应148,900股）。Advance Auto Parts Inc (AAP)期权总交易量12,025份合约（对应120万股），占月均成交量270万股的44.7%，2024年1月12日到期、行权价45美元的看跌期权交易量7,006份合约（对应700,600股）。基于这些异常期权交易量和行权价分布情况，如何分析这三只股票在对应到期日附近的市场预期和潜在价格波动风险？请结合期权持仓集中度与标的股票历史波动特征进行说明。\", \"id\": 0}\n",
    "{\"question\": \"基于以下信息，请分析Arcos Dorados (ARCO)作为成长型股票的投资价值：1) 该公司当前获得Zacks成长风格评分系统中的A级成长评分和Zacks排名第1(强力买入)；2) 历史每股收益增长率为38%，预计今年每股收益增长18.8%，高于行业平均的17.9%；3) 资产利用率(S/TA)为1.52，显著高于行业平均的0.94；4) 预计今年销售额增长19.3%，远超行业平均的5.4%；5) 过去一个月当前年度盈利预期上调了9.3%。这些指标如何共同支持该股票作为成长型投资的合理性？在评估成长型股票时，为什么资产利用率指标和盈利预期修正趋势与传统的每股收益增长指标同样重要？\", \"id\": 1}\n",
    "{\"question\": \"麦当劳(MCD.N)于12月6日宣布，计划到2027年在全球新增约10,000家餐厅，使其总数达到约50,000家，覆盖100多个国家，这将是该公司历史上最快的扩张期。同时，麦当劳计划将其忠诚度计划的用户基数从目前的1.5亿活跃用户增加到2027年的2.5亿，预计将带来450亿美元的年销售额，而目前忠诚度计划用户贡献的系统销售额超过200亿美元。此外，麦当劳正在大力投资自动化流程和加快服务速度，包括与Alphabet(GOOGL.O)的Google Cloud合作部署人工智能解决方案，以及推广'Best Burger'计划以提高汉堡质量，该计划已扩展到70个市场，并计划到2026年覆盖几乎所有市场。尽管美国消费者支出面临压力，但由于其价格亲民的菜单和积极的促销活动，麦当劳在截至9月的季度中销售和利润均超出预期。2024年，麦当劳预计按固定汇率计算的系统销售额将增长近2%，高于2023年预期的1.5%，预计明年的营业利润率将在中高40%的范围内。在波动的盘前交易中，麦当劳股价小幅下跌。基于以上信息，请分析麦当劳的扩张计划、忠诚度计划增长目标以及自动化投资将如何影响其未来的财务表现和股价走势？\", \"id\": 2}\n",
    "{\"question\": \"Macerich (MAC)作为零售REIT公司，在最近一个季度(截至2023年9月30日)的财报显示：FFO每股0.44美元(扣除Chandler Freehold相关融资费用和应计违约利息支出)，与Zacks一致预期持平，但同比下降4.3%；季度营收2.182亿美元，同比增长3.6%，但低于预期的2.262亿美元。同中心NOI(含租赁终止收入)同比增长4.6%至1.947亿美元，低于预期的2.01亿美元。截至2023年9月30日，投资组合出租率达93.4%，高于去年同期的92.1%；重新租赁价差较到期基本租金高出10.6%。2023年前9个月签约租赁面积314万平方英尺，可比中心签约面积同比增长10%。截至2023年10月31日，公司拥有约6.65亿美元流动性。尽管财报后股价上涨15.8%，但过去一个月分析师预期呈下降趋势，Zacks评级为4(Sell)，VGM综合评分为B。同时，同行业公司Equinix(EQIX)同期股价上涨9.4%，Zacks评级为2(Buy)。基于这些数据，从基本面、行业比较和市场预期角度分析，Macerich股价在下一季度财报发布前继续上涨的可能性有多大？需要考虑哪些关键因素？\", \"id\": 3}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa7020",
   "metadata": {},
   "source": [
    "generation_report.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bfe26",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"generation_summary\": {\n",
    "    \"total_questions\": 11,\n",
    "    \"completed_questions\": 11,\n",
    "    \"successful_questions\": 11,\n",
    "    \"total_time_seconds\": 193.74196314811707,\n",
    "    \"questions_per_minute\": 3.4065929201689027\n",
    "  },\n",
    "  \"api_statistics\": {\n",
    "    \"total_api_calls\": 55,\n",
    "    \"successful_api_calls\": 55,\n",
    "    \"failed_api_calls\": 0,\n",
    "    \"success_rate\": 100.0\n",
    "  },\n",
    "  \"concurrency_settings\": {\n",
    "    \"question_concurrency\": 3,\n",
    "    \"answer_concurrency\": 5\n",
    "  },\n",
    "  \"file_locations\": {\n",
    "    \"batch_files_directory\": \"reward_data/answers\",\n",
    "    \"merged_file\": \"reward_data/complete_qa_dataset.jsonl\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3970f",
   "metadata": {},
   "source": [
    "generated_questions.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b13c6",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"question\": \"基于以下信息，请分析Arcos Dorados (ARCO)作为成长型股票的投资价值：1) 该公司当前获得Zacks成长风格评分系统中的A级成长评分和Zacks排名第1(强力买入)；2) 历史每股收益增长率为38%，预计今年每股收益增长18.8%，高于行业平均的17.9%；3) 资产利用率(S/TA)为1.52，显著高于行业平均的0.94；4) 预计今年销售额增长19.3%，远超行业平均的5.4%；5) 过去一个月当前年度盈利预期上调了9.3%。这些指标如何共同支持该股票作为成长型投资的合理性？在评估成长型股票时，为什么资产利用率指标和盈利预期修正趋势与传统的每股收益增长指标同样重要？\", \"source\": \"generated_from_article\", \"original_article_index\": -1}\n",
    "{\"question\": \"在Russell 3000指数的成分股中，达美航空(DAL)今日出现显著期权交易量，总计42,941份合约，对应约430万股标的股票，占该股过去一个月日均交易量910万股的47.3%。其中2024年1月19日到期的45美元看涨期权交易量尤为突出，今日已成交2,603份合约，对应约260,300股标的股票。California Resources Corp(CRC)期权交易量为2,170份合约，对应约217,000股标的股票，占过去一个月日均交易量460,790股的47.1%。2024年12月20日到期的35美元看跌期权交易活跃，今日已成交827份合约，对应约82,700股标的股票。Nuvalent Inc(NUVL)期权交易量为2,058份合约，对应约205,800股标的股票，占过去一个月日均交易量437,580股的47%。2024年4月19日到期的95美元看涨期权交易活跃，今日已成交2,002份合约，对应约200,200股标的股票。基于这些数据，如何分析这三只股票期权市场的流动性和投资者情绪？这些异常交易量可能预示着哪些市场动向或投资者策略？\", \"source\": \"generated_from_article\", \"original_article_index\": -1}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e5a6a",
   "metadata": {},
   "source": [
    "train/eval/test/ 下数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce80e06",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620125820168.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e536cc9",
   "metadata": {},
   "source": [
    "preference_dataset.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ec32f",
   "metadata": {},
   "source": [
    "```json\n",
    "拆解答案\n",
    "\n",
    "{\"question_id\": 7, \"question\": \"在Russell 3000指数的成分股中，达美航空(DAL)今日出现显著期权交易量，总计42,941份合约，对应约430万股标的股票，占该股过去一个月日均交易量910万股的47.3%。其中2024年1月19日到期的45美元看涨期权交易量尤为突出，今日已成交2,603份合约，对应约260,300股标的股票。California Resources Corp(CRC)期权交易量为2,170份合约，对应约217,000股标的股票，占过去一个月日均交易量460,790股的47.1%。2024年12月20日到期的35美元看跌期权交易活跃，今日已成交827份合约，对应约82,700股标的股票。Nuvalent Inc(NUVL)期权交易量为2,058份合约，对应约205,800股标的股票，占过去一个月日均交易量437,580股的47%。2024年4月19日到期的95美元看涨期权交易活跃，今日已成交2,002份合约，对应约200,200股标的股票。基于这些数据，如何分析这三只股票期权市场的流动性和投资者情绪？这些异常交易量可能预示着哪些市场动向或投资者策略？\", \"chosen\": \"<think>\\n1. 问题分析和理解：\\n- 题目给出了三只股票(DAL, CRC, NUVL)的期权交易数据\\n- 需要分析这些异常交易量反映的市场流动性和投资者情绪\\n- 还要推测可能的投资者策略和市场动向\\n\\n2. 相关金融概念和理论：\\n- 期权交易量可以反映市场流动性\\n- 异常交易量可能预示重大消息或投资者情绪变化\\n- 看涨期权交易活跃可能显示看涨情绪\\n- 看跌期权交易活跃可能显示看跌情绪\\n\\n3. 分析步骤和逻辑推理：\\n- 比较期权交易量与股票日均交易量的比例\\n- 观察是看涨还是看跌期权交易活跃\\n- 看期权到期日远近\\n- 简单推测投资者可能的方向性押注\\n\\n4. 结论推导过程：\\n- DAL看涨期权交易量大，可能有人看涨\\n- CRC看跌期权活跃，可能有人看跌\\n- NUVL看涨期权活跃，可能有人看涨\\n- 交易量都较大，流动性应该不错\\n</think>\\n\\n从数据来看，这三只股票的期权市场流动性都比较好，因为交易量占股票日均交易量的比例较高。DAL和NUVL的看涨期权交易活跃，可能显示投资者对这两只股票持乐观态度，特别是DAL的1月到期看涨期权交易量突出。CRC的看跌期权交易活跃，可能反映部分投资者看跌该股。这些异常交易量可能预示着投资者在进行方向性押注，DAL和NUVL可能有上涨预期，CRC可能有下跌预期。但具体原因还需要结合更多信息分析。\", \"rejected\": \"<think>\\n1. 问题分析和理解：这个问题问的是关于三只股票期权交易量和投资者情绪的分析。看起来DAL、CRC和NUVL的期权交易量都挺大的，特别是某些特定行权价和到期日的合约。\\n\\n2. 相关金融概念和理论：期权交易量可以反映流动性，交易量大的通常流动性好。看涨期权多可能说明投资者看涨，看跌期权多可能说明看跌。异常交易量可能有大资金在操作。\\n\\n3. 分析步骤和逻辑推理：\\n   - DAL的看涨期权交易量大，可能有人看涨\\n   - CRC的看跌期权交易量大，可能有人看跌\\n   - NUVL的看涨期权交易量大，可能有人看涨\\n   - 交易量都占到日均交易量的47%左右，这个数字挺大的\\n\\n4. 结论推导过程：因为交易量都很大，所以流动性应该不错。看涨期权多就是看涨，看跌期权多就是看跌。可能有大资金在布局。\\n</think>\\n\\n这三只股票的期权流动性看起来都不错，因为交易量都挺大的。DAL和NUVL的看涨期权交易活跃，可能投资者比较看好这两只股票。CRC的看跌期权交易多，可能有人不看好。交易量都占到日均交易量的47%左右，说明这些期权交易很活跃。可能是有些大资金在做对冲或者投机，但具体原因不太清楚。总的来说，期权交易量大说明市场对这些股票关注度高，但具体会涨会跌还要看其他因素。\", \"chosen_level\": 2, \"rejected_level\": 1, \"quality_gap\": 1}\n",
    "{\"question_id\": 7, \"question\": \"在Russell 3000指数的成分股中，达美航空(DAL)今日出现显著期权交易量，总计42,941份合约，对应约430万股标的股票，占该股过去一个月日均交易量910万股的47.3%。其中2024年1月19日到期的45美元看涨期权交易量尤为突出，今日已成交2,603份合约，对应约260,300股标的股票。California Resources Corp(CRC)期权交易量为2,170份合约，对应约217,000股标的股票，占过去一个月日均交易量460,790股的47.1%。2024年12月20日到期的35美元看跌期权交易活跃，今日已成交827份合约，对应约82,700股标的股票。Nuvalent Inc(NUVL)期权交易量为2,058份合约，对应约205,800股标的股票，占过去一个月日均交易量437,580股的47%。2024年4月19日到期的95美元看涨期权交易活跃，今日已成交2,002份合约，对应约200,200股标的股票。基于这些数据，如何分析这三只股票期权市场的流动性和投资者情绪？这些异常交易量可能预示着哪些市场动向或投资者策略？\", \"chosen\": \"<think>\\n1. 问题分析和理解：\\n- 需要分析三只股票(DAL, CRC, NUVL)的期权交易异常情况\\n- 重点关注：交易量相对于日均交易量的比例、特定行权价和到期日的合约交易活跃度\\n- 目标：评估流动性水平和投资者情绪，推测可能的交易策略\\n\\n2. 相关金融概念和理论：\\n- 期权流动性指标：交易量/持仓量、买卖价差\\n- 投资者情绪指标：看涨/看跌比例、隐含波动率变化\\n- 常见期权策略：covered call、protective put、straddle等\\n\\n3. 分析步骤和逻辑推理：\\na) 流动性分析：\\n- 三只股票期权交易量都接近日均交易量的47%，显示异常活跃\\n- DAL的绝对交易量最大(42,941份)，流动性最好\\n- CRC和NUVL交易量相近，但NUVL的看涨期权更集中\\n\\nb) 投资者情绪分析：\\n- DAL：大量45美元看涨期权交易，可能显示看涨情绪\\n- CRC：35美元看跌期权活跃，可能显示对冲或看跌情绪\\n- NUVL：95美元看涨期权集中，显示强烈看涨预期\\n\\n4. 结论推导过程：\\n- 异常交易量可能反映机构投资者的定向押注\\n- DAL和NUVL的看涨集中可能预示盈利预期提升\\n- CRC的看跌交易可能反映行业或公司特定风险\\n- 需结合隐含波动率和现货价格走势进一步确认\\n</think>\\n\\n从期权交易数据来看，三只股票都出现了显著的流动性提升和投资者关注。达美航空(DAL)显示出较强的看涨情绪，45美元看涨期权的集中交易可能预示着投资者预期股价将在2024年1月前突破该水平。California Resources(CRC)的看跌期权活跃则反映了部分投资者对该股的谨慎态度，可能是对冲或直接看跌策略。Nuvalent(NUVL)的看涨期权交易最为集中，95美元的高行权价看涨期权交易活跃，显示部分投资者对该生物科技股持强烈乐观态度。\\n\\n这些异常交易可能预示着：1)机构投资者在进行定向押注；2)市场对航空业(DAL)和生物科技(NUVL)板块的乐观情绪；3)对能源股(CRC)的谨慎态度。但分析存在局限性，未考虑隐含波动率变化、未平仓合约等关键因素。\", \"rejected\": \"<think>\\n1. 问题分析和理解：这个问题问的是关于三只股票期权交易量和投资者情绪的分析。看起来DAL、CRC和NUVL的期权交易量都挺大的，特别是某些特定行权价和到期日的合约。\\n\\n2. 相关金融概念和理论：期权交易量可以反映流动性，交易量大的通常流动性好。看涨期权多可能说明投资者看涨，看跌期权多可能说明看跌。异常交易量可能有大资金在操作。\\n\\n3. 分析步骤和逻辑推理：\\n   - DAL的看涨期权交易量大，可能有人看涨\\n   - CRC的看跌期权交易量大，可能有人看跌\\n   - NUVL的看涨期权交易量大，可能有人看涨\\n   - 交易量都占到日均交易量的47%左右，这个数字挺大的\\n\\n4. 结论推导过程：因为交易量都很大，所以流动性应该不错。看涨期权多就是看涨，看跌期权多就是看跌。可能有大资金在布局。\\n</think>\\n\\n这三只股票的期权流动性看起来都不错，因为交易量都挺大的。DAL和NUVL的看涨期权交易活跃，可能投资者比较看好这两只股票。CRC的看跌期权交易多，可能有人不看好。交易量都占到日均交易量的47%左右，说明这些期权交易很活跃。可能是有些大资金在做对冲或者投机，但具体原因不太清楚。总的来说，期权交易量大说明市场对这些股票关注度高，但具体会涨会跌还要看其他因素。\", \"chosen_level\": 3, \"rejected_level\": 1, \"quality_gap\": 2}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a3cb9",
   "metadata": {},
   "source": [
    "qa_dataset.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967831ba",
   "metadata": {},
   "source": [
    "```json\n",
    "问题 1 ： 5 答案\n",
    "\n",
    "{\"question_id\": 1, \"question\": \"基于以下信息，请分析Arcos Dorados (ARCO)作为成长型股票的投资价值：1) 该公司当前获得Zacks成长风格评分系统中的A级成长评分和Zacks排名第1(强力买入)；2) 历史每股收益增长率为38%，预计今年每股收益增长18.8%，高于行业平均的17.9%；3) 资产利用率(S/TA)为1.52，显著高于行业平均的0.94；4) 预计今年销售额增长19.3%，远超行业平均的5.4%；5) 过去一个月当前年度盈利预期上调了9.3%。这些指标如何共同支持该股票作为成长型投资的合理性？在评估成长型股票时，为什么资产利用率指标和盈利预期修正趋势与传统的每股收益增长指标同样重要？\", \"answers\": [{\"quality_level\": 1, \"quality_name\": \"低质量答案\", \"quality_description\": \"逻辑混乱，信息不准确，分析浅显\", \"content\": \"<think>\\n1. 问题分析和理解：这个问题问的是ARCO股票作为成长股的投资价值，给了几个指标数据，要分析这些指标怎么支持它是个好成长股，还要解释为什么资产利用率和盈利预期修正也很重要。\\n\\n2. 相关金融概念和理论：成长股就是增长快的公司股票，一般看EPS增长、收入增长这些。Zacks评分是个评级系统，A级应该不错。资产利用率好像是说公司用资产赚钱的效率。\\n\\n3. 分析步骤和逻辑推理：ARCO的EPS增长比行业高，收入增长也高，Zacks评分好，说明它增长快。资产利用率高可能说明它用资产赚钱能力强。盈利预期上调说明分析师看好。\\n\\n4. 结论推导过程：把这些指标拼在一起，ARCO看起来是个不错的成长股选择。资产利用率重要是因为...可能和赚钱效率有关？盈利预期修正重要是因为...反映市场看法变化？\\n</think>\\n\\nARCO看起来是个挺好的成长股，因为它的增长评分很高，EPS和收入增长都比同行快。Zacks给了强力买入评级说明专家看好。资产利用率高表示它用资产赚钱的效率不错，这个指标重要是因为...效率高的公司可能更有潜力？盈利预期上调了说明分析师们越来越看好它，这个和EPS增长一样重要是因为能反映市场情绪变化。总之这些指标加在一起说明ARCO值得考虑。\", \"length\": 537, \"has_think_tags\": true}, {\"quality_level\": 2, \"quality_name\": \"中低质量答案\", \"quality_description\": \"基本正确但分析不够深入\", \"content\": \"<think>\\n1. 问题分析和理解：\\n- 需要评估ARCO作为成长型股票的投资价值\\n- 提供了5个关键指标数据\\n- 需要解释这些指标如何支持其成长性\\n- 还要说明资产利用率和盈利预期修正的重要性\\n\\n2. 相关金融概念：\\n- 成长型股票：收入/盈利增长高于平均水平的公司\\n- Zacks评分：分析师对股票的评价系统\\n- 资产利用率(S/TA)：衡量公司使用资产产生销售的效率\\n- 盈利预期修正：分析师对未来盈利预测的调整\\n\\n3. 分析步骤：\\n- 看Zacks评分高说明分析师看好\\n- 看历史EPS增长和预期增长都高于行业\\n- 销售增长远高于行业\\n- 资产利用率高说明效率好\\n- 盈利预期上调是利好\\n\\n4. 结论推导：\\n- 这些指标都显示ARCO增长强劲\\n- 资产利用率显示管理效率\\n- 盈利预期修正反映市场情绪\\n- 综合来看是好的成长股\\n</think>\\n\\n最终答案：\\nARCO显示出较强的成长性特征。Zacks的高评分和排名表明分析师看好，历史38%的EPS增长和预期的18.8%增长都高于行业。19.3%的销售增长远超行业5.4%的平均水平，显示业务扩张能力强。1.52的资产利用率表明公司能高效利用资产产生收入。盈利预期上调9.3%反映分析师持续看好。这些指标共同支持其作为成长股的投资价值。\\n\\n资产利用率重要因为它反映管理效率和资产使用效果，高利用率可以带来更高利润。盈利预期修正趋势能提前反映市场对公司前景的看法变化，与历史增长数据结合能更全面评估成长潜力。这两个指标补充了传统EPS增长指标的不足。\", \"length\": 655, \"has_think_tags\": true}, {\"quality_level\": 3, \"quality_name\": \"中等质量答案\", \"quality_description\": \"正确但不够全面\", \"content\": \"<think>\\n1. 问题分析和理解：\\n- 需要评估Arcos Dorados(ARCO)作为成长型股票的投资价值\\n- 提供了5个关键指标数据\\n- 需要解释这些指标如何共同支持其成长性\\n- 需要说明资产利用率和盈利预期修正为何与EPS增长同等重要\\n\\n2. 相关金融概念和理论：\\n- 成长型股票的特征：高于平均的盈利/销售增长\\n- Zacks评分系统：量化评估成长性的工具\\n- 资产利用率(S/TA)：衡量资产使用效率，高值表明更有效产生销售\\n- 盈利预期修正：反映分析师共识变化，正向修正通常预示更好表现\\n\\n3. 分析步骤和逻辑推理：\\na) 成长性评分验证：\\n- Zacks成长评分A级+排名第1 → 机构认可其成长潜力\\nb) 历史与预期增长：\\n- 历史EPS增长38% + 预期18.8% → 持续高增长\\n- 高于行业平均 → 竞争优势\\nc) 运营效率：\\n- S/TA 1.52 vs 行业0.94 → 资产使用效率显著更高\\nd) 销售增长：\\n- 19.3% vs 行业5.4% → 市场份额扩张能力\\ne) 预期修正：\\n- 月内上调9.3% → 分析师持续看好\\n\\n4. 结论推导过程：\\n- 所有指标都指向高于平均的成长性\\n- 资产利用率显示运营效率支撑增长质量\\n- 预期修正反映增长可持续性\\n- 但未考虑估值水平、负债情况等补充指标\\n</think>\\n\\n[最终答案内容]\\n\\n基于提供的数据，Arcos Dorados(ARCO)展现出强劲的成长型股票特征。其ZacksA级成长评分和排名第一反映了机构对其成长潜力的认可。历史38%的EPS增长和预期18.8%的增长均显著高于行业平均，显示持续的盈利增长能力。1.52的资产利用率表明公司能高效利用资产创造收入，这是支撑高质量增长的关键。19.3%的预期销售增长远超行业，显示市场份额获取能力。盈利预期上调9.3%表明分析师持续看好。\\n\\n资产利用率之所以重要，是因为它衡量增长的质量和可持续性——高利用率意味着增长不依赖过度资本投入。盈利预期修正反映市场共识变化，是成长可持续性的前瞻指标。这两个指标与传统的EPS增长形成互补：EPS显示历史表现，资产利用率揭示增长效率，预期修正预示未来潜力。不过分析未涵盖估值倍数、现金流等要素，这是需要注意的局限性。\", \"length\": 952, \"has_think_tags\": true}, {\"quality_level\": 4, \"quality_name\": \"中高质量答案\", \"quality_description\": \"专业且全面\", \"content\": \"<think>\\n1. 问题分析和理解：\\n- 需要评估Arcos Dorados(ARCO)作为成长型股票的投资价值\\n- 提供了5个关键指标：Zacks评分、EPS增长率、资产利用率、销售增长预期和盈利预期修正\\n- 需要分析这些指标如何共同支持其成长性\\n- 还需要解释为什么资产利用率和盈利预期修正与EPS增长同等重要\\n\\n2. 相关金融概念和理论：\\n- 成长型股票的特征：高于平均的盈利/销售增长、高再投资率、高估值倍数\\n- 成长性评估的多维度：历史增长、预期增长、增长质量(如资产效率)、增长动能(预期修正)\\n- 资产利用率(S/TA)反映资本效率，高比率表明用较少资产创造更多收入\\n- 盈利预期修正反映分析师共识变化，是增长持续性的前瞻指标\\n\\n3. 分析步骤和逻辑推理：\\na) 量化增长优势：\\n- 历史EPS增长38% vs 行业，预期18.8% vs 17.9%，显示持续优势\\n- 销售增长19.3% vs 5.4%，差距更大，反映市场份额获取能力\\nb) 增长质量分析：\\n- S/TA 1.52 vs 0.94，表明卓越的运营效率和资本配置\\n- 这种效率可以支持更高的再投资率和可持续增长\\nc) 增长动能验证：\\n- 盈利预期上调9.3%，显示增长可能被低估\\n- 配合Zacks第1排名，确认短期增长动能强劲\\nd) 多维指标互补性：\\n- EPS增长是结果指标，资产利用率是驱动因素\\n- 预期修正是验证指标，三者形成\\\"原因-结果-验证\\\"闭环\\n\\n4. 结论推导过程：\\n- 所有指标呈现一致性：高绝对增长+高效率+持续上调\\n- 资产利用率解释高ROIC的可能性，这是持续增长的基础\\n- 预期修正反映市场认知滞后，存在alpha机会\\n- 综合判断：ARCO具备优质成长股的所有关键特征\\n</think>\\n\\n[最终答案内容]\\n\\nArcos Dorados(ARCO)展现出典型的优质成长股特征，其投资价值可以从三个维度论证：\\n\\n1. 卓越的增长表现：\\n- 历史EPS增长38%远超同业，未来18.8%的预期增长继续保持优势\\n- 19.3%的销售增速预期是行业3.6倍，显示强劲的营收动能\\n- 这种\\\"双高增长\\\"(盈利+收入)降低了单纯成本削减带来的增长风险\\n\\n2. 高质量的成长驱动：\\n- 1.52的资产周转率证明其运营效率显著优于同业(0.94)\\n- 这种资本效率意味着：①更高的ROIC支撑再投资能力 ②更可持续的增长模式\\n- 高S/TA往往预示规模经济效应，支持长期增长故事\\n\\n3. 持续的增长动能：\\n- 9.3%的盈利预期上调幅度显示分析师持续修正乐观预期\\n- 配合Zacks\\\"强力买入\\\"评级，形成短期催化剂\\n- 预期修正趋势比静态增长数据更能反映增长持续性\\n\\n资产利用率和盈利预期修正之所以关键，是因为：\\n1) 资产效率决定增长质量，避免\\\"烧钱换增长\\\"的伪成长；\\n2) 预期修正反映市场认知过程，能捕捉增长预期的边际变化；\\n3) 三者结合可识别真正可持续的成长股，而不仅是周期性的高增长。\\n\\n结论：ARCO的指标组合呈现了\\\"高增长-高效率-持续上调\\\"的理想形态，在当前估值尚未完全反映其增长潜力的情况下，确实具备优质成长股的投资价值。但需注意拉美市场的汇率风险和消费波动性可能带来的短期波动。\", \"length\": 1346, \"has_think_tags\": true}, {\"quality_level\": 5, \"quality_name\": \"高质量答案\", \"quality_description\": \"专业、全面、深入\", \"content\": \"<think>\\n1. 问题分析和理解：\\n- 需要评估Arcos Dorados (ARCO)作为成长型股票的投资价值\\n- 提供了5个关键指标：Zacks评分、EPS增长率、资产利用率、销售增长预期、盈利预期修正\\n- 需要解释这些指标如何共同支持成长性投资论点\\n- 需要说明资产利用率和盈利预期修正为何与传统EPS增长同等重要\\n\\n2. 相关金融概念和理论：\\n- 成长型股票特征：高于平均的盈利/销售增长、高再投资率、高估值倍数\\n- 成长评分系统：综合多项成长性指标\\n- 资产周转率(S/TA)：衡量资产使用效率的关键运营指标\\n- 盈利预期修正：反映分析师共识变化的前瞻性指标\\n- 杜邦分析法：ROE=利润率×资产周转率×财务杠杆\\n\\n3. 分析步骤和逻辑推理：\\na) 成长性评分系统验证：\\n- Zacks成长A级+排名第1，说明在量化模型中表现优异\\n- 评分系统通常考虑历史增长、预期增长、质量指标等\\n\\nb) 盈利增长分析：\\n- 历史EPS增长38%显示强劲执行能力\\n- 预期18.8%增长仍高于行业，显示持续优势\\n- 盈利预期上调9.3%表明增长可能被低估\\n\\nc) 资产利用率解读：\\n- 1.52 vs 0.94行业平均，显示卓越的运营效率\\n- 高周转率可支撑ROE和增长质量\\n- 可能源于：更好的门店选址、供应链管理或数字化\\n\\nd) 销售增长评估：\\n- 19.3% vs 5.4%行业，显示市场份额获取能力\\n- 结合高资产周转，增长更具可持续性\\n\\ne) 指标协同效应：\\n- 高销售增长+高资产周转=有机增长而非单纯扩张\\n- 盈利预期上调+高历史增长=增长可信度高\\n\\n4. 结论推导过程：\\n- 所有指标指向高质量成长：速度快(增长指标)、效率高(周转率)、可持续(预期上调)\\n- 资产利用率重要原因：区分\\\"烧钱增长\\\"与\\\"高效增长\\\"\\n- 盈利修正重要原因：反映专业分析师对增长前景的重新评估\\n- 综合判断：ARCO呈现典型高质量成长股特征\\n</think>\\n\\n[最终答案内容]\\n\\nArcos Dorados (ARCO)展现出作为优质成长型股票的完整特征组合：\\n\\n1. 核心增长指标优异：\\n- 历史EPS增长38%和预期18.8%的增长均显著高于行业\\n- 19.3%的预期销售增长反映强劲的营收驱动力\\n- Zacks最高评级验证了增长质量的系统性优势\\n\\n2. 关键质量指标突出：\\n- 1.52的资产周转率(是行业1.6倍)表明：\\n  • 卓越的资本配置效率\\n  • 单位资产产生更多收入\\n  • 增长不依赖过度资本支出\\n- 盈利预期持续上调显示增长动能可能被市场低估\\n\\n3. 指标协同价值：\\n- 高增长与高效率的结合降低了\\\"增长陷阱\\\"风险\\n- 预期上调强化了增长预测的可信度\\n- 形成\\\"销售增长→资产效率→盈利增长\\\"的良性循环\\n\\n专业见解：\\n资产利用率之所以关键，是因为它能区分真假成长：单纯收入增长可能来自资本消耗，而高周转率增长才是高质量成长。盈利预期修正则是成长股投资的领先指标，因为分析师共识变化往往先于价格调整。这两个指标与EPS增长形成三维验证：EPS证明成长结果，周转率证明成长质量，预期修正预示成长持续性。\\n\\n投资建议：\\nARCO呈现的成长特征组合在拉美消费板块中罕见。建议关注：\\n1) 下次财报后的预期修正方向\\n2) 同店销售增长与新店ROIC的平衡\\n3) 美元汇率对区域盈利的影响\\n当前指标组合支持将其作为成长型投资组合的核心持仓。\", \"length\": 1424, \"has_think_tags\": true}], \"metadata\": {\"total_answers\": 5, \"successful_answers\": 5, \"failed_answers\": 0}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6b007",
   "metadata": {},
   "source": [
    "# 3.模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d27c2a0",
   "metadata": {},
   "source": [
    "**核心业务目标：**\n",
    "我们需要构建一个专门评判中文金融领域COT（Chain of Thought）推理质量的奖励模型，用于强化学习训练更优秀的金融专家模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f25975",
   "metadata": {},
   "source": [
    "## 一、业务场景与需求的精确定义\n",
    "\n",
    "### 1.1 业务场景深度分析\n",
    "\n",
    "**具体应用场景：**\n",
    "- **金融分析评估**：评判对公司财务状况、投资建议、风险评估等分析的质量\n",
    "- **推理过程评价**：评估包含`<think>`标签的思维链推理的逻辑性和准确性\n",
    "- **专业知识验证**：确保回答符合金融专业标准和监管要求\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de68878",
   "metadata": {},
   "source": [
    "### 1.2 数据资源现状分析\n",
    "\n",
    "**数据规模与质量：**\n",
    "- 拥有多组高质量的中文金融偏好数据集\n",
    "- 每个数据集包含问题对应的5种不同回答\n",
    "- 通过专家评估整合出偏好对比数据\n",
    "- 所有回答都包含`<think>`标签的COT结构\n",
    "\n",
    "**数据特点分析：**\n",
    "```python\n",
    "data_characteristics = {\n",
    "    \"语言特性\": {\n",
    "        \"主要语言\": \"中文\",\n",
    "        \"专业术语\": \"金融领域专业词汇密集\",\n",
    "        \"表达方式\": \"正式的金融分析语言风格\"\n",
    "    },\n",
    "    \n",
    "    \"结构特性\": {\n",
    "        \"COT标签\": \"包含<think>...</think>的思维过程\",\n",
    "        \"推理链长度\": \"通常比普通回答长2-3倍\",\n",
    "        \"逻辑结构\": \"问题分析→推理过程→结论输出\"\n",
    "    },\n",
    "    \n",
    "    \"质量特性\": {\n",
    "        \"专家标注\": \"由金融专业人士进行质量评估\",\n",
    "        \"偏好明确\": \"每组数据都有明确的优劣排序\",\n",
    "        \"覆盖全面\": \"涵盖金融分析的各个子领域\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce40fbaf",
   "metadata": {},
   "source": [
    "## 二、技术路径选择的系统性分析\n",
    "\n",
    "### 2.1 从LLM训练奖励模型 vs 现有奖励模型继续训练\n",
    "\n",
    "**技术路径对比分析：**\n",
    "\n",
    "#### 路径A：从通用LLM（如Qwen2.5-7B-Instruct）训练奖励模型\n",
    "\n",
    "**技术流程：**\n",
    "```python\n",
    "llm_to_reward_process = {\n",
    "    \"第一步\": \"架构改造 - 替换输出层\",\n",
    "    \"第二步\": \"偏好数据预训练 - 学习基础评分能力\", \n",
    "    \"第三步\": \"领域数据微调 - 适应中文金融场景\",\n",
    "    \"第四步\": \"性能优化 - 调整超参数和训练策略\"\n",
    "}\n",
    "```\n",
    "\n",
    "**优势分析：**\n",
    "- **完全可控**：可以针对中文金融场景深度定制\n",
    "- **架构灵活**：可以设计专门的评分机制\n",
    "- **知识对齐**：确保模型完全理解中文金融知识体系\n",
    "\n",
    "**劣势分析：**\n",
    "- **训练成本高**：需要大量计算资源和时间\n",
    "- **技术风险大**：从生成任务到评分任务的转换存在不确定性\n",
    "- **数据需求大**：需要更多的偏好数据来训练基础评分能力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f72ef1",
   "metadata": {},
   "source": [
    "#### 路径B：从现有奖励模型继续训练\n",
    "\n",
    "**技术流程：**\n",
    "```python\n",
    "existing_reward_continue = {\n",
    "    \"第一步\": \"模型选择 - 基于权威排名选择基础模型\",\n",
    "    \"第二步\": \"适配性验证 - 测试模型对中文和COT数据的理解\",\n",
    "    \"第三步\": \"领域微调 - 使用金融偏好数据进行适应性训练\",\n",
    "    \"第四步\": \"性能验证 - 在验证集上测试效果\"\n",
    "}\n",
    "```\n",
    "\n",
    "**优势分析：**\n",
    "- **训练效率高**：跳过基础评分能力学习阶段\n",
    "- **技术风险低**：基于已验证的奖励模型架构\n",
    "- **资源需求少**：主要进行领域适应，计算成本可控\n",
    "\n",
    "**劣势分析：**\n",
    "- **定制化程度有限**：受限于原模型的架构设计\n",
    "- **可能存在偏差**：原模型的训练数据可能与我们的场景不完全匹配\n",
    "\n",
    "### 2.2 基于业务场景的技术路径选择\n",
    "\n",
    "**决策依据：**\n",
    "\n",
    "考虑到我们的具体情况：\n",
    "- 拥有高质量的中文金融偏好数据\n",
    "- 需要快速验证和迭代\n",
    "- 计算资源有一定限制\n",
    "- 对最终效果有明确要求\n",
    "\n",
    "**最优选择：路径B（现有奖励模型继续训练）**\n",
    "\n",
    "**选择理由：**\n",
    "1. **效率优先**：可以快速获得可用的模型\n",
    "2. **风险可控**：基于成熟的技术方案\n",
    "3. **资源匹配**：符合我们的计算资源约束\n",
    "4. **效果保证**：通过权威排名验证的基础性能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60598b5",
   "metadata": {},
   "source": [
    "## 三、基于RewardBench排行榜的模型选择\n",
    "\n",
    "### 3.1 RewardBench排行榜的权威性分析\n",
    "\n",
    "**为什么RewardBench是权威标准？**\n",
    "\n",
    "[RewardBench](https://huggingface.co/spaces/allenai/reward-bench)由AllenAI开发，是目前最权威的奖励模型评估基准，其权威性体现在：\n",
    "\n",
    "**学术权威性：**\n",
    "- **机构背景**：AllenAI是由微软联合创始人Paul Allen创立的顶级AI研究机构\n",
    "- **研究实力**：在NLP领域发表大量顶级会议论文，开发了ELMo、AllenNLP等广泛使用的工具\n",
    "- **方法严谨**：采用标准化的评估流程，避免各家自说自话的问题\n",
    "\n",
    "**评估全面性：**\n",
    "```python\n",
    "rewardbench_dimensions = {\n",
    "    \"Chat\": {\n",
    "        \"含义\": \"基础对话能力评估\",\n",
    "        \"重要性\": \"测试模型的基本交互质量\",\n",
    "        \"权重\": \"25%\"\n",
    "    },\n",
    "    \n",
    "    \"Chat-Hard\": {\n",
    "        \"含义\": \"复杂对话场景评估\", \n",
    "        \"重要性\": \"测试模型处理困难场景的能力\",\n",
    "        \"权重\": \"25%\"\n",
    "    },\n",
    "    \n",
    "    \"Safety\": {\n",
    "        \"含义\": \"安全性评估\",\n",
    "        \"重要性\": \"确保模型不产生有害内容\",\n",
    "        \"权重\": \"25%\"\n",
    "    },\n",
    "    \n",
    "    \"Reasoning\": {\n",
    "        \"含义\": \"推理能力评估\",\n",
    "        \"重要性\": \"对金融分析任务最为关键\",\n",
    "        \"权重\": \"25%\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d8230",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620131258212.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ed4ef",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620131436886.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dcea22",
   "metadata": {},
   "source": [
    "### 3.2 排行榜数据的深度解读\n",
    "\n",
    "**如何正确解读排名数据：**\n",
    "\n",
    "1. **总分的含义**：反映模型在标准测试集上的综合表现\n",
    "2. **维度分数的重要性**：对于金融应用，Reasoning维度最为关键\n",
    "3. **排名的相对意义**：排名靠前的模型在大多数场景下表现更好\n",
    "4. **适用性判断**：需要结合具体应用场景进行分析\n",
    "\n",
    "**针对中文金融场景的筛选标准：**\n",
    "```python\n",
    "selection_criteria = {\n",
    "    \"基础门槛\": {\n",
    "        \"开源可用\": \"必须是开源且可商用的模型\",\n",
    "        \"社区活跃\": \"有良好的社区支持和文档\"\n",
    "    },\n",
    "    \n",
    "    \"性能要求\": {\n",
    "        \"总排名\": \"前50%（确保基础性能）\",\n",
    "        \"Reasoning分数\": \"高于平均水平（适合金融分析）\",\n",
    "        \"综合能力\": \"各维度相对均衡\"\n",
    "    },\n",
    "    \n",
    "    \"适配性要求\": {\n",
    "        \"多语言支持\": \"支持中文或多语言\",\n",
    "        \"架构成熟\": \"基于成熟的基础架构\",\n",
    "        \"部署友好\": \"支持常见的推理框架\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d443d4",
   "metadata": {},
   "source": [
    "\n",
    "## 四、RewardBench vs RewardBench 2的关键差异\n",
    "\n",
    "### 1.1 两个榜单的本质区别 排行榜差异与数据污染问题\n",
    "\n",
    "**RewardBench 2（新版本）特点：**\n",
    "- **评估标准**：基于未见过的人类数据，设计得更加困难\n",
    "- **模型类型分类**：\n",
    "  - `Seq. Classifier`（序列分类器）\n",
    "  - `Custom Classifier`（自定义分类器）  \n",
    "  - `Generative`（生成式模型）\n",
    "- **评估维度**：Score、Factuality、Precise_IF、Math、Safety、Focus、Ties  评分、事实性、精确性、数学、安全性、焦点、联系\n",
    "\n",
    "**RewardBench（原版本）特点：**\n",
    "- **评估标准**：基于原始的评估数据集\n",
    "- **模型类型分类**：\n",
    "  - `Seq. Classifier`（序列分类器）\n",
    "  - `Custom Classifier`（自定义分类器）\n",
    "  - `Generative`（生成式模型）\n",
    "- **评估维度**：Score、Chat、Chat_Hard、Safety、Reasoning  得分、聊天、Chat_Hard、安全、推理\n",
    "\n",
    "### 1.2 排名差异的深度分析\n",
    "\n",
    "**同一模型在两个榜单上的表现对比(注意榜单有时效性不做长期对比)：**\n",
    "\n",
    "以`nicolinho/QRM-Llama3.1-8B-v2`为例：\n",
    "- **RewardBench 2**：排名第17位，总分70.7\n",
    "- **RewardBench（原版）**：排名第10位，总分93.1\n",
    "\n",
    "这种显著差异说明：\n",
    "\n",
    "```python\n",
    "ranking_difference_analysis = {\n",
    "    \"评估难度差异\": {\n",
    "        \"RewardBench 2\": \"基于未见过的人类数据，更加困难\",\n",
    "        \"RewardBench\": \"基于已知的评估集，相对容易\",\n",
    "        \"影响\": \"新版本更能反映模型的真实泛化能力\"\n",
    "    },\n",
    "    \n",
    "    \"评估维度差异\": {\n",
    "        \"RewardBench 2\": \"更关注事实性、数学能力、精确性\",\n",
    "        \"RewardBench\": \"更关注对话能力和推理能力\",\n",
    "        \"影响\": \"不同维度导致模型排名发生变化\"\n",
    "    },\n",
    "    \n",
    "    \"数据污染影响\": {\n",
    "        \"RewardBench\": \"存在数据污染问题，部分高排名可能不真实\",\n",
    "        \"RewardBench 2\": \"使用未见过的数据，避免了污染问题\",\n",
    "        \"影响\": \"原版排名可能存在虚高现象\"\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc4b5b",
   "metadata": {},
   "source": [
    "## 五、数据污染问题的深度解析\n",
    "\n",
    "### 2.1 数据污染的技术原理\n",
    "\n",
    "根据[Nathan Lambert的分析](https://gist.github.com/natolambert/1aed306000c13e0e8c5bc17c1a5dd300)，数据污染的具体情况："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a1320",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620132416880.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0bd36",
   "metadata": {},
   "source": [
    "\n",
    "**污染来源：**\n",
    "- **Skyworks Preferences 80K数据集**包含了与RewardBench测试集重叠的数据\n",
    "- 污染源是**Magpie数据集**，通过空聊天模板让语言模型生成指令\n",
    "- 原始来源是`Argilla/magpie-ultra-v0.1`，由Llama 3.1 405B Instruct生成\n",
    "\n",
    "**污染规模：**\n",
    "```python\n",
    "contamination_scale = {\n",
    "    \"总体影响\": \"多个顶级奖励模型受到影响\",\n",
    "    \"具体数量\": {\n",
    "        \"math-prm\": 233,\n",
    "        \"hep-rust\": 53,\n",
    "        \"hep-js\": 50,\n",
    "        \"hep-java\": 50,\n",
    "        \"hep-python\": 50,\n",
    "        # ... 其他子集\n",
    "    },\n",
    "    \"污染类型\": \"训练数据与测试数据的直接重叠\"\n",
    "}\n",
    "```\n",
    "\n",
    "**污染检测方法：**\n",
    "使用n-gram重叠检测（7-13个词的连续序列），通过以下技术实现：\n",
    "- CountVectorizer进行文本向量化\n",
    "- 计算相似度矩阵找出重叠内容\n",
    "- 基于重叠分数排序识别污染程度\n",
    "\n",
    "### 2.2 数据污染对模型排名的影响\n",
    "\n",
    "**受影响的模型：**\n",
    "从排行榜可以看到，多个Skywork系列模型都有⚠️标记，表明它们使用了被污染的数据集：\n",
    "\n",
    "- `Skywork/Skywork-Reward-Gemma-2-27B` ⚠️\n",
    "- `Skywork/Skywork-Reward-Llama-3.1-8B` ⚠️  \n",
    "- `Skywork/Skywork-Critic-Llama-3.1-70B` ⚠️\n",
    "\n",
    "**污染的实际影响：**\n",
    "```python\n",
    "contamination_impact = {\n",
    "    \"性能虚高\": \"模型在测试集上表现异常好，因为见过类似数据\",\n",
    "    \"泛化能力质疑\": \"真实场景下的性能可能远低于排行榜显示\",\n",
    "    \"公平性问题\": \"与未使用污染数据的模型比较不公平\",\n",
    "    \"选择误导\": \"可能导致选择了实际性能不佳的模型\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d643f42",
   "metadata": {},
   "source": [
    "## 六、基于两个榜单的综合分析与模型选择策略\n",
    "\n",
    "### 6.1 榜单设计的根本差异\n",
    "\n",
    "**RewardBench（原版）的价值：**\n",
    "```python\n",
    "original_rewardbench_value = {\n",
    "    \"成熟度\": {\n",
    "        \"时间验证\": \"经过更长时间的社区验证和使用\",\n",
    "        \"模型覆盖\": \"包含更多经过实际应用验证的模型\",\n",
    "        \"稳定性\": \"评估标准相对稳定，结果可重现\"\n",
    "    },\n",
    "    \n",
    "    \"实用性\": {\n",
    "        \"维度设计\": \"Chat、Chat_Hard、Safety、Reasoning更贴近实际应用\",\n",
    "        \"业务相关\": \"Reasoning维度直接对应我们的金融分析需求\",\n",
    "        \"部署参考\": \"更多模型有实际部署经验可参考\"\n",
    "    },\n",
    "    \n",
    "    \"数据污染考虑\": {\n",
    "        \"已知问题\": \"虽然存在污染，但污染程度和影响已被充分分析\",\n",
    "        \"可控风险\": \"可以通过了解污染情况来调整选择策略\",\n",
    "        \"实际影响\": \"污染主要影响部分Skywork模型，不是全面性问题\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**RewardBench 2的价值：**\n",
    "```python\n",
    "rewardbench2_value = {\n",
    "    \"技术先进性\": {\n",
    "        \"未见数据\": \"基于未见过的人类数据，避免数据泄露\",\n",
    "        \"评估严格\": \"更加困难的测试，更能反映泛化能力\",\n",
    "        \"方法创新\": \"代表了评估方法的最新发展\"\n",
    "    },\n",
    "    \n",
    "    \"局限性\": {\n",
    "        \"样本有限\": \"模型数量相对较少，覆盖面不够广\",\n",
    "        \"新颖性风险\": \"评估标准较新，可能存在未知偏差\",\n",
    "        \"实用性待验证\": \"与实际应用场景的相关性需要验证\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f2fa6",
   "metadata": {},
   "source": [
    "### 6.2 数据集差异的深度分析\n",
    "\n",
    "基于提供的数据集链接分析：\n",
    "\n",
    "**RewardBench数据集特点：**\n",
    "- **规模**: 2,985个样本\n",
    "- **来源**: 多个已验证的评估数据集\n",
    "- **覆盖**: Chat、Chat_Hard、Safety、Reasoning四个维度\n",
    "- **特点**: 经过长期验证，与实际应用场景相关性高\n",
    "\n",
    "**RewardBench 2数据集特点：**\n",
    "- **规模**: 相对较小但更精选\n",
    "- **来源**: 未见过的人类标注数据\n",
    "- **覆盖**: Factuality、Precise_IF、Math、Safety、Focus、Ties六个维度\n",
    "- **特点**: 避免数据泄露，但与实际应用的相关性需要验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a995d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 七、四个候选模型的综合技术分析\n",
    "\n",
    "### 1 LxzGordon/URM-LLaMa-3.1-8B 深度解析\n",
    "\n",
    "基于[模型页面](https://huggingface.co/LxzGordon/URM-LLaMa-3.1-8B)的详细信息：\n",
    "\n",
    "**技术创新点：**\n",
    "```python\n",
    "urm_technical_analysis = {\n",
    "    \"核心创新\": {\n",
    "        \"不确定性感知\": \"输出参数是正态分布的参数，而非单一分数\",\n",
    "        \"属性回归\": \"分别对5个属性进行回归：Helpfulness、Correctness、Coherence、Complexity、Verbosity\",\n",
    "        \"门控学习\": \"学习门控层来组合多属性分数，而非固定权重\"\n",
    "    },\n",
    "    \n",
    "    \"训练策略\": {\n",
    "        \"两阶段训练\": \"1. 属性回归阶段 2. 门控层学习阶段\",\n",
    "        \"数据使用\": \"HelpSteer2 + Skywork-Reward-Preference-80K-v0.1\",\n",
    "        \"基础模型\": \"基于Skywork-Reward-Llama-3.1-8B微调\"\n",
    "    },\n",
    "    \n",
    "    \"技术优势\": {\n",
    "        \"不确定性量化\": \"能够表达评分的置信度\",\n",
    "        \"多属性建模\": \"更细粒度的评估维度\",\n",
    "        \"自适应权重\": \"根据具体情况调整属性权重\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**与COT数据的适配性：**\n",
    "```python\n",
    "urm_cot_compatibility = {\n",
    "    \"不确定性价值\": {\n",
    "        \"复杂推理\": \"COT推理往往存在多种合理路径\",\n",
    "        \"置信度评估\": \"可以识别推理过程中的不确定环节\",\n",
    "        \"风险控制\": \"在金融场景中特别重要\"\n",
    "    },\n",
    "    \n",
    "    \"多属性评估\": {\n",
    "        \"Correctness\": \"评估推理逻辑和结论的正确性\",\n",
    "        \"Coherence\": \"评估思维链的连贯性\",\n",
    "        \"Complexity\": \"评估推理的复杂度和深度\",\n",
    "        \"Helpfulness\": \"评估回答的实用性\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 2 Skywork/Skywork-Reward-Llama-3.1-8B 重新评估\n",
    "\n",
    "基于[模型页面](https://huggingface.co/Skywork/Skywork-Reward-Llama-3.1-8B)的信息：\n",
    "\n",
    "**技术特点：**\n",
    "```python\n",
    "skywork_technical_analysis = {\n",
    "    \"数据策略\": {\n",
    "        \"精选数据\": \"仅使用80K高质量偏好对\",\n",
    "        \"多源融合\": \"HelpSteer2 + OffsetBias + WildGuard + Magpie系列\",\n",
    "        \"质量控制\": \"基于ArmoRM分数进行样本选择\"\n",
    "    },\n",
    "    \n",
    "    \"训练技巧\": {\n",
    "        \"分层采样\": \"不同数据源采用不同的采样策略\",\n",
    "        \"分数调整\": \"对不同Magpie子集进行分数调整\",\n",
    "        \"安全性优化\": \"专门优化Safety维度表现\"\n",
    "    },\n",
    "    \n",
    "    \"性能表现\": {\n",
    "        \"原版RewardBench\": \"第16名，92.5分\",\n",
    "        \"RewardBench2\": \"第10名，73.1分\",\n",
    "        \"均衡性\": \"各维度表现相对均衡\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**数据污染问题重新评估：**\n",
    "```python\n",
    "skywork_contamination_reanalysis = {\n",
    "    \"污染程度\": {\n",
    "        \"数据来源\": \"使用了Skywork-Reward-Preference-80K-v0.1\",\n",
    "        \"污染范围\": \"主要影响原版RewardBench的部分子集\",\n",
    "        \"实际影响\": \"在RewardBench2上仍保持良好表现\"\n",
    "    },\n",
    "    \n",
    "    \"风险评估\": {\n",
    "        \"过拟合风险\": \"可能在特定类型的问题上表现虚高\",\n",
    "        \"泛化能力\": \"RewardBench2的表现证明了一定的泛化能力\",\n",
    "        \"实用性\": \"在实际应用中需要额外验证\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 3 nicolinho/QRM-Llama3.1-8B-v2\n",
    "\n",
    "**技术价值重新评估：**\n",
    "```python\n",
    "qrm_repositioning = {\n",
    "    \"技术创新\": {\n",
    "        \"分布式奖励\": \"输出奖励分布而非单一分数\",\n",
    "        \"量化回归\": \"使用分位数回归估计分布\",\n",
    "        \"多属性融合\": \"聚合多个属性的分布\"\n",
    "    },\n",
    "    \n",
    "    \"性能表现\": {\n",
    "        \"原版RewardBench\": \"第10名，93.1分\",\n",
    "        \"RewardBench2\": \"第17名，70.7分\",\n",
    "        \"差异分析\": \"在新评估标准下表现下降明显\"\n",
    "    },\n",
    "    \n",
    "    \"适用性分析\": {\n",
    "        \"理论优势\": \"分布式奖励理论上更适合复杂评估\",\n",
    "        \"实际表现\": \"在严格评估下表现不如预期\",\n",
    "        \"应用价值\": \"可能更适合特定场景或作为研究基准\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 4 allenai/Llama-3.1-8B-Instruct-RM-RB2 的特殊价值\n",
    "\n",
    "**权威性分析：**\n",
    "```python\n",
    "allenai_model_analysis = {\n",
    "    \"开发背景\": {\n",
    "        \"机构权威\": \"AllenAI，RewardBench的开发者\",\n",
    "        \"专门设计\": \"专门为RewardBench2优化\",\n",
    "        \"基准意义\": \"可作为新评估标准的参考基准\"\n",
    "    },\n",
    "    \n",
    "    \"技术特点\": {\n",
    "        \"Factuality优势\": \"74.3分，在事实准确性方面表现最佳\",\n",
    "        \"专业优化\": \"针对新评估维度进行专门优化\",\n",
    "        \"可靠性\": \"来自权威机构，技术路径可信\"\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d2f06",
   "metadata": {},
   "source": [
    "## 八、QRM模型对COT数据的适配性分析\n",
    "\n",
    "### 8.1 QRM技术架构的COT优势\n",
    "\n",
    "**业务需求分析：**\n",
    "```python\n",
    "business_requirements = {\n",
    "    \"核心需求\": {\n",
    "        \"COT理解\": \"需要理解<think>标签内的推理过程\",\n",
    "        \"金融专业\": \"需要掌握中文金融领域知识\",\n",
    "        \"质量评估\": \"需要准确评估推理质量和结论正确性\"\n",
    "    },\n",
    "    \n",
    "    \"性能要求\": {\n",
    "        \"准确性\": \"与专家评判一致性>80%\",\n",
    "        \"稳定性\": \"在不同类型的金融问题上表现稳定\",\n",
    "        \"效率\": \"推理速度满足实时应用需求\"\n",
    "    },\n",
    "    \n",
    "    \"风险控制\": {\n",
    "        \"不确定性\": \"能够识别和表达评估的不确定性\",\n",
    "        \"专业性\": \"避免在专业知识上出现明显错误\",\n",
    "        \"合规性\": \"符合金融行业的合规要求\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "**QRM的分布式奖励机制特别适合COT数据：**\n",
    "\n",
    "```python\n",
    "qrm_cot_advantages = {\n",
    "    \"多维度评估\": {\n",
    "        \"传统奖励模型\": \"单一标量分数，难以评估复杂推理\",\n",
    "        \"QRM优势\": \"分别评估推理过程的不同属性\",\n",
    "        \"COT适配\": \"可以分别评估<think>部分和最终答案\"\n",
    "    },\n",
    "    \n",
    "    \"不确定性量化\": {\n",
    "        \"传统问题\": \"无法表达评分的置信度\",\n",
    "        \"QRM解决\": \"提供奖励分布，表达评估的不确定性\",\n",
    "        \"COT价值\": \"复杂推理往往存在多种合理路径\"\n",
    "    },\n",
    "    \n",
    "    \"属性分解\": {\n",
    "        \"helpfulness\": \"回答的有用性\",\n",
    "        \"correctness\": \"推理和结论的正确性\", \n",
    "        \"coherence\": \"逻辑的连贯性\",\n",
    "        \"complexity\": \"推理的复杂度\",\n",
    "        \"verbosity\": \"表达的详细程度\"\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e833ec",
   "metadata": {},
   "source": [
    "### 8.2 COT数据评估的特殊需求\n",
    "\n",
    "**COT数据的评估挑战：**\n",
    "\n",
    "1. **推理过程评估**：需要判断`<think>`标签内的推理逻辑是否正确\n",
    "2. **结论一致性**：推理过程与最终答案是否一致\n",
    "3. **专业准确性**：金融领域的专业知识是否正确应用\n",
    "4. **逻辑连贯性**：整个思维链是否逻辑清晰\n",
    "\n",
    "**QRM的解决方案：**\n",
    "```python\n",
    "qrm_cot_solution = {\n",
    "    \"分步评估\": \"可以分别对推理过程和最终结论进行评分\",\n",
    "    \"置信度评估\": \"通过分布宽度判断评估的可靠性\",\n",
    "    \"多属性融合\": \"综合考虑逻辑性、准确性、完整性等多个维度\",\n",
    "    \"风险控制\": \"在不确定性高时给出保守评分\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0657b33",
   "metadata": {},
   "source": [
    "## 九、基于新信息的模型选择重新评估\n",
    "\n",
    "**QRM-Llama3.1-8B-v2的重新定位：**\n",
    "- **RewardBench 2排名**：第17位，70.7分\n",
    "- **参数规模**：8B，符合资源约束\n",
    "- **技术优势**：分布式奖励机制仍然先进\n",
    "- **污染状况**：未发现明显的数据污染标记\n",
    "\n",
    "### 9.1 最终选择建议\n",
    "\n",
    "**综合考虑后的选择：**\n",
    "\n",
    "```python\n",
    "final_recommendation = {\n",
    "    \"首选方案\": {\n",
    "        \"模型\": \"nicolinho/QRM-Llama3.1-8B-v2\",\n",
    "        \"理由\": [\n",
    "            \"技术架构先进，特别适合COT数据\",\n",
    "            \"参数规模符合资源约束\",\n",
    "            \"未发现数据污染问题\",\n",
    "            \"在RewardBench 2上仍有合理表现\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"备选方案\": {\n",
    "        \"模型\": \"infly/INF-ORM-Llama3.1-70B的8B版本或类似模型\",\n",
    "        \"理由\": \"在RewardBench 2上排名更高，但需要确认参数规模\"\n",
    "    },\n",
    "    \n",
    "    \"风险控制\": {\n",
    "        \"策略\": \"选择多个候选模型进行小规模测试\",\n",
    "        \"验证\": \"在自己的验证集上测试实际效果\",\n",
    "        \"迭代\": \"根据实际表现调整选择\"\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8721fd",
   "metadata": {},
   "source": [
    "### 9.2 QRM-Llama3.1-8B-v2的深度分析\n",
    "\n",
    "基于[QRM-Llama3.1-8B-v2模型页面](https://huggingface.co/nicolinho/QRM-Llama3.1-8B-v2)的详细信息，我们来分析这个模型的技术特点和优势。\n",
    "\n",
    "#### 9.2.1 QRM技术原理解析\n",
    "\n",
    "**QRM（Quantile Regression for Distributional Reward Models）核心创新：**\n",
    "\n",
    "传统奖励模型输出单一标量分数，而QRM输出奖励分布，这带来了以下技术优势：\n",
    "\n",
    "```python\n",
    "qrm_innovation = {\n",
    "    \"传统奖励模型\": {\n",
    "        \"输出\": \"单一标量分数 r\",\n",
    "        \"局限\": \"无法表达评分的不确定性\",\n",
    "        \"风险\": \"可能过于自信或保守\"\n",
    "    },\n",
    "    \n",
    "    \"QRM奖励模型\": {\n",
    "        \"输出\": \"奖励分布 P(r)\",\n",
    "        \"优势\": \"提供评分的置信区间\",\n",
    "        \"应用\": \"更好的风险控制和决策支持\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "**技术架构详解：**\n",
    "\n",
    "根据模型描述，QRM通过以下方式工作：\n",
    "1. **多属性评估**：分别评估helpfulness、harmlessness、truthfulness、complexity等属性\n",
    "2. **分布聚合**：将各属性的分布聚合成最终的奖励分布\n",
    "3. **量化回归**：使用分位数回归技术估计分布的不同分位点\n",
    "\n",
    "#### 9.2.2 模型的技术优势分析\n",
    "\n",
    "**基础架构优势：**\n",
    "- **Backbone模型**：基于[Skywork-Reward-Llama-3.1-8B-v0.2](https://huggingface.co/Skywork/Skywork-Reward-Llama-3.1-8B-v0.2)\n",
    "- **训练数据**：使用[Skywork-Reward-Preference-80K-v0.2](https://huggingface.co/Skywork/Skywork-Reward-Preference-80K-v0.2)进行训练\n",
    "- **中文能力**：Llama3.1在中文任务上表现优秀\n",
    "\n",
    "**技术创新优势：**\n",
    "```python\n",
    "qrm_advantages = {\n",
    "    \"分布式奖励\": {\n",
    "        \"传统问题\": \"单点估计容易出现极端值\",\n",
    "        \"QRM解决\": \"提供完整的奖励分布信息\",\n",
    "        \"实际价值\": \"更好地处理评分的不确定性\"\n",
    "    },\n",
    "    \n",
    "    \"多属性融合\": {\n",
    "        \"传统问题\": \"难以平衡不同评价维度\",\n",
    "        \"QRM解决\": \"分别建模各属性后再融合\",\n",
    "        \"实际价值\": \"更精细的评价粒度\"\n",
    "    },\n",
    "    \n",
    "    \"量化回归\": {\n",
    "        \"传统问题\": \"只能给出期望值\",\n",
    "        \"QRM解决\": \"提供多个分位点的估计\",\n",
    "        \"实际价值\": \"支持风险敏感的决策\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### 9.2.3 与中文金融场景的适配性分析\n",
    "\n",
    "**场景匹配度分析：**\n",
    "\n",
    "1. **COT数据适配性**\n",
    "   - QRM的多属性评估机制天然适合评估COT数据\n",
    "   - 可以分别评估推理过程的逻辑性、结论的正确性等\n",
    "   - 分布式输出提供更丰富的评价信息\n",
    "\n",
    "2. **中文金融领域适配性**\n",
    "   - 基于Llama3.1，具备良好的中文理解能力\n",
    "   - 多属性评估框架可以适应金融分析的复杂性\n",
    "   - 不确定性量化对金融风险评估特别重要\n",
    "\n",
    "3. **资源约束适配性**\n",
    "   - 8B参数规模符合我们的硬件限制\n",
    "   - 基于成熟的Llama架构，部署和优化相对容易\n",
    "\n",
    "**具体适配策略：**\n",
    "```python\n",
    "adaptation_strategy = {\n",
    "    \"属性定制\": {\n",
    "        \"原始属性\": [\"helpfulness\", \"correctness\", \"coherence\", \"complexity\", \"verbosity\"],\n",
    "        \"金融定制\": [\"专业准确性\", \"逻辑严密性\", \"风险意识\", \"实用性\", \"合规性\"],\n",
    "        \"实现方式\": \"通过微调调整各属性的权重和定义\"\n",
    "    },\n",
    "    \n",
    "    \"分布利用\": {\n",
    "        \"置信度评估\": \"利用分布宽度评估模型的置信度\",\n",
    "        \"风险控制\": \"在不确定性高的情况下给出保守评分\",\n",
    "        \"决策支持\": \"为强化学习提供更丰富的奖励信号\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## 十、最终选择的综合决策\n",
    "\n",
    "### 10.1 QRM-Llama3.1-8B-v2的选择依据\n",
    "\n",
    "**综合评估结果：**\n",
    "\n",
    "基于以上分析，选择QRM-Llama3.1-8B-v2作为基础模型的理由：\n",
    "\n",
    "1. **技术先进性**：QRM的分布式奖励机制代表了奖励模型的最新发展方向\n",
    "2. **性能验证性**：基于权威的RewardBench排名，性能得到验证\n",
    "3. **场景适配性**：多属性评估框架特别适合复杂的金融分析任务\n",
    "4. **资源匹配性**：8B参数规模符合我们的硬件约束\n",
    "5. **技术成熟性**：基于Llama3.1的成熟架构，风险可控\n",
    "\n",
    "\n",
    "**预期效果：**\n",
    "- 保持QRM的分布式奖励优势\n",
    "- 获得专门的中文金融评价能力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7ca46",
   "metadata": {},
   "source": [
    "# 4.微调方式选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe73782a",
   "metadata": {},
   "source": [
    "## 一、业务场景需求总结\n",
    "\n",
    "在进行微调方法选择之前，我们先明确核心业务需求：\n",
    "\n",
    "**核心需求：**\n",
    "- 训练中文金融领域的奖励模型，评估包含`<think>`标签的COT推理质量\n",
    "- 数据：有限的高质量偏好数据集，序列长度比普通对话长2-3倍\n",
    "- 资源：最大支持8B参数模型，需要快速迭代验证"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1148078c",
   "metadata": {},
   "source": [
    "## 二、主流微调方法的详细分析\n",
    "\n",
    "### 2.1 Full Fine-tuning（全参数微调）\n",
    "\n",
    "**微调原理：**\n",
    "全参数微调是最直接的微调方法，更新模型的所有参数。数学表示为：\n",
    "```\n",
    "θ_new = θ_pretrained + Δθ\n",
    "其中所有参数都通过梯度下降更新：Δθ = -η∇L(θ)\n",
    "```\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **表达能力最强**：可以充分适应中文金融领域的复杂需求\n",
    "- ✅ **灵活性最高**：可以对模型进行深度定制，完全适应奖励模型任务\n",
    "- ✅ **理论效果最佳**：在数据充足的情况下通常能获得最好的性能\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **资源需求过大**：8B模型全参数微调需要>64GB显存，同步扩展更大模型超出我们的硬件限制太多\n",
    "- ❌ **过拟合风险高**：在有限的偏好数据上容易过拟合，破坏预训练知识\n",
    "- ❌ **训练时间长**：需要数天到数周的训练时间，不符合快速迭代需求\n",
    "- ❌ **成本过高**：计算成本是其他方法的5-10倍\n",
    "\n",
    "**排除原因：**\n",
    "资源约束是决定性因素。我们的硬件配置无法支持8B模型的全参数微调，即使强行实施也会因为显存不足导致训练失败或效率极低。\n",
    "\n",
    "**具体问题：**\n",
    "1. 显存需求：8B × 4字节（参数）+ 8B × 4字节（梯度）+ 8B × 8字节（Adam优化器状态）= 128GB，远超现有硬件能力（假设当前共计48G显存）\n",
    "2. 过拟合风险：在有限数据上更新所有80亿参数，极易记住训练数据而失去泛化能力\n",
    "3. 知识遗忘：可能破坏模型原有的COT理解能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d7f0b1",
   "metadata": {},
   "source": [
    "### 2.2 LoRA（Low-Rank Adaptation）\n",
    "\n",
    "**微调原理：**\n",
    "LoRA通过低秩矩阵分解来近似权重更新，在原始权重矩阵旁边添加两个小矩阵的乘积：\n",
    "```\n",
    "W_new = W_frozen + α/r × A × B\n",
    "其中：A ∈ R^(d×r), B ∈ R^(r×k), r << min(d,k)\n",
    "```\n",
    "只训练A和B矩阵，原始权重W保持冻结。\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **参数效率极高**：通常只需要训练0.1-1%的参数，大幅降低资源需求\n",
    "- ✅ **推理无额外开销**：训练完成后可以将LoRA权重合并到原模型，推理速度不受影响\n",
    "- ✅ **实现简单**：有成熟的工具链支持，如PEFT库\n",
    "- ✅ **多任务支持**：可以为不同任务训练不同的LoRA适配器\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **表达能力受限**：低秩约束可能无法充分表达从生成任务到评分任务的复杂转换\n",
    "- ❌ **超参数敏感**：rank值r的选择对效果影响很大，需要大量实验调优\n",
    "- ❌ **任务转换局限**：对于奖励模型这种输出结构根本改变的任务，LoRA的适应能力可能不足\n",
    "- ❌ **控制粒度粗糙**：无法精确控制不同层的学习程度\n",
    "\n",
    "**排除原因：**\n",
    "虽然LoRA在资源效率上表现优秀，但其低秩约束的本质限制了它在复杂任务转换上的能力。奖励模型需要从文本生成转换为质量评分，这种根本性的任务变化可能超出了LoRA的表达能力范围。\n",
    "\n",
    "**具体问题：**\n",
    "1. 低秩瓶颈：rank=64的LoRA只能表达64维的变化空间，可能无法充分适应评分任务的复杂性\n",
    "2. 输出层适配困难：从vocab_size输出到标量输出的转换，LoRA难以有效处理\n",
    "3. COT理解保持：在保持长序列COT理解能力的同时学习评分，LoRA的表达能力可能不足"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc4cb3",
   "metadata": {},
   "source": [
    "### 2.3 AdaLoRA（Adaptive LoRA）\n",
    "\n",
    "**微调原理：**\n",
    "AdaLoRA是LoRA的改进版本，通过自适应调整不同层和不同权重矩阵的rank值：\n",
    "```\n",
    "W_new = W_frozen + α × A_i × B_i\n",
    "其中每层的rank r_i 根据重要性动态调整\n",
    "```\n",
    "使用奇异值分解（SVD）来评估参数重要性，动态分配rank。\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **自适应优化**：自动为重要层分配更多参数，理论上比固定rank的LoRA更有效\n",
    "- ✅ **参数效率**：在相同参数预算下可能获得更好的效果\n",
    "- ✅ **理论先进性**：代表了参数高效微调的最新发展方向\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **复杂度高**：实现和调试比标准LoRA复杂得多\n",
    "- ❌ **稳定性问题**：动态rank调整可能导致训练不稳定\n",
    "- ❌ **工具链不成熟**：相比LoRA，工具支持和社区经验较少\n",
    "- ❌ **根本局限未解决**：仍然受到低秩约束的根本限制\n",
    "\n",
    "**排除原因：**\n",
    "AdaLoRA虽然在理论上比LoRA更先进，但它并没有解决LoRA在奖励模型任务上的根本局限性。同时，其增加的复杂性与我们快速迭代的需求不符。\n",
    "\n",
    "**具体问题：**\n",
    "1. 实现复杂性：需要额外的SVD计算和rank调整逻辑，增加了调试难度\n",
    "2. 训练不稳定：动态调整可能导致训练过程中的性能波动\n",
    "3. 经验不足：缺乏在奖励模型任务上的成功案例和最佳实践\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30b98f",
   "metadata": {},
   "source": [
    "### 2.4 QLoRA（Quantized LoRA）\n",
    "\n",
    "**微调原理：**\n",
    "QLoRA结合了量化技术和LoRA，使用4位量化存储预训练权重，同时用LoRA进行微调：\n",
    "```\n",
    "W_new = dequantize(W_4bit) + α/r × A × B\n",
    "其中W_4bit是4位量化的预训练权重\n",
    "```\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **极致的内存效率**：4位量化可以将内存需求降低到原来的1/4\n",
    "- ✅ **大模型支持**：可以在有限硬件上训练更大的模型\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **精度损失风险**：量化可能影响模型的精度，特别是对精确评分任务\n",
    "- ❌ **复杂性增加**：需要处理量化和反量化的复杂逻辑\n",
    "- ❌ **LoRA局限依然存在**：仍然受到低秩约束的根本限制\n",
    "- ❌ **推理复杂性**：量化模型的推理可能更复杂\n",
    "\n",
    "**排除原因：**\n",
    "虽然QLoRA在内存效率上有优势，但量化带来的精度损失对于需要精确评分的奖励模型来说是不可接受的风险。\n",
    "\n",
    "**具体问题：**\n",
    "1. 评分精度影响：量化误差可能导致评分不准确，影响奖励模型的核心功能\n",
    "2. 调试困难：量化引入的数值问题难以调试和解决\n",
    "3. 部署复杂性：量化模型的部署和优化更加复杂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd21fad7",
   "metadata": {},
   "source": [
    "### 2.5 Adapter微调\n",
    "\n",
    "**微调原理：**\n",
    "Adapter在预训练模型的层间插入小型的可训练模块，原始参数保持冻结：\n",
    "```\n",
    "h_new = h + Adapter(h)\n",
    "其中Adapter通常是一个bottleneck结构：down_project → activation → up_project\n",
    "```\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **模块化设计**：可以为不同任务设计专门的Adapter模块\n",
    "- ✅ **参数效率**：只训练Adapter参数，效率较高\n",
    "- ✅ **灵活性**：可以在不同位置插入不同类型的Adapter\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **推理开销**：每个Adapter都会增加推理时的计算开销\n",
    "- ❌ **序列长度敏感**：对于COT这种长序列，多个Adapter的累积开销较大\n",
    "- ❌ **信息流干扰**：插入的模块可能干扰原有的信息流动\n",
    "- ❌ **位置选择困难**：需要仔细选择Adapter的插入位置\n",
    "\n",
    "**排除原因：**\n",
    "Adapter的推理开销与我们的实时性要求不符，特别是对于长序列的COT数据，多个Adapter的累积延迟会显著影响用户体验。\n",
    "\n",
    "**具体问题：**\n",
    "1. 推理延迟：每个Adapter增加5-10ms延迟，多个Adapter累积可能超过100ms限制\n",
    "2. 长序列处理：COT数据的长序列会放大Adapter的计算开销\n",
    "3. 架构复杂性：需要仔细设计Adapter的位置和结构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835890ba",
   "metadata": {},
   "source": [
    "### 2.6 Prefix Tuning\n",
    "\n",
    "**微调原理：**\n",
    "在输入序列前添加可训练的连续提示向量，模型参数保持冻结：\n",
    "```\n",
    "input_new = [trainable_prefix; original_input]\n",
    "只训练prefix部分的embedding\n",
    "```\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **参数极少**：只需要训练很少的prefix参数\n",
    "- ✅ **原模型不变**：完全不修改原始模型参数\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ❌ **任务不适配**：Prefix Tuning主要适用于生成任务，不适合奖励模型的评分任务\n",
    "- ❌ **输出结构无法改变**：无法处理从vocab输出到标量输出的根本性改变\n",
    "- ❌ **表达能力极限**：仅通过prefix很难表达复杂的任务转换\n",
    "- ❌ **序列长度影响**：对于长序列COT数据，prefix的影响可能被稀释\n",
    "\n",
    "**排除原因：**\n",
    "Prefix Tuning的设计理念与奖励模型的需求根本不匹配。它无法处理输出结构的根本性改变，也无法有效适应评分任务。\n",
    "\n",
    "**具体问题：**\n",
    "1. 输出层无法改变：无法从文本生成转换为标量评分\n",
    "2. 任务理解局限：仅通过prefix无法让模型理解评分任务的本质\n",
    "3. 长序列稀释：COT的长序列会稀释prefix的影响力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f73d0e",
   "metadata": {},
   "source": [
    "### 2.7 Freeze微调（分层冻结微调）\n",
    "\n",
    "**微调原理：**\n",
    "选择性地冻结和解冻模型的不同层，实现渐进式的能力获取：\n",
    "```\n",
    "θ_new = [θ_frozen, θ_trainable + Δθ_trainable]\n",
    "可以精确控制哪些层参与训练，哪些层保持冻结\n",
    "```\n",
    "\n",
    "**与业务场景的匹配分析：**\n",
    "\n",
    "**匹配的方面：**\n",
    "- ✅ **完美的任务适配**：可以专门训练score_head层，完美适应奖励模型任务\n",
    "- ✅ **知识保护机制**：冻结大部分层保护预训练的COT理解能力\n",
    "- ✅ **渐进式学习**：分阶段解冻，逐步获得领域适应能力，避免过拟合\n",
    "- ✅ **精确控制**：可以精确控制每一层的学习程度，训练过程高度可控\n",
    "- ✅ **资源高效**：显存需求随训练阶段递增，可以根据资源情况动态调整\n",
    "- ✅ **训练稳定**：分阶段训练，每阶段目标明确，收敛稳定\n",
    "- ✅ **调试友好**：容易定位问题，可以逐层分析模型行为\n",
    "\n",
    "**不匹配的方面：**\n",
    "- ⚠️ **策略设计复杂**：需要仔细设计冻结和解冻的策略，需要一定经验\n",
    "- ⚠️ **超参数较多**：不同阶段的学习率、训练步数等需要调优\n",
    "\n",
    "**选择原因：**\n",
    "Freeze微调在所有方面都与我们的业务场景高度匹配，是唯一能够完美解决所有核心需求的方法。\n",
    "\n",
    "**具体优势：**\n",
    "1. **任务转换完美支持**：可以专门训练输出层实现从生成到评分的转换\n",
    "2. **COT能力保护**：冻结transformer层保护长序列理解能力\n",
    "3. **过拟合防护**：限制可训练参数数量，在有限数据上获得更好泛化\n",
    "4. **资源匹配**：可以从最少的参数开始，逐步增加，完美匹配资源约束\n",
    "5. **快速迭代**：分阶段训练支持快速验证和调整策略\n",
    "\n",
    "## 三、最终选择总结\n",
    "\n",
    "通过对所有主流微调方法的详细分析，**Freeze微调**是唯一能够完美匹配我们业务场景所有需求的方法：\n",
    "\n",
    "- **解决任务转换问题**：专门训练score_head实现评分功能\n",
    "- **保护预训练能力**：冻结大部分参数保护COT理解能力  \n",
    "- **适应资源约束**：分阶段训练，资源需求可控\n",
    "- **支持快速迭代**：训练过程稳定，便于快速验证和调整\n",
    "- **提供精确控制**：可以精确控制学习过程的每个细节\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5eafe9",
   "metadata": {},
   "source": [
    "# 5.服务器选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469995b3",
   "metadata": {},
   "source": [
    "## 一、多机多卡异构集群搭建注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fa91ae",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620102714636.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b0a85",
   "metadata": {},
   "source": [
    "当前是用平台为[优云智算——注册连接](https://passport.compshare.cn/register?referral_code=Gkp7G2YRdxfEcI5fG6AWRr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9129c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620152511147.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee37d5d1",
   "metadata": {},
   "source": [
    "CPU平台选择：\n",
    "\n",
    "```bash\n",
    "# AMD的内存架构\n",
    "- 每个CPU直接连接8个内存通道\n",
    "- 总内存带宽：DDR5-4800 × 8通道 = 384GB/s\n",
    "- NUMA设计：每个CCD(Core Complex Die)都有独立内存控制器\n",
    "- 内存延迟：相对较低且一致\n",
    "\n",
    "# Intel Xeon的内存架构  \n",
    "- 每个CPU连接8个内存通道\n",
    "- 总内存带宽：DDR5-4800 × 8通道 = 384GB/s\n",
    "- 但实际可用带宽因架构限制通常更低\n",
    "- 内存延迟：在跨NUMA访问时较高\n",
    "\n",
    "# 大模型微调时，模型参数需要频繁在CPU内存和GPU显存之间传输，AMD的内存子系统设计让这个过程更高效。\n",
    "# 内存带宽优势：AMD的统一内存架构减少了NUMA跨域访问\n",
    "# PCIe拓扑优势：GPU间通信和CPU-GPU通信更高效\n",
    "\n",
    "# 1. 奖励模型微调 - 需要频繁的CPU-GPU数据交换\n",
    "# 2. 多机多卡分布式 - 需要高效的互连\n",
    "# 3. 预算敏感 - 需要更好的性价比\n",
    "# 4. 后续扩展 - 需要更多GPU支持能力\n",
    "\n",
    "例如：\n",
    "AMD EPYC 9554:\n",
    "- 奖励模型训练速度: ~1.2 samples/sec\n",
    "- GPU利用率: 98%\n",
    "- 内存带宽利用: 85%\n",
    "\n",
    "Intel Xeon 8480+:\n",
    "- 奖励模型训练速度: ~0.9 samples/sec  \n",
    "- GPU利用率: 95%\n",
    "- 内存带宽利用: 72%\n",
    "\n",
    "性能提升: AMD比Intel快约33%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bea319",
   "metadata": {},
   "source": [
    "## 不同服务器GPU型号和数量都不同\n",
    "\n",
    "### 1. **理论方案示例**\n",
    "```yaml\n",
    "TFLOPS 简单说：每秒能执行多少万亿次浮点运算\n",
    "集群配置:\n",
    "  服务器1: 4张RTX 4090 (24GB显存, 83 TFLOPS)\n",
    "  服务器2: 2张A100 (80GB显存, 156 TFLOPS) \n",
    "  服务器3: 6张RTX 3090 (24GB显存, 36 TFLOPS)\n",
    "```\n",
    "\n",
    "### 2. **会导致的结果**\n",
    "\n",
    "**性能瓶颈：**\n",
    "```python\n",
    "# 训练速度受限于最慢的GPU组\n",
    "实际训练速度 = min(\n",
    "    服务器1速度 / 4,  # RTX 4090组\n",
    "    服务器2速度 / 2,  # A100组  \n",
    "    服务器3速度 / 6   # RTX 3090组 (最慢)\n",
    ")\n",
    "# 结果：整个集群速度被RTX 3090拖累\n",
    "```\n",
    "\n",
    "**内存分配不均：**\n",
    "```bash\n",
    "模型分片问题:\n",
    "- A100: 80GB显存 → 可以加载更大的模型分片\n",
    "- RTX 4090/3090: 24GB显存 → 只能加载较小分片\n",
    "- 导致负载不均衡，A100利用率不足\n",
    "```\n",
    "\n",
    "### 3. **可能影响的问题**\n",
    "\n",
    "**同步等待时间长：**\n",
    "```python\n",
    "# DeepSpeed AllReduce通信模式\n",
    "梯度同步时间 = max(\n",
    "    服务器1_计算时间,\n",
    "    服务器2_计算时间, \n",
    "    服务器3_计算时间  # 最长\n",
    ")\n",
    "# 快的GPU要等慢的GPU完成计算\n",
    "```\n",
    "\n",
    "**资源浪费严重：**\n",
    "```bash\n",
    "GPU利用率:\n",
    "- A100: ~60% (性能被限制)\n",
    "- RTX 4090: ~75% (等待同步)\n",
    "- RTX 3090: ~95% (满负荷但拖累整体)\n",
    "\n",
    "实际效果: 花了A100的钱，得到RTX 3090的性能\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac558e02",
   "metadata": {},
   "source": [
    "## 二、所有GPU型号相同，但数量不同\n",
    "\n",
    "### 1. **理论方案示例**\n",
    "```yaml\n",
    "集群配置:\n",
    "  服务器1: 8张RTX 4090\n",
    "  服务器2: 4张RTX 4090\n",
    "  服务器3: 2张RTX 4090\n",
    "```\n",
    "\n",
    "### 2. **会导致的结果**\n",
    "\n",
    "**负载分配不均：**\n",
    "```python\n",
    "# DeepSpeed数据并行分配\n",
    "数据分片大小 = 总batch_size / 总GPU数量\n",
    "# 每个GPU处理相同大小的数据片\n",
    "\n",
    "服务器1: 8个GPU × 相同数据片 = 工作量大\n",
    "服务器2: 4个GPU × 相同数据片 = 工作量中等  \n",
    "服务器3: 2个GPU × 相同数据片 = 工作量小\n",
    "\n",
    "# 但同步时间相同，造成资源浪费\n",
    "```\n",
    "\n",
    "**通信开销不对称：**\n",
    "```bash\n",
    "AllReduce通信模式:\n",
    "- 服务器1: 需要聚合8个GPU的梯度\n",
    "- 服务器2: 需要聚合4个GPU的梯度\n",
    "- 服务器3: 需要聚合2个GPU的梯度\n",
    "\n",
    "结果: 服务器1的内部通信时间最长\n",
    "```\n",
    "\n",
    "### 3. **可能影响的问题**\n",
    "\n",
    "**同步瓶颈：**\n",
    "```python\n",
    "# 训练步骤时间分析\n",
    "步骤时间 = max(\n",
    "    服务器1_内部聚合时间,  # 最长，因为GPU最多\n",
    "    服务器2_内部聚合时间,\n",
    "    服务器3_内部聚合时间\n",
    ") + 跨服务器通信时间\n",
    "\n",
    "# GPU多的服务器成为瓶颈\n",
    "```\n",
    "\n",
    "**扩展性问题：**\n",
    "```bash\n",
    "动态扩缩容困难:\n",
    "- 增加GPU时必须考虑平衡性\n",
    "- 减少GPU时可能破坏现有平衡\n",
    "- 故障恢复复杂（不同服务器重要性不同）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d47d7c",
   "metadata": {},
   "source": [
    "\n",
    "### 1. **异构GPU型号配置**\n",
    "```bash\n",
    "影响程度: ★★★★★ (严重)\n",
    "性能损失: 40-60%\n",
    "推荐度: ❌ 不推荐\n",
    "\n",
    "原因:\n",
    "- 性能瓶颈明显\n",
    "- 调试复杂度高\n",
    "- 资源浪费严重\n",
    "- 扩展性差\n",
    "```\n",
    "\n",
    "### 2. **同构GPU数量不均配置**\n",
    "```bash\n",
    "影响程度: ★★★☆☆ (中等)\n",
    "性能损失: 15-25%\n",
    "推荐度: ⚠️ 可接受但不理想\n",
    "\n",
    "原因:\n",
    "- 同步开销增加\n",
    "- 负载不够均衡\n",
    "- 但至少GPU性能一致\n",
    "- 可通过配置优化\n",
    "```\n",
    "\n",
    "### 3. **最佳实践建议**\n",
    "```yaml\n",
    "理想配置:\n",
    "  每台服务器: 相同型号 + 相同数量的GPU\n",
    "  例如: 3台服务器 × 4张RTX 4090\n",
    "\n",
    "可接受配置:\n",
    "  每台服务器: 相同型号GPU，数量可略有差异\n",
    "  例如: 服务器1(4张) + 服务器2(4张) + 服务器3(2张)\n",
    "\n",
    "避免配置:\n",
    "  不同型号GPU混合使用\n",
    "  例如: A100 + RTX 4090 + RTX 3090\n",
    "```\n",
    "\n",
    "**核心原则：GPU型号一致比数量一致更重要！**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114821c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195128439.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244c11d",
   "metadata": {},
   "source": [
    "ssh ubuntu@106.75.127.84\n",
    "密码 B1M6n82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aab7272",
   "metadata": {},
   "source": [
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195447835.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39242668",
   "metadata": {},
   "source": [
    "看个人使用习惯的软件进行链接即可"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e2dee5",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195606437.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa5057",
   "metadata": {},
   "source": [
    "新建链接地址"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf233b4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195705116.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcda64",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195722261.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486879cb",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195745764.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928e9f8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604195805425.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5b7345",
   "metadata": {},
   "source": [
    "安装基础环境(只是安装示例，软件版本会有调整)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080e327",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604150228503.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728e5b0",
   "metadata": {},
   "source": [
    "直接ok tab按键\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604150413945.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c681c2",
   "metadata": {},
   "source": [
    "sudo apt update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9fd30",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604151044810.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8b5e3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604151501035.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085140fa",
   "metadata": {},
   "source": [
    "sudo ln -s /usr/bin/python3 /usr/bin/python   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7549e7b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604151539510.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b40387",
   "metadata": {},
   "source": [
    "安装miniconda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6ba52",
   "metadata": {},
   "source": [
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ab4c7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604152632235.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dcad06",
   "metadata": {},
   "source": [
    "如果速度慢更换镜像源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7e5e9",
   "metadata": {},
   "source": [
    "更换镜像源  wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc50a20",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604153039212.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717b501",
   "metadata": {},
   "source": [
    "安装miniconda  注意与下载脚本在相同路径下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0024e1f7",
   "metadata": {},
   "source": [
    "bash Miniconda3-latest-Linux-x86_64.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df12a8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604152800158.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f6f794",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604153316812.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5105b07f",
   "metadata": {},
   "source": [
    "刷新配置文件  source ~/.bashrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee337aa",
   "metadata": {},
   "source": [
    "检验安装状况  conda --version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e5106",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604153408669.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de4706",
   "metadata": {},
   "source": [
    "一键替换为清华镜像源的方式如下：\n",
    "\n",
    "conda config --remove-key channels\n",
    "\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge\n",
    "conda config --add channels defaults\n",
    "\n",
    "conda config --set show_channel_urls true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706de1df",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604154343094.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15529a",
   "metadata": {},
   "source": [
    "一键安装conda环境脚本\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "echo \"🔍 正在删除旧的安装包（如果有）...\"\n",
    "rm -f Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    "echo \"🌐 从清华源下载 Miniconda 安装包...\"\n",
    "wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    "echo \"📦 开始安装 Miniconda 到 ~/miniconda3...\"\n",
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3\n",
    "\n",
    "echo \"🔁 配置 Conda 环境变量...\"\n",
    "eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "echo 'export PATH=\"$HOME/miniconda3/bin:$PATH\"' >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "\n",
    "echo \"🚀 初始化 Conda...\"\n",
    "conda init\n",
    "source ~/.bashrc\n",
    "\n",
    "echo \"🇨🇳 正在设置 Conda 清华镜像源...\"\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge\n",
    "conda config --add channels defaults\n",
    "\n",
    "conda config --set show_channel_urls true\n",
    "\n",
    "echo \"🐍 创建 Python 3.11 虚拟环境：py311\"\n",
    "conda create -y -n reward python=3.11\n",
    "\n",
    "echo \"✅ 安装完成！现在你可以激活环境了：\"\n",
    "echo \"    conda activate reward\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65402f",
   "metadata": {},
   "source": [
    "创建环境\n",
    "\n",
    "conda create -n reward python=3.11 -y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8416f84",
   "metadata": {},
   "source": [
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604155932428.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442375fa",
   "metadata": {},
   "source": [
    "```bash\n",
    "# 安装核心依赖\n",
    "\n",
    "pip install transformers==4.36.0\n",
    "pip install datasets==2.14.0\n",
    "pip install accelerate==0.24.0\n",
    "pip install deepspeed==0.15.4\n",
    "pip install peft==0.7.0\n",
    "\n",
    "\n",
    "# 安装其他必要依赖\n",
    "\n",
    "pip install \\\n",
    "​    numpy \\\n",
    "​    pandas \\\n",
    "​    scikit-learn \\\n",
    "​    matplotlib \\\n",
    "​    seaborn \\\n",
    "​    tensorboard \\\n",
    "​    wandb \\\n",
    "​    tqdm \\\n",
    "​    psutil \\\n",
    "​    py-cpuinfo \\\n",
    "​    pynvml\n",
    "\n",
    "准备下载模型\n",
    "pip install modelscope\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3333146",
   "metadata": {},
   "source": [
    "mkdir -p QRM-Llama3.1(路径名称可以自行指定)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54406ed",
   "metadata": {},
   "source": [
    "nohup modelscope download --model nicolinho/QRM-Llama3.1-8B-v2  --local_dir ./QRM-Llama3.1 > modelscope_dow.log 2>&1 &\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fbaab",
   "metadata": {},
   "source": [
    "tail -f modelscope_dow.log \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28597757",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250604194915238.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda62ce",
   "metadata": {},
   "source": [
    "安装命令合集可以考虑一键执行\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "set -e  # 遇到错误立即退出\n",
    "\n",
    "echo \"🚀 开始配置深度学习训练环境（精简版）\"\n",
    "echo \"========================================\"\n",
    "\n",
    "# 1. 系统基础配置\n",
    "echo \"📦 1. 更新系统并安装基础依赖...\"\n",
    "sudo apt update && sudo apt upgrade -y\n",
    "sudo apt install -y \\\n",
    "    wget curl git vim htop tmux \\\n",
    "    build-essential python3-dev python3-pip python3-venv \\\n",
    "    software-properties-common\n",
    "\n",
    "# 创建python软链接（如果不存在）\n",
    "if ! command -v python &> /dev/null; then\n",
    "    sudo ln -s /usr/bin/python3 /usr/bin/python\n",
    "    echo \"✅ 创建python软链接\"\n",
    "fi\n",
    "\n",
    "# 2. 处理Miniconda安装\n",
    "echo \"🐍 2. 处理Miniconda安装...\"\n",
    "\n",
    "# 检查是否已经安装conda\n",
    "if command -v conda &> /dev/null; then\n",
    "    echo \"✅ 检测到已安装的Conda，跳过安装步骤\"\n",
    "    # 确保conda在PATH中\n",
    "    export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "    eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "else\n",
    "    # 检查是否存在miniconda3目录但conda命令不可用\n",
    "    if [ -d \"$HOME/miniconda3\" ]; then\n",
    "        echo \"🔧 检测到miniconda3目录但conda不可用，尝试修复...\"\n",
    "        export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "        if [ -f \"$HOME/miniconda3/bin/conda\" ]; then\n",
    "            eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "            $HOME/miniconda3/bin/conda init\n",
    "            source ~/.bashrc\n",
    "            echo \"✅ Conda环境修复成功\"\n",
    "        else\n",
    "            echo \"⚠️ miniconda3目录损坏，重新安装...\"\n",
    "            rm -rf $HOME/miniconda3\n",
    "            # 重新安装\n",
    "            echo \"🔍 删除旧的安装包...\"\n",
    "            rm -f Miniconda3-latest-Linux-x86_64.sh\n",
    "            \n",
    "            echo \"🌐 从清华源下载Miniconda...\"\n",
    "            wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "            \n",
    "            echo \"📦 安装Miniconda到 ~/miniconda3...\"\n",
    "            bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3\n",
    "            \n",
    "            echo \"🔁 配置环境变量...\"\n",
    "            export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "            eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "            echo 'export PATH=\"$HOME/miniconda3/bin:$PATH\"' >> ~/.bashrc\n",
    "            \n",
    "            echo \"🚀 初始化Conda...\"\n",
    "            $HOME/miniconda3/bin/conda init\n",
    "            source ~/.bashrc\n",
    "        fi\n",
    "    else\n",
    "        # 全新安装\n",
    "        echo \"🔍 删除旧的安装包...\"\n",
    "        rm -f Miniconda3-latest-Linux-x86_64.sh\n",
    "        \n",
    "        echo \"🌐 从清华源下载Miniconda...\"\n",
    "        wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "        \n",
    "        echo \"📦 安装Miniconda到 ~/miniconda3...\"\n",
    "        bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3\n",
    "        \n",
    "        echo \"🔁 配置环境变量...\"\n",
    "        export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "        eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "        echo 'export PATH=\"$HOME/miniconda3/bin:$PATH\"' >> ~/.bashrc\n",
    "        \n",
    "        echo \"🚀 初始化Conda...\"\n",
    "        $HOME/miniconda3/bin/conda init\n",
    "        source ~/.bashrc\n",
    "    fi\n",
    "fi\n",
    "\n",
    "# 确保conda可用\n",
    "export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "\n",
    "# 3. 配置Conda镜像源\n",
    "echo \"🇨🇳 3. 配置Conda清华镜像源...\"\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge\n",
    "conda config --add channels defaults\n",
    "conda config --set show_channel_urls true\n",
    "\n",
    "# 4. 自动处理虚拟环境（无交互）\n",
    "echo \"🐍 4. 处理Python 3.11虚拟环境...\"\n",
    "if conda env list | grep -q \"^reward \"; then\n",
    "    echo \"✅ 检测到已存在的reward环境，继续使用现有环境\"\n",
    "    echo \"📝 如果需要重新创建环境，请手动运行: conda env remove -n reward -y && conda create -n reward python=3.11 -y\"\n",
    "else\n",
    "    echo \"🆕 创建新的reward环境...\"\n",
    "    conda create -n reward python=3.11 -y\n",
    "fi\n",
    "\n",
    "# 5. 激活环境并配置pip镜像源\n",
    "echo \"⚙️ 5. 激活环境并配置pip镜像源...\"\n",
    "conda activate reward\n",
    "\n",
    "mkdir -p ~/.pip\n",
    "cat > ~/.pip/pip.conf << 'EOF'\n",
    "[global]\n",
    "index-url = https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "trusted-host = pypi.tuna.tsinghua.edu.cn\n",
    "timeout = 300\n",
    "retries = 5\n",
    "EOF\n",
    "\n",
    "# 6. 智能检查并安装依赖\n",
    "echo \"📊 6. 智能检查并安装依赖...\"\n",
    "\n",
    "# 检查包是否已安装的函数\n",
    "check_package() {\n",
    "    conda activate reward\n",
    "    python -c \"import $1\" 2>/dev/null && return 0 || return 1\n",
    "}\n",
    "\n",
    "# 检查conda包是否已安装\n",
    "check_conda_package() {\n",
    "    conda list | grep -q \"^$1 \" && return 0 || return 1\n",
    "}\n",
    "\n",
    "# 安装基础科学计算包\n",
    "echo \"📊 检查并安装基础科学计算包...\"\n",
    "missing_packages=()\n",
    "for pkg in numpy pandas scikit-learn matplotlib seaborn pyyaml tqdm psutil; do\n",
    "    if ! check_conda_package $pkg; then\n",
    "        missing_packages+=($pkg)\n",
    "    fi\n",
    "done\n",
    "\n",
    "if [ ${#missing_packages[@]} -gt 0 ]; then\n",
    "    echo \"安装缺失的基础包: ${missing_packages[*]}\"\n",
    "    conda install -y \"${missing_packages[@]}\"\n",
    "else\n",
    "    echo \"✅ 基础科学计算包已完整安装\"\n",
    "fi\n",
    "\n",
    "# 安装PyTorch 2.5.1（更新版本）\n",
    "echo \"🔥 检查并安装PyTorch 2.5.1...\"\n",
    "if ! check_package torch; then\n",
    "    if command -v nvidia-smi &> /dev/null; then\n",
    "        echo \"检测到NVIDIA GPU，安装GPU版本PyTorch 2.5.1...\"\n",
    "        # 使用pip安装指定版本，避免conda版本冲突\n",
    "        pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n",
    "            -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "    else\n",
    "        echo \"未检测到GPU，安装CPU版本PyTorch 2.5.1...\"\n",
    "        pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 \\\n",
    "            --index-url https://download.pytorch.org/whl/cpu \\\n",
    "            -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "    fi\n",
    "else\n",
    "    # 检查PyTorch版本是否正确\n",
    "    current_version=$(python -c \"import torch; print(torch.__version__)\" 2>/dev/null || echo \"unknown\")\n",
    "    if [[ \"$current_version\" == \"2.5.1\"* ]]; then\n",
    "        echo \"✅ PyTorch 2.5.1已安装\"\n",
    "    else\n",
    "        echo \"⚠️  当前PyTorch版本: $current_version，建议升级到2.5.1\"\n",
    "        echo \"   如需升级，请运行: pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\"\n",
    "    fi\n",
    "fi\n",
    "\n",
    "# 安装transformers生态\n",
    "echo \"🤗 检查并安装transformers生态...\"\n",
    "if ! check_package transformers; then\n",
    "    echo \"安装transformers生态...\"\n",
    "    pip install tokenizers huggingface-hub\n",
    "    pip install transformers==4.36.0\n",
    "else\n",
    "    echo \"✅ Transformers已安装\"\n",
    "fi\n",
    "\n",
    "# 安装其他核心依赖（包含兼容的DeepSpeed版本）\n",
    "echo \"⚡ 检查并安装其他核心依赖...\"\n",
    "pip_packages=(\n",
    "    \"datasets==2.14.0:datasets\"\n",
    "    \"accelerate==0.24.0:accelerate\" \n",
    "    \"peft==0.7.0:peft\"\n",
    "    \"deepspeed==0.15.4:deepspeed\"\n",
    "    \"tensorboard:tensorboard\"\n",
    "    \"wandb:wandb\"\n",
    "    \"py-cpuinfo:cpuinfo\"\n",
    "    \"pynvml:pynvml\"\n",
    ")\n",
    "\n",
    "for package_info in \"${pip_packages[@]}\"; do\n",
    "    package_spec=$(echo $package_info | cut -d':' -f1)\n",
    "    package_name=$(echo $package_info | cut -d':' -f2)\n",
    "    \n",
    "    if ! check_package $package_name; then\n",
    "        echo \"安装 $package_spec...\"\n",
    "        pip install $package_spec\n",
    "    else\n",
    "        echo \"✅ $package_name 已安装\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "# 7. 创建通用激活脚本\n",
    "echo \"📝 7. 创建环境激活脚本...\"\n",
    "cat > $HOME/activate_reward_env.sh << 'EOF'\n",
    "#!/bin/bash\n",
    "export PATH=\"$HOME/miniconda3/bin:$PATH\"\n",
    "eval \"$($HOME/miniconda3/bin/conda shell.bash hook)\"\n",
    "conda activate reward\n",
    "echo \"🎉 reward环境已激活！\"\n",
    "echo \"🐍 Python版本: $(python --version)\"\n",
    "echo \"🔥 PyTorch版本: $(python -c 'import torch; print(torch.__version__)')\"\n",
    "echo \"🤗 Transformers版本: $(python -c 'import transformers; print(transformers.__version__)')\"\n",
    "if python -c \"import torch; exit(0 if torch.cuda.is_available() else 1)\" 2>/dev/null; then\n",
    "    echo \"🎮 GPU可用: $(python -c 'import torch; print(torch.cuda.device_count())')\"\n",
    "    for i in $(python -c \"import torch; print(' '.join(map(str, range(torch.cuda.device_count()))))\"); do\n",
    "        echo \"   GPU $i: $(python -c \"import torch; print(torch.cuda.get_device_name($i))\")\"\n",
    "    done\n",
    "else\n",
    "    echo \"💻 使用CPU模式\"\n",
    "fi\n",
    "EOF\n",
    "chmod +x $HOME/activate_reward_env.sh\n",
    "\n",
    "# 8. 验证安装\n",
    "echo \"🔍 8. 验证安装...\"\n",
    "conda activate reward\n",
    "python -c \"\n",
    "import sys\n",
    "print(f'Python版本: {sys.version}')\n",
    "print('=' * 50)\n",
    "\n",
    "packages = [\n",
    "    ('torch', 'PyTorch'),\n",
    "    ('transformers', 'Transformers'),\n",
    "    ('datasets', 'Datasets'),\n",
    "    ('accelerate', 'Accelerate'),\n",
    "    ('deepspeed', 'DeepSpeed'),\n",
    "    ('peft', 'PEFT'),\n",
    "    ('numpy', 'NumPy'),\n",
    "    ('pandas', 'Pandas'),\n",
    "    ('tensorboard', 'TensorBoard'),\n",
    "    ('wandb', 'WandB')\n",
    "]\n",
    "\n",
    "success_count = 0\n",
    "for module, name in packages:\n",
    "    try:\n",
    "        mod = __import__(module)\n",
    "        version = getattr(mod, '__version__', 'unknown')\n",
    "        print(f'✅ {name}: {version}')\n",
    "        success_count += 1\n",
    "    except ImportError as e:\n",
    "        print(f'❌ {name}: 安装失败 - {e}')\n",
    "\n",
    "print('=' * 50)\n",
    "print(f'安装成功: {success_count}/{len(packages)} 个包')\n",
    "\n",
    "# 检查CUDA\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'🎮 CUDA可用: {torch.cuda.device_count()} GPU(s)')\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f'   GPU {i}: {torch.cuda.get_device_name(i)}')\n",
    "    else:\n",
    "        print('💻 CUDA不可用，使用CPU模式')\n",
    "except Exception as e:\n",
    "    print(f'⚠️ 无法检查CUDA状态: {e}')\n",
    "\"\n",
    "\n",
    "# 9. 清理\n",
    "echo \"🧹 9. 清理安装文件...\"\n",
    "rm -f Miniconda3-latest-Linux-x86_64.sh\n",
    "\n",
    "# 10. 创建环境信息文件\n",
    "echo \"📋 10. 创建环境信息文件...\"\n",
    "cat > $HOME/environment_info.txt << EOF\n",
    "深度学习训练环境信息\n",
    "==================\n",
    "\n",
    "安装时间: $(date)\n",
    "Python版本: $(conda activate reward && python --version)\n",
    "PyTorch版本: 2.5.1\n",
    "DeepSpeed版本: 0.16.8\n",
    "Conda版本: $(conda --version)\n",
    "\n",
    "激活脚本: $HOME/activate_reward_env.sh\n",
    "\n",
    "使用方法:\n",
    "1. 激活环境: source ~/activate_reward_env.sh\n",
    "2. 手动激活: conda activate reward\n",
    "3. 查看环境: conda env list\n",
    "4. 查看已安装包: conda list\n",
    "\n",
    "如需重新创建环境:\n",
    "conda env remove -n reward -y\n",
    "conda create -n reward python=3.11 -y\n",
    "EOF\n",
    "\n",
    "echo \"\"\n",
    "echo \"🎉 环境配置完成！\"\n",
    "echo \"========================\"\n",
    "echo \"📋 使用说明：\"\n",
    "echo \"1. 激活环境: source ~/activate_reward_env.sh\"\n",
    "echo \"2. 或者手动激活: conda activate reward\"\n",
    "echo \"3. 环境信息: ~/environment_info.txt\"\n",
    "echo \"\"\n",
    "echo \"🔧 如果需要重新创建环境，运行:\"\n",
    "echo \"   conda env remove -n reward -y && conda create -n reward python=3.11 -y\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770295f",
   "metadata": {},
   "source": [
    "# 6.总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74f7ef8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250620165830822.png\" width=100%></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fufan_chat_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
